resources:
  - apiVersion: apps/v1
    kind: Deployment
    metadata:
      annotations:
        appliance.sourcegraph.com/configHash: 67efb602e9f61b6b18e0c5eea7be1713e7f99cb08862aa0bc779a8eef66be301
      creationTimestamp: "2024-04-19T00:00:00Z"
      generation: 1
      labels:
        app.kubernetes.io/component: prometheus
        app.kubernetes.io/name: sourcegraph
        app.kubernetes.io/version: 5.3.9104
        deploy: sourcegraph
      name: prometheus
      namespace: NORMALIZED_FOR_TESTING
      ownerReferences:
        - apiVersion: v1
          blockOwnerDeletion: true
          controller: true
          kind: ConfigMap
          name: sg
          uid: NORMALIZED_FOR_TESTING
      resourceVersion: NORMALIZED_FOR_TESTING
      uid: NORMALIZED_FOR_TESTING
    spec:
      minReadySeconds: 10
      progressDeadlineSeconds: 600
      replicas: 1
      revisionHistoryLimit: 10
      selector:
        matchLabels:
          app: prometheus
      strategy:
        type: Recreate
      template:
        metadata:
          annotations:
            kubectl.kubernetes.io/default-container: prometheus
          creationTimestamp: null
          labels:
            app: prometheus
            deploy: sourcegraph
          name: prometheus
        spec:
          containers:
            - image: index.docker.io/sourcegraph/prometheus:5.3.9104
              imagePullPolicy: IfNotPresent
              name: prometheus
              ports:
                - containerPort: 9090
                  name: http
                  protocol: TCP
              readinessProbe:
                failureThreshold: 120
                httpGet:
                  path: /-/ready
                  port: http
                  scheme: HTTP
                periodSeconds: 5
                successThreshold: 1
                timeoutSeconds: 3
              resources:
                limits:
                  cpu: "2"
                  memory: 6G
                requests:
                  cpu: 500m
                  memory: 6G
              securityContext:
                allowPrivilegeEscalation: false
                readOnlyRootFilesystem: true
                runAsGroup: 101
                runAsUser: 100
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: FallbackToLogsOnError
              volumeMounts:
                - mountPath: /prometheus
                  name: data
                - mountPath: /sg_prometheus_add_ons
                  name: config
          dnsPolicy: ClusterFirst
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 101
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 101
            runAsUser: 100
          serviceAccount: prometheus
          serviceAccountName: prometheus
          terminationGracePeriodSeconds: 30
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: prometheus
            - configMap:
                defaultMode: 511
                name: prometheus
              name: config
    status: {}
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      annotations:
        appliance.sourcegraph.com/configHash: 67efb602e9f61b6b18e0c5eea7be1713e7f99cb08862aa0bc779a8eef66be301
      creationTimestamp: "2024-04-19T00:00:00Z"
      labels:
        deploy: sourcegraph
        for-namespace: NORMALIZED_FOR_TESTING
      name: NORMALIZED_FOR_TESTING-prometheus
      namespace: NORMALIZED_FOR_TESTING
      resourceVersion: NORMALIZED_FOR_TESTING
      uid: NORMALIZED_FOR_TESTING
    rules:
      - apiGroups:
          - ""
        resources:
          - endpoints
          - pods
          - services
          - namespaces
          - nodes
          - nodes/metrics
          - nodes/proxy
        verbs:
          - get
          - list
          - watch
      - apiGroups:
          - ""
        resources:
          - configmaps
        verbs:
          - get
      - nonResourceURLs:
          - /metrics
        verbs:
          - get
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      annotations:
        appliance.sourcegraph.com/configHash: 67efb602e9f61b6b18e0c5eea7be1713e7f99cb08862aa0bc779a8eef66be301
      creationTimestamp: "2024-04-19T00:00:00Z"
      labels:
        deploy: sourcegraph
        for-namespace: NORMALIZED_FOR_TESTING
      name: NORMALIZED_FOR_TESTING-prometheus
      namespace: NORMALIZED_FOR_TESTING
      resourceVersion: NORMALIZED_FOR_TESTING
      uid: NORMALIZED_FOR_TESTING
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: NORMALIZED_FOR_TESTING-prometheus
    subjects:
      - kind: ServiceAccount
        name: prometheus
        namespace: NORMALIZED_FOR_TESTING
  - apiVersion: v1
    data:
      extra_rules.yml: ""
      prometheus.yml: |
        global:
          scrape_interval:     30s
          evaluation_interval: 30s

        alerting:
          alertmanagers:
            # Bundled Alertmanager, started by prom-wrapper
            - static_configs:
                - targets: ['127.0.0.1:9093']
              path_prefix: /alertmanager
            # Uncomment the following to have alerts delivered to additional Alertmanagers discovered
            # in the cluster. This configuration is not required if you use Sourcegraph's built-in alerting:
            # https://docs.sourcegraph.com/admin/observability/alerting
            # - kubernetes_sd_configs:
            #  - role: endpoints
            #  relabel_configs:
            #    - source_labels: [__meta_kubernetes_service_name]
            #      regex: alertmanager
            #      action: keep

        rule_files:
          - '*_rules.yml'
          - "/sg_config_prometheus/*_rules.yml"
          - "/sg_prometheus_add_ons/*_rules.yml"

        # A scrape configuration for running Prometheus on a Kubernetes cluster.
        # This uses separate scrape configs for cluster components (i.e. API server, node)
        # and services to allow each to use different authentication configs.
        #
        # Kubernetes labels will be added as Prometheus labels on metrics via the
        # `labelmap` relabeling action.

        # Scrape config for API servers.
        #
        # Kubernetes exposes API servers as endpoints to the default/kubernetes
        # service so this uses `endpoints` role and uses relabelling to only keep
        # the endpoints associated with the default/kubernetes service using the
        # default named port `https`. This works for single API server deployments as
        # well as HA API server deployments.
        scrape_configs:
        - job_name: 'kubernetes-apiservers'

          kubernetes_sd_configs:
          - role: endpoints

          # Default to scraping over https. If required, just disable this or change to
          # `http`.
          scheme: https

          # This TLS & bearer token file config is used to connect to the actual scrape
          # endpoints for cluster components. This is separate to discovery auth
          # configuration because discovery & scraping are two separate concerns in
          # Prometheus. The discovery auth config is automatic if Prometheus runs inside
          # the cluster. Otherwise, more config options have to be provided within the
          # <kubernetes_sd_config>.
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            # If your node certificates are self-signed or use a different CA to the
            # master CA, then disable certificate verification below. Note that
            # certificate verification is an integral part of a secure infrastructure
            # so this should only be disabled in a controlled environment. You can
            # disable certificate verification by uncommenting the line below.
            #
            # insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

          # Keep only the default/kubernetes service endpoints for the https port. This
          # will add targets for each API server which Kubernetes adds an endpoint to
          # the default/kubernetes service.
          relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https

        - job_name: 'kubernetes-nodes'

          # Default to scraping over https. If required, just disable this or change to
          # `http`.
          scheme: https

          # This TLS & bearer token file config is used to connect to the actual scrape
          # endpoints for cluster components. This is separate to discovery auth
          # configuration because discovery & scraping are two separate concerns in
          # Prometheus. The discovery auth config is automatic if Prometheus runs inside
          # the cluster. Otherwise, more config options have to be provided within the
          # <kubernetes_sd_config>.
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            # If your node certificates are self-signed or use a different CA to the
            # master CA, then disable certificate verification below. Note that
            # certificate verification is an integral part of a secure infrastructure
            # so this should only be disabled in a controlled environment. You can
            # disable certificate verification by uncommenting the line below.
            #
            insecure_skip_verify: true
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

          kubernetes_sd_configs:
          - role: node

          relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics # End of privileged config

        # Scrape config for service endpoints.
        #
        # The relabeling allows the actual service scrape endpoint to be configured
        # via the following annotations:
        #
        # * `prometheus.io/scrape`: Only scrape services that have a value of `true`
        # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
        # to set this to `https` & most likely set the `tls_config` of the scrape config.
        # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
        # * `prometheus.io/port`: If the metrics are exposed on a different port to the
        # service then set this appropriately.
        - job_name: 'kubernetes-service-endpoints'

          kubernetes_sd_configs:
          - role: endpoints
            namespaces:
              names:
               - NORMALIZED_FOR_TESTING

          relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_sourcegraph_prometheus_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: drop
            regex: jaeger-agent
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: (.+)(?::\d+);(\d+)
            replacement: $1:$2
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            # Sourcegraph specific customization. We want a more convenient to type label.
            # target_label: kubernetes_namespace
            target_label: ns
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: kubernetes_name
          # Sourcegraph specific customization. We want a nicer name for job
          - source_labels: [app]
            action: replace
            target_label: job
          # Sourcegraph specific customization. We want a nicer name for instance
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: instance
          # Sourcegraph specific customization. We want to add a label to every
          # metric that indicates the node it came from.
          - source_labels: [__meta_kubernetes_endpoint_node_name]
            action: replace
            target_label: nodename
          metric_relabel_configs:
          # Sourcegraph specific customization. Drop metrics with empty nodename responses from the k8s API
          - source_labels: [nodename]
            regex: ^$
            action: drop

        # Example scrape config for probing services via the Blackbox Exporter.
        #
        # The relabeling allows the actual service scrape endpoint to be configured
        # via the following annotations:
        #
        # * `prometheus.io/probe`: Only probe services that have a value of `true`
        - job_name: 'kubernetes-services'

          metrics_path: /probe
          params:
            module: [http_2xx]

          kubernetes_sd_configs:
          - role: service

          relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
            action: keep
            regex: true
          - source_labels: [__address__]
            target_label: __param_target
          - target_label: __address__
            replacement: blackbox
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_service_namespace]
            # Sourcegraph specific customization. We want a more convenient to type label.
            # target_label: kubernetes_namespace
            target_label: ns
          - source_labels: [__meta_kubernetes_service_name]
            target_label: kubernetes_name

        # Example scrape config for pods
        #
        # The relabeling allows the actual pod scrape endpoint to be configured via the
        # following annotations:
        #
        # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`
        # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
        # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.
        - job_name: 'kubernetes-pods'

          kubernetes_sd_configs:
          - role: pod

          relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_sourcegraph_prometheus_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: (.+):(?:\d+);(\d+)
            replacement: ${1}:${2}
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
          # Sourcegraph specific customization. We want a more convenient to type label.
          # target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: ns
          # Sourcegraph specific customization. We want to add a label to every
          # metric that indicates the node it came from.
          - source_labels: [__meta_kubernetes_pod_node_name]
            action: replace
            target_label: nodename

          metric_relabel_configs:
          # cAdvisor-specific customization. Drop container metrics exported by cAdvisor
          # not in the same namespace as Sourcegraph.
          # Uncomment this if you have problems with certain dashboards or cAdvisor itself
          # picking up non-Sourcegraph services. Ensure all Sourcegraph services are running
          # within the Sourcegraph namespace you have defined.
          # The regex must keep matches on '^$' (empty string) to ensure other metrics do not
          # get dropped.
          - source_labels: [container_label_io_kubernetes_pod_namespace]
            regex: ^$|NORMALIZED_FOR_TESTING
            action: keep
          # cAdvisor-specific customization. We want container metrics to be named after their container name label.
          # Note that 'io.kubernetes.container.name' and 'io.kubernetes.pod.name' must be provided in cAdvisor
          # '--whitelisted_container_labels' (see cadvisor.DaemonSet.yaml)
          - source_labels: [container_label_io_kubernetes_container_name, container_label_io_kubernetes_pod_name]
            regex: (.+)
            action: replace
            target_label: name
            separator: '-'
          # Sourcegraph specific customization. Drop metrics with empty nodename responses from the k8s API
          - source_labels: [nodename]
            regex: ^$
            action: drop

        # Scrape prometheus itself for metrics.
        - job_name: 'builtin-prometheus'
          static_configs:
            - targets: ['127.0.0.1:9092']
              labels:
                app: prometheus
        - job_name: 'builtin-alertmanager'
          metrics_path: /alertmanager/metrics
          static_configs:
            - targets: ['127.0.0.1:9093']
              labels:
                app: alertmanager
    immutable: false
    kind: ConfigMap
    metadata:
      annotations:
        appliance.sourcegraph.com/configHash: 67efb602e9f61b6b18e0c5eea7be1713e7f99cb08862aa0bc779a8eef66be301
      creationTimestamp: "2024-04-19T00:00:00Z"
      labels:
        deploy: sourcegraph
      name: prometheus
      namespace: NORMALIZED_FOR_TESTING
      ownerReferences:
        - apiVersion: v1
          blockOwnerDeletion: true
          controller: true
          kind: ConfigMap
          name: sg
          uid: NORMALIZED_FOR_TESTING
      resourceVersion: NORMALIZED_FOR_TESTING
      uid: NORMALIZED_FOR_TESTING
  - apiVersion: v1
    data:
      spec: |
        spec:
          requestedVersion: "5.3.9104"

          blobstore:
            disabled: true

          codeInsights:
            disabled: true

          codeIntel:
            disabled: true

          frontend:
            disabled: true

          grafana:
            disabled: true

          gitServer:
            disabled: true

          indexedSearch:
            disabled: true

          nodeExporter:
            disabled: true

          openTelemetryCollector:
            disabled: true

          openTelemetryAgent:
            disabled: true

          pgsql:
            disabled: true

          postgresExporter:
            disabled: true

          preciseCodeIntel:
            disabled: true

          redisCache:
            disabled: true

          redisStore:
            disabled: true

          repoUpdater:
            disabled: true

          searcher:
            disabled: true

          symbols:
            disabled: true

          syntectServer:
            disabled: true

          worker:
            disabled: true

          prometheus:
            privileged: true
    kind: ConfigMap
    metadata:
      annotations:
        appliance.sourcegraph.com/currentVersion: 5.3.9104
        appliance.sourcegraph.com/managed: "true"
      creationTimestamp: "2024-04-19T00:00:00Z"
      name: sg
      namespace: NORMALIZED_FOR_TESTING
      resourceVersion: NORMALIZED_FOR_TESTING
      uid: NORMALIZED_FOR_TESTING
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      annotations:
        appliance.sourcegraph.com/configHash: 67efb602e9f61b6b18e0c5eea7be1713e7f99cb08862aa0bc779a8eef66be301
      creationTimestamp: "2024-04-19T00:00:00Z"
      finalizers:
        - kubernetes.io/pvc-protection
      labels:
        deploy: sourcegraph
      name: prometheus
      namespace: NORMALIZED_FOR_TESTING
      ownerReferences:
        - apiVersion: v1
          blockOwnerDeletion: true
          controller: true
          kind: ConfigMap
          name: sg
          uid: NORMALIZED_FOR_TESTING
      resourceVersion: NORMALIZED_FOR_TESTING
      uid: NORMALIZED_FOR_TESTING
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 200Gi
      volumeMode: Filesystem
    status:
      phase: Pending
  - apiVersion: v1
    kind: ServiceAccount
    metadata:
      annotations:
        appliance.sourcegraph.com/configHash: 67efb602e9f61b6b18e0c5eea7be1713e7f99cb08862aa0bc779a8eef66be301
      creationTimestamp: "2024-04-19T00:00:00Z"
      labels:
        deploy: sourcegraph
      name: prometheus
      namespace: NORMALIZED_FOR_TESTING
      ownerReferences:
        - apiVersion: v1
          blockOwnerDeletion: true
          controller: true
          kind: ConfigMap
          name: sg
          uid: NORMALIZED_FOR_TESTING
      resourceVersion: NORMALIZED_FOR_TESTING
      uid: NORMALIZED_FOR_TESTING
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
        appliance.sourcegraph.com/configHash: 67efb602e9f61b6b18e0c5eea7be1713e7f99cb08862aa0bc779a8eef66be301
      creationTimestamp: "2024-04-19T00:00:00Z"
      labels:
        app: prometheus
        app.kubernetes.io/component: prometheus
        deploy: sourcegraph
      name: prometheus
      namespace: NORMALIZED_FOR_TESTING
      ownerReferences:
        - apiVersion: v1
          blockOwnerDeletion: true
          controller: true
          kind: ConfigMap
          name: sg
          uid: NORMALIZED_FOR_TESTING
      resourceVersion: NORMALIZED_FOR_TESTING
      uid: NORMALIZED_FOR_TESTING
    spec:
      clusterIP: NORMALIZED_FOR_TESTING
      clusterIPs:
        - NORMALIZED_FOR_TESTING
      internalTrafficPolicy: Cluster
      ipFamilies:
        - IPv4
      ipFamilyPolicy: SingleStack
      ports:
        - name: http
          port: 30090
          protocol: TCP
          targetPort: http
      selector:
        app: syntect-server
      sessionAffinity: None
      type: ClusterIP
    status:
      loadBalancer: {}
