{
	"codeinsights": {
		"Definitions": [
			{
				"ID": -1000000000,
				"Name": "squashed migrations (privileged)",
				"UpQuery": "",
				"DownQuery": "",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": null,
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000000,
				"Name": "squashed migrations",
				"UpQuery": "-- empty migration",
				"DownQuery": "-- empty migration",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					-1000000000
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000001,
				"Name": "initial schema",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pg_trgm;\nCREATE EXTENSION IF NOT EXISTS citext;\n\n-- Records repository names, both historical and present, using a unique repository _name_ ID\n-- (unrelated to the repository ID.)\nCREATE TABLE repo_names (\n    -- The repository _name_ ID.\n    id bigserial NOT NULL PRIMARY KEY,\n\n    -- The name, trigram-indexed for fast e.g. regexp filtering.\n    name citext NOT NULL,\n\n    CONSTRAINT check_name_nonempty CHECK ((name OPERATOR(\u003c\u003e) ''::citext))\n);\n\n-- Enforce that names are unique.\nCREATE UNIQUE INDEX repo_names_name_unique_idx ON repo_names(name);\n\n-- Create trigram indexes for repository name filtering based on e.g. regexps.\nCREATE INDEX repo_names_name_trgm ON repo_names USING gin (lower((name)::text) gin_trgm_ops);\n\n\n-- Records arbitrary metadata about events. Stored in a separate table as it is often repeated\n-- for multiple events.\nCREATE TABLE metadata (\n    -- The metadata ID.\n    id bigserial NOT NULL PRIMARY KEY,\n\n    -- Metadata about this event, this can be any arbitrary JSON metadata which will be returned\n    -- when querying events, and can be filtered on and grouped using jsonb operators ?, ?\u0026, ?|,\n    -- and @\u003e. This should be small data only, primary use case is small lists such as:\n    --\n    --  {\"java_versions\": [...]}\n    --  {\"languages\":     [...]}\n    --  {\"pull_requests\": [...]}\n    --  {\"annotations\":   [...]}\n    --\n    metadata jsonb NOT NULL\n);\n\n-- Enforce that metadata is unique.\nCREATE UNIQUE INDEX metadata_metadata_unique_idx ON metadata(metadata);\n\n-- Index metadata to optimize WHERE clauses with jsonb ?, ?\u0026, ?|, and @\u003e operators.\nCREATE INDEX metadata_metadata_gin ON metadata USING GIN (metadata);\n\n-- Records events over time associated with a repository (or none, i.e. globally) where a single\n-- numerical value is going arbitrarily up and down.\n--\n-- Repository association is based on both repository ID and name. The ID can be used to refer to\n-- a specific repository, or lookup the current name of a repository after it has been e.g. renamed.\n-- The name can be used to refer to the name of the repository at the time of the event's creation,\n-- for example to trace the change in a gauge back to a repository being renamed.\nCREATE TABLE series_points (\n    -- A unique identifier for the series of data being recorded. This is not an ID from another\n    -- table, but rather just a unique identifier.\n    series_id integer,\n\n    -- The timestamp of the recorded event.\n    time TIMESTAMPTZ NOT NULL,\n\n    -- The floating point value at the time of the event.\n    value double precision NOT NULL,\n\n    -- Associated metadata for this event, if any.\n    metadata_id integer,\n\n    -- The repository ID (from the main application DB) at the time the event was created. Note\n    -- that the repository may no longer exist / be valid at query time, however.\n    --\n    -- null if the event was not for a single repository (i.e. a global gauge).\n    repo_id integer,\n\n    -- The most recently known name for the repository, updated periodically to account for e.g.\n    -- repository renames. If the repository was deleted, this is still the most recently known\n    -- name.\n    --\n    -- null if the event was not for a single repository (i.e. a global gauge).\n    repo_name_id integer,\n\n    -- The repository name as it was known at the time the event was created. It may have been renamed\n    -- since.\n    original_repo_name_id integer,\n\n    -- Ensure if one repo association field is specified, all are.\n    CONSTRAINT check_repo_fields_specifity CHECK (\n        ((repo_id IS NULL) AND (repo_name_id IS NULL) AND (original_repo_name_id IS NULL))\n        OR\n        ((repo_id IS NOT NULL) AND (repo_name_id IS NOT NULL) AND (original_repo_name_id IS NOT NULL))\n    ),\n\n    FOREIGN KEY (metadata_id) REFERENCES metadata(id) ON DELETE CASCADE DEFERRABLE,\n    FOREIGN KEY (repo_name_id) REFERENCES repo_names(id) ON DELETE CASCADE DEFERRABLE,\n    FOREIGN KEY (original_repo_name_id) REFERENCES repo_names(id) ON DELETE CASCADE DEFERRABLE\n);\n\n-- Create btree indexes for repository filtering.\nCREATE INDEX series_points_repo_id_btree ON series_points USING btree (repo_id);\nCREATE INDEX series_points_repo_name_id_btree ON series_points USING btree (repo_name_id);\nCREATE INDEX series_points_original_repo_name_id_btree ON series_points USING btree (original_repo_name_id);",
				"DownQuery": "DROP TABLE IF EXISTS series_points;\nDROP TABLE IF EXISTS repo_names;\nDROP TABLE IF EXISTS metadata;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000000
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000002,
				"Name": "comments",
				"UpQuery": "COMMENT ON TABLE repo_names IS 'Records repository names, both historical and present, using a unique repository _name_ ID (unrelated to the repository ID.)';\nCOMMENT ON COLUMN repo_names.id IS 'The repository _name_ ID.';\nCOMMENT ON COLUMN repo_names.name IS 'The repository name string, with unique constraint for table entry deduplication and trigram index for e.g. regex filtering.';\n\nCOMMENT ON TABLE metadata IS 'Records arbitrary metadata about events. Stored in a separate table as it is often repeated for multiple events.';\nCOMMENT ON COLUMN metadata.id IS 'The metadata ID.';\nCOMMENT ON COLUMN metadata.metadata IS 'Metadata about some event, this can be any arbitrary JSON emtadata which will be returned when querying events, and can be filtered on and grouped using jsonb operators ?, ?\u0026, ?|, and @\u003e. This should be small data only.';\n\nCOMMENT ON TABLE series_points IS 'Records events over time associated with a repository (or none, i.e. globally) where a single numerical value is going arbitrarily up and down.  Repository association is based on both repository ID and name. The ID can be used to refer toa specific repository, or lookup the current name of a repository after it has been e.g. renamed. The name can be used to refer to the name of the repository at the time of the events creation, for example to trace the change in a gauge back to a repository being renamed.';\nCOMMENT ON COLUMN series_points.series_id IS 'A unique identifier for the series of data being recorded. This is not an ID from another table, but rather just a unique identifier.';\nCOMMENT ON COLUMN series_points.time IS 'The timestamp of the recorded event.';\nCOMMENT ON COLUMN series_points.value IS 'The floating point value at the time of the event.';\nCOMMENT ON COLUMN series_points.metadata_id IS 'Associated metadata for this event, if any.';\nCOMMENT ON COLUMN series_points.repo_id IS 'The repository ID (from the main application DB) at the time the event was created. Note that the repository may no longer exist / be valid at query time, however.';\nCOMMENT ON COLUMN series_points.repo_name_id IS 'The most recently known name for the repository, updated periodically to account for e.g. repository renames. If the repository was deleted, this is still the most recently known name.  null if the event was not for a single repository (i.e. a global gauge).';\nCOMMENT ON COLUMN series_points.original_repo_name_id IS 'The repository name as it was known at the time the event was created. It may have been renamed since.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000001
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000003,
				"Name": "insights series id",
				"UpQuery": "DELETE FROM series_points; -- affects dev environments only, others never had data in this table.\nALTER TABLE series_points ALTER COLUMN series_id TYPE text;\nALTER TABLE series_points ALTER COLUMN series_id SET NOT NULL;\n\n-- Give series_id a btree index since we'll be filtering on it very frequently.\nCREATE INDEX series_points_series_id_btree ON series_points USING btree (series_id);",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000002
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000004,
				"Name": "no telemetry",
				"UpQuery": "-- This file is empty because it used to contain TimescaleDB specific migrations that have seen been deprecated.",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000003
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000005,
				"Name": "wipe data",
				"UpQuery": "-- We changed the default timeframe that the historical insights builder produces from:\n--\n-- 1 data point per week, for the last 52 weeks\n--\n-- To:\n--\n-- 1 data point per month, for the last 6 months\n--\n-- To avoid any confusion and just start fresh, we wipe all data here for now. This isn't\n-- needed in general when making this change, but is useful in this specific situation.\nDELETE FROM series_points;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000004
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000006,
				"Name": "commit index",
				"UpQuery": "CREATE TABLE commit_index\n(\n\tcommitted_at TIMESTAMPTZ NOT NULL,\n\trepo_id INT NOT NULL,\n\tcommit_bytea bytea NOT NULL,\n\n\tPRIMARY KEY (committed_at, repo_id, commit_bytea)\n);\n\nCREATE INDEX commit_index_repo_id_idx ON commit_index USING btree (repo_id, committed_at);\n\nCREATE TABLE commit_index_metadata\n(\n    repo_id INT NOT NULL PRIMARY KEY,\n    enabled BOOLEAN NOT NULL DEFAULT 'y',\n    last_indexed_at TIMESTAMPTZ NOT NULL DEFAULT '1900-01-01'\n);",
				"DownQuery": "DROP TABLE IF EXISTS commit_index;\nDROP TABLE IF EXISTS commit_index_metadata;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000005
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000007,
				"Name": "series points index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS series_points_series_id_repo_id_time_idx ON series_points (series_id, repo_id, time);",
				"DownQuery": "DROP INDEX IF EXISTS series_points_series_id_repo_id_time_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000006
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000008,
				"Name": "insights views series",
				"UpQuery": "CREATE TABLE insight_series\n(\n    id                      SERIAL    NOT NULL PRIMARY KEY,\n    series_id               TEXT      NOT NULL,\n    query                   TEXT      NOT NULL,\n    created_at              TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    oldest_historical_at    TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP - INTERVAL '1 year',\n    last_recorded_at        TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP - INTERVAL '10 year',\n    next_recording_after    TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    recording_interval_days INT       NOT NULL DEFAULT 1,\n    deleted_at              TIMESTAMP\n);\n\ncomment on table insight_series is 'Data series that comprise code insights.';\n\ncomment on column insight_series.id is 'Primary key ID of this series';\ncomment on column insight_series.series_id is 'Unique Series ID represents a globally unique identifier for this series.';\ncomment on column insight_series.query is 'Query string that generates this series';\ncomment on column insight_series.created_at is 'Timestamp when this series was created';\ncomment on column insight_series.oldest_historical_at is 'Timestamp representing the oldest point of which this series is backfilled.';\ncomment on column insight_series.last_recorded_at is 'Timestamp when this series was last recorded (non-historical).';\ncomment on column insight_series.next_recording_after is 'Timestamp when this series should next record (non-historical).';\ncomment on column insight_series.recording_interval_days is 'Number of days that should pass between recordings (non-historical)';\ncomment on column insight_series.deleted_at is 'Timestamp of a soft-delete of this row.';\n\nCREATE UNIQUE INDEX insight_series_series_id_unique_idx ON insight_series (series_id);\nCREATE INDEX insight_series_deleted_at_idx ON insight_series (deleted_at);\nCREATE INDEX insight_series_next_recording_after_idx ON insight_series (next_recording_after);\n\nCREATE TABLE insight_view\n(\n    id          SERIAL NOT NULL PRIMARY KEY,\n    title       TEXT,\n    description TEXT,\n    unique_id   TEXT NOT NULL\n);\n\ncomment on table insight_view is 'Views for insight data series. An insight view is an abstraction on top of an insight data series that allows for lightweight modifications to filters or metadata without regenerating the underlying series.';\n\ncomment on column insight_view.id is 'Primary key ID for this view';\ncomment on column insight_view.title is 'Title of the view. This may render in a chart depending on the view type.';\ncomment on column insight_view.description is 'Description of the view. This may render in a chart depending on the view type.';\ncomment on column insight_view.unique_id is 'Globally unique identifier for this view that is externally referencable.';\n\nCREATE UNIQUE INDEX insight_view_unique_id_unique_idx ON insight_view (unique_id);\n\nCREATE TABLE insight_view_series\n(\n    insight_view_id   INT NOT NULL,\n    insight_series_id INT NOT NULL,\n    label             TEXT,\n    stroke            TEXT,\n    PRIMARY KEY (insight_view_id, insight_series_id)\n);\n\ncomment on table insight_view_series is 'Join table to correlate data series with insight views';\ncomment on column insight_view_series.insight_view_id is 'Foreign key to insight view.';\ncomment on column insight_view_series.insight_series_id is 'Foreign key to insight data series.';\ncomment on column insight_view_series.label is 'Label text for this data series. This may render in a chart depending on the view type.';\ncomment on column insight_view_series.stroke is 'Stroke color metadata for this data series. This may render in a chart depending on the view type.';\n\nALTER TABLE insight_view_series\n    ADD FOREIGN KEY (insight_view_id) REFERENCES insight_view (id);\n\nALTER TABLE insight_view_series\n    ADD FOREIGN KEY (insight_series_id) REFERENCES insight_series (id);",
				"DownQuery": "DROP TABLE IF EXISTS insight_view_series;\nDROP TABLE IF EXISTS insight_view;\nDROP TABLE IF EXISTS insight_series;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000007
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000009,
				"Name": "backfiller state",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insight_series ADD COLUMN backfill_queued_at TIMESTAMP;\nCOMMENT ON COLUMN insight_series.series_id IS\n    'Timestamp that this series completed a full repository iteration for backfill. This flag has limited semantic value, and only means it tried to queue up queries for each repository. It does not guarantee success on those queries.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insight_series DROP COLUMN IF EXISTS backfill_queued_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000008
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000010,
				"Name": "series points reset",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\n-- Prior to 3.31 this table stored points in two formats. Historical points were stored in a compressed\n-- format where samples were only recorded if the underlying repository changed. After 3.31 we are changing\n-- the semantic to require full vectors for each data point. To avoid any incompatibilities and to prepare for beta\n-- we are going to reset the stored data and all of the underlying Timescale chunks back to zero.\n-- Note: This data is by design reproducible, so there is no risk of permanent data loss here. Any and all data\n-- will be queued and regenerated as soon as code insights starts up.\n\n-- Clean up the remaining records if any exist.\nTRUNCATE series_points CASCADE;\n\n-- There is the possibility that the commit index has fallen out of sync with the primary postgres database in 3.30 due\n-- to a data corruption issue. We will regenerate it to be sure it is healthy for beta.\nTRUNCATE commit_index;\nTRUNCATE commit_index_metadata;\n\n-- Update all of the underlying insights that may have been synced to reset metadata and rebuild their data.\nupdate insight_series set created_at = current_timestamp, backfill_queued_at = null, next_recording_after = date_trunc('month', current_date) + interval '1 month';\nCOMMIT;\n\n-- This file used to contain TimescaleDB specific migrations that have seen been deprecated.",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000009
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000011,
				"Name": "insights dirty queries",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE insight_dirty_queries\n(\n    id                SERIAL NOT NULL,\n    insight_series_id INT,\n    query             TEXT NOT NULL,\n    dirty_at          TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    reason            TEXT NOT NULL,\n    for_time          TIMESTAMP NOT NULL,\n    PRIMARY KEY (id),\n    FOREIGN KEY (insight_series_id) REFERENCES insight_series(id)\n);\n\nCREATE INDEX insight_dirty_queries_insight_series_id_fk_idx ON insight_dirty_queries (insight_series_id);\n\nCOMMENT ON TABLE insight_dirty_queries IS 'Stores queries that were unsuccessful or otherwise flagged as incomplete or incorrect.';\n\nCOMMENT ON COLUMN insight_dirty_queries.query IS 'Sourcegraph query string that was executed.';\nCOMMENT ON COLUMN insight_dirty_queries.dirty_at IS 'Timestamp when this query was marked dirty.';\nCOMMENT ON COLUMN insight_dirty_queries.reason IS 'Human readable string indicating the reason the query was marked dirty.';\nCOMMENT ON COLUMN insight_dirty_queries.for_time IS 'Timestamp for which the original data point was recorded or intended to be recorded.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\nDROP TABLE IF EXISTS insight_dirty_queries;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000010
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000012,
				"Name": "insights snapshots",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE series_points_snapshots\n(\n    LIKE series_points INCLUDING DEFAULTS INCLUDING CONSTRAINTS INCLUDING INDEXES\n);\n\nCOMMENT ON TABLE series_points_snapshots is 'Stores ephemeral snapshot data of insight recordings.';\n\nalter table insight_series\n    add last_snapshot_at timestamp default (CURRENT_TIMESTAMP - '10 years'::interval);\n\nalter table insight_series\n    add next_snapshot_after timestamp default CURRENT_TIMESTAMP;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE series_points_snapshots;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000011
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000013,
				"Name": "insights view grants",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insight_view_grants\n(\n    id              SERIAL\n        CONSTRAINT insight_view_grants_pk\n            PRIMARY KEY,\n    insight_view_id INTEGER NOT NULL\n        CONSTRAINT insight_view_grants_insight_view_id_fk\n            REFERENCES insight_view\n            ON DELETE CASCADE, -- These grants only have meaning in the context of a parent view.\n    user_id         INTEGER,\n    org_id          INTEGER,\n    global          BOOLEAN\n);\n\nCOMMENT ON TABLE insight_view_grants IS 'Permission grants for insight views. Each row should represent a unique principal (user, org, etc).';\nCOMMENT ON COLUMN insight_view_grants.user_id IS 'User ID that that receives this grant.';\nCOMMENT ON COLUMN insight_view_grants.org_id IS 'Org ID that that receives this grant.';\nCOMMENT ON COLUMN insight_view_grants.global IS 'Grant that does not belong to any specific principal and is granted to all users.';\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_insight_view_id_index\n    ON insight_view_grants (insight_view_id);\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_user_id_idx\n    ON insight_view_grants (user_id);\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_org_id_idx\n    ON insight_view_grants (org_id);\n\nCREATE INDEX IF NOT EXISTS insight_view_grants_global_idx\n    ON insight_view_grants (global) WHERE global IS TRUE;\n\n\n-- This series join table is completely dependent on the existence of a parent view. So to simplify db operations\n-- and avoid dangling rows, adding cascade deletes to the insight view FK.\nALTER TABLE insight_view_series\n    DROP CONSTRAINT IF EXISTS insight_view_series_insight_view_id_fkey;\n\nALTER TABLE insight_view_series\n    ADD CONSTRAINT insight_view_series_insight_view_id_fkey\n        FOREIGN KEY (insight_view_id) REFERENCES insight_view\n            ON DELETE CASCADE;",
				"DownQuery": "DROP TABLE IF EXISTS insight_view_grants;\n\nALTER TABLE insight_view_series\n    DROP CONSTRAINT IF EXISTS insight_view_series_insight_view_id_fkey;\n\nALTER TABLE insight_view_series\n    ADD CONSTRAINT insight_view_series_insight_view_id_fkey\n        FOREIGN KEY (insight_view_id) REFERENCES insight_view;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000012
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000014,
				"Name": "dashboards",
				"UpQuery": "CREATE TABLE IF NOT EXISTS dashboard\n(\n    id                 SERIAL                  NOT NULL CONSTRAINT dashboard_pk PRIMARY KEY,\n    title              TEXT,\n    created_at         TIMESTAMP DEFAULT NOW() NOT NULL,\n    created_by_user_id INT,\n    last_updated_at    TIMESTAMP DEFAULT NOW() NOT NULL,\n    deleted_at         TIMESTAMP\n);\n\nCOMMENT ON TABLE dashboard IS 'Metadata for dashboards of insights';\n\nCOMMENT ON COLUMN dashboard.title IS 'Title of the dashboard';\n\nCOMMENT ON COLUMN dashboard.created_at IS 'Timestamp the dashboard was initially created.';\n\nCOMMENT ON COLUMN dashboard.created_by_user_id IS 'User that created the dashboard, if available.';\n\nCOMMENT ON COLUMN dashboard.last_updated_at IS 'Time the dashboard was last updated, either metadata or insights.';\n\nCOMMENT ON COLUMN dashboard.deleted_at IS 'Set to the time the dashboard was soft deleted.';\n\n\n\nCREATE TABLE IF NOT EXISTS dashboard_grants\n(\n    id           SERIAL CONSTRAINT dashboard_grants_pk PRIMARY KEY,\n    dashboard_id INTEGER NOT NULL CONSTRAINT dashboard_grants_dashboard_id_fk REFERENCES dashboard ON DELETE CASCADE, -- These grants only have meaning in the context of a parent dashboard.\n    user_id      INTEGER,\n    org_id       INTEGER,\n    global       BOOLEAN\n);\n\nCOMMENT ON TABLE dashboard_grants IS 'Permission grants for dashboards. Each row should represent a unique principal (user, org, etc).';\nCOMMENT ON COLUMN dashboard_grants.user_id IS 'User ID that that receives this grant.';\nCOMMENT ON COLUMN dashboard_grants.org_id IS 'Org ID that that receives this grant.';\nCOMMENT ON COLUMN dashboard_grants.global IS 'Grant that does not belong to any specific principal and is granted to all users.';\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_dashboard_id_index\n    ON dashboard_grants (dashboard_id);\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_user_id_idx\n    ON dashboard_grants (user_id);\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_org_id_idx\n    ON dashboard_grants (org_id);\n\nCREATE INDEX IF NOT EXISTS dashboard_grants_global_idx\n    ON dashboard_grants (global) WHERE global IS TRUE;\n\nCREATE TABLE dashboard_insight_view\n(\n    id              SERIAL NOT NULL CONSTRAINT dashboard_insight_view_pk PRIMARY KEY,\n    dashboard_id    INT    NOT NULL CONSTRAINT dashboard_insight_view_dashboard_id_fk REFERENCES dashboard (id) ON DELETE CASCADE,\n    insight_view_id INT    NOT NULL CONSTRAINT dashboard_insight_view_insight_view_id_fk REFERENCES insight_view (id) ON DELETE CASCADE\n);\n\nCREATE INDEX IF NOT EXISTS dashboard_insight_view_insight_view_id_fk_idx ON dashboard_insight_view (insight_view_id);\nCREATE INDEX IF NOT EXISTS dashboard_insight_view_dashboard_id_fk_idx ON dashboard_insight_view (dashboard_id);",
				"DownQuery": "DROP TABLE IF EXISTS dashboard_grants;\nDROP TABLE IF EXISTS dashboard;\nDROP TABLE IF EXISTS dashboard_insight_view;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000013
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000015,
				"Name": "dashboard save",
				"UpQuery": "ALTER TABLE dashboard ADD COLUMN IF NOT EXISTS save BOOLEAN NOT NULL DEFAULT FALSE;\n\nCOMMENT ON COLUMN dashboard.save IS 'TEMPORARY Do not delete this dashboard when migrating settings.';",
				"DownQuery": "ALTER TABLE dashboard\nDROP COLUMN IF EXISTS save;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000016,
				"Name": "unique insights on dashboard",
				"UpQuery": "-- Remove any already existing duplicates.\nDELETE FROM\n    dashboard_insight_view a\n        USING dashboard_insight_view b\nWHERE\n\ta.id \u003e b.id\n    AND a.dashboard_id = b.dashboard_id\n    AND a.insight_view_id = b.insight_view_id;\n\nALTER TABLE dashboard_insight_view\nADD CONSTRAINT unique_dashboard_id_insight_view_id\nUNIQUE (dashboard_id, insight_view_id);",
				"DownQuery": "ALTER TABLE dashboard_insight_view\nDROP CONSTRAINT unique_dashboard_id_insight_view_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000015
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000017,
				"Name": "insight api",
				"UpQuery": "CREATE TYPE time_unit AS ENUM ('HOUR', 'DAY', 'WEEK', 'MONTH', 'YEAR');\nALTER TABLE insight_series\n    DROP COLUMN IF EXISTS recording_interval_days,\n    ADD COLUMN repositories TEXT[],\n    ADD COLUMN sample_interval_unit time_unit,\n    ADD COLUMN sample_interval_value int\n;\n\nALTER TABLE insight_view\n    ADD COLUMN default_filter_include_repo_regex text,\n    ADD COLUMN default_filter_exclude_repo_regex text\n;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insight_series\n    DROP COLUMN IF EXISTS repositories,\n    DROP COLUMN IF EXISTS sample_interval_unit,\n    DROP COLUMN IF EXISTS sample_interval_value,\n    ADD COLUMN IF NOT EXISTS recording_interval_days int;\n\nALTER TABLE insight_view\n    DROP COLUMN IF EXISTS default_filter_include_repo_regex,\n    DROP COLUMN IF EXISTS default_filter_exclude_repo_regex;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000016
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000018,
				"Name": "interval defaults",
				"UpQuery": "UPDATE insight_series\nSET sample_interval_unit = 'MONTH'\nWHERE sample_interval_unit IS NULL;\n\nUPDATE insight_series\nSET sample_interval_value = 1\nWHERE sample_interval_value IS NULL;\n\nALTER TABLE insight_series\n    ALTER COLUMN sample_interval_unit SET DEFAULT 'MONTH',\n    ALTER COLUMN sample_interval_unit SET NOT NULL,\n    ALTER COLUMN sample_interval_value SET DEFAULT '1',\n    ALTER COLUMN sample_interval_value SET NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series\n    ALTER COLUMN sample_interval_unit DROP DEFAULT,\n    ALTER COLUMN sample_interval_unit DROP NOT NULL,\n    ALTER COLUMN sample_interval_value DROP DEFAULT,\n    ALTER COLUMN sample_interval_value DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000017
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000019,
				"Name": "other threshold",
				"UpQuery": "ALTER TABLE insight_view\n    ADD COLUMN IF NOT EXISTS other_threshold FLOAT4;\n\nCOMMENT ON COLUMN insight_view.other_threshold IS 'Percent threshold for grouping series under \"other\"';",
				"DownQuery": "ALTER TABLE insight_view\nDROP COLUMN IF EXISTS other_threshold;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000018
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000020,
				"Name": "presentation type",
				"UpQuery": "CREATE TYPE presentation_type_enum AS ENUM ('LINE', 'PIE');\nALTER TABLE insight_view\n    ADD COLUMN IF NOT EXISTS presentation_type presentation_type_enum NOT NULL DEFAULT 'LINE',\n    ALTER COLUMN other_threshold type FLOAT8; -- Changing this because the GraphQL float type is a float64.\n\nCOMMENT ON COLUMN insight_view.presentation_type IS 'The basic presentation type for the insight view. (e.g Line, Pie, etc.)';",
				"DownQuery": "ALTER TABLE insight_view\n    ALTER COLUMN other_threshold TYPE FLOAT4,\n    DROP COLUMN IF EXISTS presentation_type;\n\nDROP TYPE presentation_type_enum;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000019
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000021,
				"Name": "add dirty query cascade",
				"UpQuery": "ALTER TABLE insight_dirty_queries\n    DROP CONSTRAINT insight_dirty_queries_insight_series_id_fkey,\n    ADD CONSTRAINT insight_dirty_queries_insight_series_id_fkey FOREIGN KEY (insight_series_id) REFERENCES insight_series (id) ON DELETE CASCADE;",
				"DownQuery": "ALTER TABLE insight_dirty_queries\n    DROP CONSTRAINT insight_dirty_queries_insight_series_id_fkey,\n    ADD CONSTRAINT insight_dirty_queries_insight_series_id_fkey FOREIGN KEY (insight_series_id) REFERENCES insight_series (id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000020
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000022,
				"Name": "settings migration wipe definition tables",
				"UpQuery": "-- This will reset the state of the insight definition tables to empty so that the OOB migration can fully\n-- replicate and migrate all of the insights from settings without any duplication.\n\nTRUNCATE insight_view CASCADE;\nTRUNCATE insight_series CASCADE;\nTRUNCATE dashboard CASCADE;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000021
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000023,
				"Name": "generate from query",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series\n    ADD COLUMN IF NOT EXISTS generated_from_capture_groups BOOL NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series\n    DROP COLUMN IF EXISTS generated_from_capture_groups;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000022
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000024,
				"Name": "insight series expanded type info",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series\n    ADD COLUMN IF NOT EXISTS generation_method TEXT,\n    ADD COLUMN IF NOT EXISTS just_in_time      BOOL;\n\nCOMMENT ON COLUMN insight_series.generation_method is 'Specifies the execution method for how this series is generated. This helps the system understand how to generate the time series data.';\nCOMMENT ON COLUMN insight_series.just_in_time is 'Specifies if the series should be resolved just in time at query time, or recorded in background processing.';\n\n-- This is just formalizing some of the logic that exists. It seems a little brittle, but that's why we are doing this now :)\nUPDATE insight_series\nSET generation_method =\n        CASE\n            WHEN (sample_interval_unit = 'MONTH' AND sample_interval_value = 0) THEN 'language-stats'\n            WHEN (generated_from_capture_groups IS TRUE) THEN 'search-compute'\n            ELSE 'search'\n            END;\n\nALTER TABLE IF EXISTS insight_series\n    ALTER COLUMN generation_method SET NOT NULL;\n\n-- This is using some slightly funky logic to ensure we are setting the just_in_time flag appropriately based on any existing series.\nUPDATE insight_series\nSET just_in_time =\n        CASE\n            WHEN (generation_method = 'search' AND (CARDINALITY(repositories) = 0 OR repositories IS NULL)) THEN FALSE\n            WHEN (generation_method = 'search' AND (CARDINALITY(repositories) \u003e 0)) THEN TRUE\n            WHEN (generation_method = 'language-stats' AND (CARDINALITY(repositories) \u003e 0)) THEN TRUE\n            WHEN (generation_method = 'search-compute' AND (CARDINALITY(repositories) = 0 OR repositories IS NULL))\n                THEN FALSE\n            WHEN (generation_method = 'search-compute' AND (CARDINALITY(repositories) \u003e 0)) THEN TRUE\n            ELSE FALSE\n            END;\n\nALTER TABLE IF EXISTS insight_series\n    ALTER COLUMN just_in_time SET NOT NULL,\n    ALTER COLUMN just_in_time SET DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE insight_series\n    DROP COLUMN IF EXISTS generation_method;\nALTER TABLE insight_series\n    DROP COLUMN IF EXISTS just_in_time;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000023
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000025,
				"Name": "captured values series points",
				"UpQuery": "ALTER TABLE IF EXISTS series_points\n    ADD COLUMN IF NOT EXISTS capture TEXT;\n\nALTER TABLE IF EXISTS series_points_snapshots\n    ADD COLUMN IF NOT EXISTS capture TEXT;",
				"DownQuery": "ALTER TABLE IF EXISTS series_points\n    DROP COLUMN IF EXISTS capture;\n\nALTER TABLE IF EXISTS series_points_snapshots\n    DROP COLUMN IF EXISTS capture;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000024
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000026,
				"Name": "commit indexer debug fields",
				"UpQuery": "ALTER TABLE IF EXISTS commit_index\n    ADD COLUMN IF NOT EXISTS indexed_at  TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    ADD COLUMN IF NOT EXISTS debug_field TEXT;",
				"DownQuery": "ALTER TABLE IF EXISTS commit_index\n    DROP COLUMN IF EXISTS indexed_at,\n    DROP COLUMN IF EXISTS debug_field;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000025
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000027,
				"Name": "deprecate_timescale_tables",
				"UpQuery": "DO\n$$\n    DECLARE\n        tsdb_ext PG_EXTENSION%ROWTYPE;\n    BEGIN\n        -- To ensure we only excute this once (in case of manual executions) we will check if the TimescaleDB extension exists, and only if so\n        -- perform this table migration\n        SELECT * FROM pg_extension WHERE extname = 'timescaledb' LIMIT 1 INTO tsdb_ext;\n        IF NOT found THEN\n        ELSE\n            -- Perform a table swap - create a new table and rename the hypertable\n            CREATE TABLE series_points_vanilla\n            (\n                LIKE series_points INCLUDING ALL\n            );\n            ALTER    TABLE series_points\n                RENAME TO series_points_timescale;\n            ALTER TABLE series_points_vanilla\n                RENAME TO series_points;\n\n            -- Copy all of the data and insert into the new table.\n            INSERT INTO series_points (SELECT * FROM series_points_timescale);\n\n            -- Drop the old hypertable (the extension will propagate and drop all of the hypertable stuff)\n            DROP TABLE series_points_timescale CASCADE;\n\n            -- Last, remove the extension\n            DROP EXTENSION IF EXISTS timescaledb;\n        END IF;\n    END\n$$;",
				"DownQuery": "-- Nothing to do, actually. Even if we go backwards we aren't going to restore the Timescale tables.",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000026
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646761143,
				"Name": "frozen_insights",
				"UpQuery": "ALTER TABLE IF EXISTS insight_view ADD COLUMN IF NOT EXISTS is_frozen BOOL NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_view DROP COLUMN IF EXISTS is_frozen;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000027
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1647894746,
				"Name": "dashboard_type",
				"UpQuery": "ALTER TABLE IF EXISTS dashboard ADD COLUMN IF NOT EXISTS type TEXT DEFAULT 'standard'::text NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS dashboard DROP COLUMN IF EXISTS type;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646761143
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649801281,
				"Name": "context_filters",
				"UpQuery": "ALTER TABLE IF EXISTS insight_view ADD COLUMN IF NOT EXISTS default_filter_search_contexts TEXT[];",
				"DownQuery": "ALTER TABLE IF EXISTS insight_view DROP COLUMN IF EXISTS default_filter_search_contexts;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1647894746
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1651021000,
				"Name": "sort_series",
				"UpQuery": "DO $$\nBEGIN\n    CREATE TYPE series_sort_mode_enum AS ENUM (\n        'RESULT_COUNT',\n        'LEXICOGRAPHICAL',\n        'DATE_ADDED'\n    );\nEXCEPTION\n    WHEN duplicate_object THEN null;\nEND $$;\n\nDO $$\nBEGIN\n    CREATE TYPE series_sort_direction_enum AS ENUM (\n        'ASC',\n        'DESC'\n    );\nEXCEPTION\n    WHEN duplicate_object THEN null;\nEND $$;\n\nALTER TABLE IF EXISTS insight_view\n    ADD COLUMN IF NOT EXISTS series_sort_mode series_sort_mode_enum,\n    ADD COLUMN IF NOT EXISTS series_sort_direction series_sort_direction_enum,\n    ADD COLUMN IF NOT EXISTS series_limit INT;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_view\n    DROP COLUMN IF EXISTS series_sort_mode,\n    DROP COLUMN IF EXISTS series_sort_direction,\n    DROP COLUMN IF EXISTS series_limit;\n\nDROP TYPE IF EXISTS series_sort_mode_enum;\nDROP TYPE IF EXISTS series_sort_direction_enum;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649801281
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652289966,
				"Name": "deprecate-search-stream-generation-method",
				"UpQuery": "UPDATE insight_series\n    SET generation_method = 'search'\n    WHERE generation_method = 'search-stream';",
				"DownQuery": "-- Update cannot be reverted, but this has minimal impact.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649801281
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1656517037,
				"Name": "group_by",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series ADD COLUMN IF NOT EXISTS group_by TEXT;",
				"DownQuery": "ALTER TABLE IF EXISTS insight_series DROP COLUMN IF EXISTS group_by;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1651021000,
					1652289966
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1656608833,
				"Name": "track_backfill_attempts",
				"UpQuery": "-- Perform migration here.\n--\nALTER TABLE IF EXISTS insight_series\n    ADD COLUMN IF NOT EXISTS backfill_attempts INT NOT NULL DEFAULT 0;",
				"DownQuery": "-- Undo the changes made in the up migration\nALTER TABLE IF EXISTS insight_series DROP COLUMN IF EXISTS backfill_attempts;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1651021000,
					1652289966
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659572248,
				"Name": "refresh_scoped_insights",
				"UpQuery": "ALTER TABLE IF EXISTS insight_series\n    ADD COLUMN IF NOT EXISTS needs_migration bool;\n\n\nupdate insight_series\nset needs_migration = true\nwhere cardinality(repositories) \u003e 0 AND generation_method in ('search', 'search-compute') AND needs_migration is NULL;",
				"DownQuery": "-- take no action on down so that the next up will not trigger another refreshing of series data.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1656517037,
					1656608833
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			}
		],
		"BoundsByRev": {
			"v3.29.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000006
				]
			},
			"v3.30.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000008
				]
			},
			"v3.31.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000011
				]
			},
			"v3.32.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000013
				]
			},
			"v3.33.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000016
				]
			},
			"v3.34.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000021
				]
			},
			"v3.35.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000024
				]
			},
			"v3.36.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000025
				]
			},
			"v3.37.0": {
				"RootID": -1000000000,
				"LeafIDs": [
					1000000027
				]
			},
			"v3.38.0": {
				"RootID": 1000000020,
				"LeafIDs": [
					1646761143
				]
			},
			"v3.39.0": {
				"RootID": 1000000020,
				"LeafIDs": [
					1649801281
				]
			},
			"v3.40.0": {
				"RootID": 1000000020,
				"LeafIDs": [
					1652289966
				]
			},
			"v3.41.0": {
				"RootID": 1000000026,
				"LeafIDs": [
					1651021000,
					1652289966
				]
			},
			"v3.42.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1656517037,
					1656608833
				]
			},
			"v3.43.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1659572248
				]
			},
			"v4.0.0": {
				"RootID": 1000000027,
				"LeafIDs": [
					1659572248
				]
			}
		}
	},
	"codeintel": {
		"Definitions": [
			{
				"ID": -1000000005,
				"Name": "squashed migrations (privileged)",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n\nCOMMENT ON EXTENSION pg_stat_statements IS 'track execution statistics of all SQL statements executed';",
				"DownQuery": "",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": null,
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000005,
				"Name": "squashed migrations",
				"UpQuery": "CREATE TABLE lsif_data_definitions (\n    dump_id integer NOT NULL,\n    scheme text NOT NULL,\n    identifier text NOT NULL,\n    data bytea\n);\n\nCOMMENT ON TABLE lsif_data_definitions IS 'Associates (document, range) pairs with the import monikers attached to the range.';\n\nCOMMENT ON COLUMN lsif_data_definitions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_definitions.scheme IS 'The moniker scheme.';\n\nCOMMENT ON COLUMN lsif_data_definitions.identifier IS 'The moniker identifier.';\n\nCOMMENT ON COLUMN lsif_data_definitions.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/lsifstore/types.go#L100:6) types.';\n\nCREATE TABLE lsif_data_documents (\n    dump_id integer NOT NULL,\n    path text NOT NULL,\n    data bytea,\n    schema_version integer NOT NULL,\n    num_diagnostics integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_data_documents IS 'Stores reference, hover text, moniker, and diagnostic data about a particular text document witin a dump.';\n\nCOMMENT ON COLUMN lsif_data_documents.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_documents.path IS 'The path of the text document relative to the associated dump root.';\n\nCOMMENT ON COLUMN lsif_data_documents.data IS 'A gob-encoded payload conforming to the [DocumentData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/lsifstore/types.go#L13:6) type.';\n\nCOMMENT ON COLUMN lsif_data_documents.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\n\nCOMMENT ON COLUMN lsif_data_documents.num_diagnostics IS 'The number of diagnostics stored in the data field.';\n\nCREATE TABLE lsif_data_metadata (\n    dump_id integer NOT NULL,\n    num_result_chunks integer\n);\n\nCOMMENT ON TABLE lsif_data_metadata IS 'Stores the number of result chunks associated with a dump.';\n\nCOMMENT ON COLUMN lsif_data_metadata.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_metadata.num_result_chunks IS 'A bound of populated indexes in the lsif_data_result_chunks table for the associated dump. This value is used to hash identifiers into the result chunk index to which they belong.';\n\nCREATE TABLE lsif_data_references (\n    dump_id integer NOT NULL,\n    scheme text NOT NULL,\n    identifier text NOT NULL,\n    data bytea\n);\n\nCOMMENT ON TABLE lsif_data_references IS 'Associates (document, range) pairs with the export monikers attached to the range.';\n\nCOMMENT ON COLUMN lsif_data_references.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_references.scheme IS 'The moniker scheme.';\n\nCOMMENT ON COLUMN lsif_data_references.identifier IS 'The moniker identifier.';\n\nCOMMENT ON COLUMN lsif_data_references.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/lsifstore/types.go#L100:6) types.';\n\nCREATE TABLE lsif_data_result_chunks (\n    dump_id integer NOT NULL,\n    idx integer NOT NULL,\n    data bytea\n);\n\nCOMMENT ON TABLE lsif_data_result_chunks IS 'Associates result set identifiers with the (document path, range identifier) pairs that compose the set.';\n\nCOMMENT ON COLUMN lsif_data_result_chunks.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\n\nCOMMENT ON COLUMN lsif_data_result_chunks.idx IS 'The unique result chunk index within the associated dump. Every result set identifier present should hash to this index (modulo lsif_data_metadata.num_result_chunks).';\n\nCOMMENT ON COLUMN lsif_data_result_chunks.data IS 'A gob-encoded payload conforming to the [ResultChunkData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/lsifstore/types.go#L70:6) type.';\n\nALTER TABLE ONLY lsif_data_definitions\n    ADD CONSTRAINT lsif_data_definitions_pkey PRIMARY KEY (dump_id, scheme, identifier);\n\nALTER TABLE ONLY lsif_data_documents\n    ADD CONSTRAINT lsif_data_documents_pkey PRIMARY KEY (dump_id, path);\n\nALTER TABLE ONLY lsif_data_metadata\n    ADD CONSTRAINT lsif_data_metadata_pkey PRIMARY KEY (dump_id);\n\nALTER TABLE ONLY lsif_data_references\n    ADD CONSTRAINT lsif_data_references_pkey PRIMARY KEY (dump_id, scheme, identifier);\n\nALTER TABLE ONLY lsif_data_result_chunks\n    ADD CONSTRAINT lsif_data_result_chunks_pkey PRIMARY KEY (dump_id, idx);",
				"DownQuery": "-- Nothing",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					-1000000005
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000006,
				"Name": "document versions",
				"UpQuery": "CREATE TABLE lsif_data_documents_schema_versions (\n    dump_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer\n);\nALTER TABLE lsif_data_documents_schema_versions ADD PRIMARY KEY (dump_id);\n\nCOMMENT ON TABLE lsif_data_documents_schema_versions IS 'Tracks the range of schema_versions for each upload in the lsif_data_documents table.';\nCOMMENT ON COLUMN lsif_data_documents_schema_versions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table.';\nCOMMENT ON COLUMN lsif_data_documents_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_documents.schema_version` where `lsif_data_documents.dump_id = dump_id`.';\nCOMMENT ON COLUMN lsif_data_documents_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_documents.schema_version` where `lsif_data_documents.dump_id = dump_id`.';\n\n-- Ensure that there is a lsif_data_documents_schema_versions record for each distinct dump_id in\n-- the lsif_data_documents table. We are denormalizing schema counts here, but unfortunately we\n-- have already started the migration and don't have a known schema version to put here. This will\n-- preclude us from doing a distinct on dump_id, or reading from the smaller metadata table.\n--\n-- We'll group these now. This query takes around 8 seconds on the Cloud database, so this should\n-- not cause a problem in any known instance.\nINSERT INTO lsif_data_documents_schema_versions\n    SELECT\n        dump_id,\n        min(schema_version) as min_schema_version,\n        max(schema_version) as max_schema_version\n    FROM\n        lsif_data_documents\n    GROUP BY\n        dump_id\n    ORDER BY\n        dump_id;\n\n-- On every insert into lsif_data_documents, we need to make sure we have an associated row in the\n-- lsif_data_documents_schema_versions table. We do not currently care about cleaning the table up\n-- (we will do this asynchronously).\n--\n-- We use FOR EACH STATEMENT here because we batch insert into this table. Running the trigger per\n-- statement rather than per row will save a ton of extra work. Running over batch inserts lets us\n-- do a GROUP BY on the new table and effectively upsert our new ranges.\n--\n-- Note that the only places where data is _modified_ in this database is during migrations, which\n-- will necessarily update this table's bounds for any migrated index records.\n\nCREATE OR REPLACE FUNCTION update_lsif_data_documents_schema_versions_insert() RETURNS trigger AS $$ BEGIN\n    INSERT INTO\n        lsif_data_documents_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(lsif_data_documents_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_documents_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$ LANGUAGE plpgsql;\n\nCREATE TRIGGER lsif_data_documents_schema_versions_insert\nAFTER INSERT ON lsif_data_documents REFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE PROCEDURE update_lsif_data_documents_schema_versions_insert();",
				"DownQuery": "DROP TABLE lsif_data_documents_schema_versions;\nDROP TRIGGER lsif_data_documents_schema_versions_insert ON lsif_data_documents;\nDROP FUNCTION update_lsif_data_documents_schema_versions_insert;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000005
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000007,
				"Name": "definitions locations counts",
				"UpQuery": "-- faster to supply default than manual update\nALTER TABLE lsif_data_definitions ADD COLUMN schema_version int DEFAULT 1 NOT NULL;\nALTER TABLE lsif_data_definitions ADD COLUMN num_locations int DEFAULT 0 NOT NULL;\n\n-- drop default after all existing columns have been set\nALTER TABLE lsif_data_definitions ALTER COLUMN schema_version DROP DEFAULT;\nALTER TABLE lsif_data_definitions ALTER COLUMN num_locations DROP DEFAULT;\n\nCOMMENT ON COLUMN lsif_data_definitions.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\nCOMMENT ON COLUMN lsif_data_definitions.num_locations IS 'The number of locations stored in the data field.';\n\nCREATE TABLE lsif_data_definitions_schema_versions (\n    dump_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer\n);\nALTER TABLE lsif_data_definitions_schema_versions ADD PRIMARY KEY (dump_id);\n\nCOMMENT ON TABLE lsif_data_definitions_schema_versions IS 'Tracks the range of schema_versions for each upload in the lsif_data_definitions table.';\nCOMMENT ON COLUMN lsif_data_definitions_schema_versions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table.';\nCOMMENT ON COLUMN lsif_data_definitions_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_definitions.schema_version` where `lsif_data_definitions.dump_id = dump_id`.';\nCOMMENT ON COLUMN lsif_data_definitions_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_definitions.schema_version` where `lsif_data_definitions.dump_id = dump_id`.';\n\n-- Ensure that there is a lsif_data_definitions_schema_versions record for each distinct dump_id in\n-- the lsif_data_definitions table. All definition versions in the database at this point necessarily\n-- have a schema_version of 1, so we can gather all of the dump ids quickly by scanning the metadata\n-- table. Grouping the definitions table directly would take too much time in a migration.\n\nINSERT INTO lsif_data_definitions_schema_versions\n    SELECT\n        dump_id,\n        1 AS min_schema_version,\n        1 AS max_schema_version\n    FROM\n        lsif_data_metadata\n    ORDER BY\n        lsif_data_metadata;\n\n-- On every insert into lsif_data_definitions, we need to make sure we have an associated row in the\n-- lsif_data_definitions_schema_versions table. We do not currently care about cleaning the table up\n-- (we will do this asynchronously).\n--\n-- We use FOR EACH STATEMENT here because we batch insert into this table. Running the trigger per\n-- statement rather than per row will save a ton of extra work. Running over batch inserts lets us\n-- do a GROUP BY on the new table and effectively upsert our new ranges.\n--\n-- Note that the only places where data is _modified_ in this database is during migrations, which\n-- will necessarily update this table's bounds for any migrated index records.\n\nCREATE OR REPLACE FUNCTION update_lsif_data_definitions_schema_versions_insert() RETURNS trigger AS $$ BEGIN\n    INSERT INTO\n        lsif_data_definitions_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(lsif_data_definitions_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_definitions_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$ LANGUAGE plpgsql;\n\nCREATE TRIGGER lsif_data_definitions_schema_versions_insert\nAFTER INSERT ON lsif_data_definitions REFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE PROCEDURE update_lsif_data_definitions_schema_versions_insert();",
				"DownQuery": "DROP TABLE lsif_data_definitions_schema_versions;\nDROP TRIGGER lsif_data_definitions_schema_versions_insert ON lsif_data_definitions;\nDROP FUNCTION update_lsif_data_definitions_schema_versions_insert;\n\nALTER TABLE lsif_data_definitions DROP COLUMN IF EXISTS schema_version;\nALTER TABLE lsif_data_definitions DROP COLUMN IF EXISTS num_locations;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000006
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000008,
				"Name": "references locations counts",
				"UpQuery": "-- faster to supply default than manual update\nALTER TABLE lsif_data_references ADD COLUMN schema_version int DEFAULT 1 NOT NULL;\nALTER TABLE lsif_data_references ADD COLUMN num_locations int DEFAULT 0 NOT NULL;\n\n-- drop default after all existing columns have been set\nALTER TABLE lsif_data_references ALTER COLUMN schema_version DROP DEFAULT;\nALTER TABLE lsif_data_references ALTER COLUMN num_locations DROP DEFAULT;\n\nCOMMENT ON COLUMN lsif_data_references.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\nCOMMENT ON COLUMN lsif_data_references.num_locations IS 'The number of locations stored in the data field.';\n\nCREATE TABLE lsif_data_references_schema_versions (\n    dump_id integer NOT NULL,\n    min_schema_version integer,\n    max_schema_version integer\n);\nALTER TABLE lsif_data_references_schema_versions ADD PRIMARY KEY (dump_id);\n\nCOMMENT ON TABLE lsif_data_references_schema_versions IS 'Tracks the range of schema_versions for each upload in the lsif_data_references table.';\nCOMMENT ON COLUMN lsif_data_references_schema_versions.dump_id IS 'The identifier of the associated dump in the lsif_uploads table.';\nCOMMENT ON COLUMN lsif_data_references_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_references.schema_version` where `lsif_data_references.dump_id = dump_id`.';\nCOMMENT ON COLUMN lsif_data_references_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_references.schema_version` where `lsif_data_references.dump_id = dump_id`.';\n\n-- Ensure that there is a lsif_data_references_schema_versions record for each distinct dump_id in\n-- the lsif_data_references table. All reference versions in the database at this point necessarily\n-- have a schema_version of 1, so we can gather all of the dump ids quickly by scanning the metadata\n-- table. Grouping the references table directly would take too much time in a migration.\n\nINSERT INTO lsif_data_references_schema_versions\n    SELECT\n        dump_id,\n        1 AS min_schema_version,\n        1 AS max_schema_version\n    FROM\n        lsif_data_metadata\n    ORDER BY\n        lsif_data_metadata;\n\n-- On every insert into lsif_data_references, we need to make sure we have an associated row in the\n-- lsif_data_references_schema_versions table. We do not currently care about cleaning the table up\n-- (we will do this asynchronously).\n--\n-- We use FOR EACH STATEMENT here because we batch insert into this table. Running the trigger per\n-- statement rather than per row will save a ton of extra work. Running over batch inserts lets us\n-- do a GROUP BY on the new table and effectively upsert our new ranges.\n--\n-- Note that the only places where data is _modified_ in this database is during migrations, which\n-- will necessarily update this table's bounds for any migrated index records.\n\nCREATE OR REPLACE FUNCTION update_lsif_data_references_schema_versions_insert() RETURNS trigger AS $$ BEGIN\n    INSERT INTO\n        lsif_data_references_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST(lsif_data_references_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_references_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$ LANGUAGE plpgsql;\n\nCREATE TRIGGER lsif_data_references_schema_versions_insert\nAFTER INSERT ON lsif_data_references REFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE PROCEDURE update_lsif_data_references_schema_versions_insert();",
				"DownQuery": "DROP TABLE lsif_data_references_schema_versions;\nDROP TRIGGER lsif_data_references_schema_versions_insert ON lsif_data_references;\nDROP FUNCTION update_lsif_data_references_schema_versions_insert;\n\nALTER TABLE lsif_data_references DROP COLUMN IF EXISTS schema_version;\nALTER TABLE lsif_data_references DROP COLUMN IF EXISTS num_locations;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000007
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000009,
				"Name": "documents schema version index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_data_documents_dump_id_schema_version ON lsif_data_documents (dump_id, schema_version);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_documents_dump_id_schema_version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000008
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_data_documents",
					"IndexName": "lsif_data_documents_dump_id_schema_version"
				}
			},
			{
				"ID": 1000000010,
				"Name": "definitions schema version index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_data_definitions_dump_id_schema_version ON lsif_data_definitions (dump_id, schema_version);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_definitions_dump_id_schema_version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000009
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_data_definitions",
					"IndexName": "lsif_data_definitions_dump_id_schema_version"
				}
			},
			{
				"ID": 1000000011,
				"Name": "references schema version index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_data_references_dump_id_schema_version ON lsif_data_references (dump_id, schema_version);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_references_dump_id_schema_version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000010
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_data_references",
					"IndexName": "lsif_data_references_dump_id_schema_version"
				}
			},
			{
				"ID": 1000000012,
				"Name": "delete missing schema versions",
				"UpQuery": "-- Delete data from the schema version count tables that was inserted from the metadata table but does\n-- not actually exist in the table that it shadows. This should only delete some records that we inserted\n-- in 1000000007_definitions_locations_counts.up.sql and 1000000008_references_locations_counts.up.sql.\n\nDELETE FROM lsif_data_documents_schema_versions sv WHERE NOT EXISTS (SELECT 1 FROM lsif_data_documents d WHERE d.dump_id = sv.dump_id);\nDELETE FROM lsif_data_definitions_schema_versions sv WHERE NOT EXISTS (SELECT 1 FROM lsif_data_definitions d WHERE d.dump_id = sv.dump_id);\nDELETE FROM lsif_data_references_schema_versions sv WHERE NOT EXISTS (SELECT 1 FROM lsif_data_references r WHERE r.dump_id = sv.dump_id);",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000011
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000013,
				"Name": "split document payload",
				"UpQuery": "-- Add new nullable columns\nALTER TABLE lsif_data_documents ADD COLUMN ranges bytea;\nALTER TABLE lsif_data_documents ADD COLUMN hovers bytea;\nALTER TABLE lsif_data_documents ADD COLUMN monikers bytea;\nALTER TABLE lsif_data_documents ADD COLUMN packages bytea;\nALTER TABLE lsif_data_documents ADD COLUMN diagnostics bytea;\n\n-- Add new comments\nCOMMENT ON COLUMN lsif_data_documents.ranges IS 'A gob-encoded payload conforming to the [Ranges](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L14:2) field of the DocumentDatatype.';\nCOMMENT ON COLUMN lsif_data_documents.hovers IS 'A gob-encoded payload conforming to the [HoversResults](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L15:2) field of the DocumentDatatype.';\nCOMMENT ON COLUMN lsif_data_documents.monikers IS 'A gob-encoded payload conforming to the [Monikers](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L16:2) field of the DocumentDatatype.';\nCOMMENT ON COLUMN lsif_data_documents.packages IS 'A gob-encoded payload conforming to the [PackageInformation](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L17:2) field of the DocumentDatatype.';\nCOMMENT ON COLUMN lsif_data_documents.diagnostics IS 'A gob-encoded payload conforming to the [Diagnostics](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L18:2) field of the DocumentDatatype.';\n\n-- Update outdated comments\nCOMMENT ON COLUMN lsif_data_documents.data IS 'A gob-encoded payload conforming to the [DocumentData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L13:6) type. This field is being migrated across ranges, hovers, monikers, packages, and diagnostics columns and will be removed in a future release of Sourcegraph.';\nCOMMENT ON COLUMN lsif_data_result_chunks.data IS 'A gob-encoded payload conforming to the [ResultChunkData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L76:6) type.';\nCOMMENT ON COLUMN lsif_data_definitions.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L106:6) types.';\nCOMMENT ON COLUMN lsif_data_references.data IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L106:6) types.';",
				"DownQuery": "ALTER TABLE lsif_data_documents DROP COLUMN ranges;\nALTER TABLE lsif_data_documents DROP COLUMN hovers;\nALTER TABLE lsif_data_documents DROP COLUMN monikers;\nALTER TABLE lsif_data_documents DROP COLUMN packages;\nALTER TABLE lsif_data_documents DROP COLUMN diagnostics;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000012
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000014,
				"Name": "schema version index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS lsif_data_documents_schema_versions_dump_id_schema_version_bounds ON lsif_data_documents_schema_versions (dump_id, min_schema_version, max_schema_version);\nCREATE INDEX IF NOT EXISTS lsif_data_definitions_schema_versions_dump_id_schema_version_bounds ON lsif_data_definitions_schema_versions (dump_id, min_schema_version, max_schema_version);\nCREATE INDEX IF NOT EXISTS lsif_data_references_schema_versions_dump_id_schema_version_bounds ON lsif_data_references_schema_versions (dump_id, min_schema_version, max_schema_version);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_documents_schema_versions_dump_id_schema_version_bounds;\nDROP INDEX IF EXISTS lsif_data_definitions_schema_versions_dump_id_schema_version_bounds;\nDROP INDEX IF EXISTS lsif_data_references_schema_versions_dump_id_schema_version_bounds;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000013
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000015,
				"Name": "lsif documentation",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_documentation_pages (\n    dump_id integer NOT NULL,\n    path_id TEXT,\n    data bytea\n);\n\nALTER TABLE lsif_data_documentation_pages ADD PRIMARY KEY (dump_id, path_id);\n\nCOMMENT ON TABLE lsif_data_documentation_pages IS 'Associates documentation pathIDs to their documentation page hierarchy chunk.';\nCOMMENT ON COLUMN lsif_data_documentation_pages.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_pages.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_pages.data IS 'A gob-encoded payload conforming to a `type DocumentationPageData struct` pointer (lib/codeintel/semantic/types.go)';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_documentation_pages;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000016,
				"Name": "apidocs clean",
				"UpQuery": "-- PR #22080 landed a number of backwards-incompatible API docs data changes and given how early\n-- stages API docs is, we don't care to maintain backwards compat with the old data and choose to\n-- instead start from scratch with indexing again (not many repos have been indexed with API docs,\n-- anyway.)\nTRUNCATE lsif_data_documentation_pages;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000015
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000017,
				"Name": "lsif documentation path info",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_documentation_path_info (\n    dump_id integer NOT NULL,\n    path_id TEXT,\n    data bytea\n);\n\nALTER TABLE lsif_data_documentation_path_info ADD PRIMARY KEY (dump_id, path_id);\n\nCOMMENT ON TABLE lsif_data_documentation_path_info IS 'Associates documentation page pathIDs to information about what is at that pathID, its immediate children, etc.';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_path_info.data IS 'A gob-encoded payload conforming to a `type DocumentationPathInoData struct` pointer (lib/codeintel/semantic/types.go)';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_documentation_path_info;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000016
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000018,
				"Name": "lsif documentation mappings",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_documentation_mappings (\n    dump_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    result_id integer NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_mappings ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE UNIQUE INDEX lsif_data_documentation_mappings_inverse_unique_idx ON lsif_data_documentation_mappings(dump_id, result_id);\n\nCOMMENT ON TABLE lsif_data_documentation_mappings IS 'Maps documentation path IDs to their corresponding integral documentationResult vertex IDs, which are unique within a dump.';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.path_id IS 'The documentation page path ID, see see GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_documentation_mappings.result_id IS 'The documentationResult vertex ID.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_documentation_mappings;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000017
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000019,
				"Name": "documentation path mapping",
				"UpQuery": "-- Add nullable file_path column, for mapping documentationResult ID -\u003e file_path\nALTER TABLE lsif_data_documentation_mappings ADD COLUMN file_path text;\nCOMMENT ON COLUMN lsif_data_documentation_mappings.file_path IS 'The document file path for the documentationResult, if any. e.g. the path to the file where the symbol described by this documentationResult is located, if it is a symbol.';",
				"DownQuery": "ALTER TABLE lsif_data_documentation_mappings DROP COLUMN file_path;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000018
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000020,
				"Name": "lsif data documentation search",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pg_trgm;\n\nALTER TABLE lsif_data_documentation_pages ADD COLUMN search_indexed boolean DEFAULT 'false';\n\n-- We're going to create the new lsif_data_documentation_search_* tables. These tables will have a\n-- trigram index and will be data decoded from the GOB encoded lsif_data_documentation_pages.data\n-- field, hence an OOB migration is needed as that table is quite large and not decodable in SQL\n-- alone.\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_public (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL,\n\n    PRIMARY KEY (dump_id, path_id)\n);\n\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_repo_id_idx ON lsif_data_documentation_search_public USING BTREE(repo_id);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_lang_trgm ON lsif_data_documentation_search_public USING gin(lang gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_repo_name_trgm ON lsif_data_documentation_search_public USING gin(repo_name gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_search_key_trgm ON lsif_data_documentation_search_public USING gin(search_key gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_label_trgm ON lsif_data_documentation_search_public USING gin(label gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_public_tags_trgm ON lsif_data_documentation_search_public USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_public IS 'A trigram index over documentation for search (public repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_public.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';\n\n-- Same exact thing as above, but for \"_private\" repos.\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_private (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL,\n\n    PRIMARY KEY (dump_id, path_id)\n);\n\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_repo_id_idx ON lsif_data_documentation_search_private USING BTREE(repo_id);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_lang_trgm ON lsif_data_documentation_search_private USING gin(lang gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_repo_name_trgm ON lsif_data_documentation_search_private USING gin(repo_name gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_search_key_trgm ON lsif_data_documentation_search_private USING gin(search_key gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_label_trgm ON lsif_data_documentation_search_private USING gin(label gin_trgm_ops);\nCREATE INDEX IF NOT EXISTS lsif_data_documentation_search_private_tags_trgm ON lsif_data_documentation_search_private USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_private IS 'A trigram index over documentation for search (private repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_private.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';",
				"DownQuery": "ALTER TABLE lsif_data_documentation_pages DROP COLUMN search_indexed;\nDROP TABLE IF EXISTS lsif_data_documentation_search;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000019
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000021,
				"Name": "reverted",
				"UpQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"DownQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000020
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000022,
				"Name": "undo apidocs root column",
				"UpQuery": "-- Undo the changes corresponding to https://github.com/sourcegraph/sourcegraph/pull/25715\nALTER TABLE lsif_data_documentation_search_public DROP COLUMN IF EXISTS dump_root;\nALTER TABLE lsif_data_documentation_search_private DROP COLUMN IF EXISTS dump_root;",
				"DownQuery": "-- Nothing to do, the up migration undid changes previously made.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000021
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000023,
				"Name": "apidocs add dump root column",
				"UpQuery": "ALTER TABLE lsif_data_documentation_search_public ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_public_dump_root_idx ON lsif_data_documentation_search_public USING BTREE(dump_root);\n\nALTER TABLE lsif_data_documentation_search_private ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_private_dump_root_idx ON lsif_data_documentation_search_public USING BTREE(dump_root);\n\n-- Truncate both tables; we don't care about reindexing given so little has been indexed to date.\nTRUNCATE lsif_data_documentation_search_public;\nTRUNCATE lsif_data_documentation_search_private;",
				"DownQuery": "ALTER TABLE lsif_data_documentation_search_public DROP COLUMN IF EXISTS dump_root;\nALTER TABLE lsif_data_documentation_search_private DROP COLUMN IF EXISTS dump_root;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000022
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000024,
				"Name": "apidocs search to tsvector",
				"UpQuery": "-- We're completely changing the API docs search table schema, so we'll reindex everything\n-- from scratch. Reset our OOB migration's progress entirely.\n--\n-- IMPORTANT: Dropping the column and recreating it is nearly instant, updating the table\n-- to set the column to 'false' again can take several minutes.\nALTER TABLE lsif_data_documentation_pages DROP COLUMN search_indexed;\nALTER TABLE lsif_data_documentation_pages ADD COLUMN search_indexed boolean DEFAULT 'false';\n\n-- We're completely redefining the table.\nDROP TABLE IF EXISTS lsif_data_documentation_search_public;\n\n-- Each unique language name being stored in the search index.\n--\n-- Contains a tsvector index for matching a logical OR of query terms against the language name\n-- (e.g. \"http router go\" to match \"go\" without knowing if \"http\", \"router\", or \"go\" are actually\n-- a language name or not.)\nCREATE TABLE lsif_data_docs_search_lang_names_public (\n    id BIGSERIAL PRIMARY KEY,\n    lang_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_lang_names_public_tsv_idx ON lsif_data_docs_search_lang_names_public USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_lang_names_public IS 'Each unique language name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.id IS 'The ID of the language name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.lang_name IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_public.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique repository name being stored in the search index.\n--\n-- Contains a tsvector index for matching against repository names, with both prefix and suffix\n-- (reverse prefix) matching within lexemes (words).\nCREATE TABLE lsif_data_docs_search_repo_names_public (\n    id BIGSERIAL PRIMARY KEY,\n    repo_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL,\n    reverse_tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_repo_names_public_tsv_idx ON lsif_data_docs_search_repo_names_public USING GIN(tsv);\nCREATE INDEX lsif_data_docs_search_repo_names_public_reverse_tsv_idx ON lsif_data_docs_search_repo_names_public USING GIN(reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_repo_names_public IS 'Each unique repository name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.id IS 'The ID of the repository name.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.repo_name IS 'The fully qualified name of the repository.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_public.reverse_tsv IS 'Indexed tsvector for the reverse of the lang_name field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique sequence of space-separated tags being stored in the search index. This could be as\n-- many rows as the search table itself, because in theory each result could have a unique string\n-- of tags. In practice, though, they are frequently similar sequences.\n--\n-- The space separated tags have a tsvector for matching a logcal OR of query terms against, for\n-- the same reason as the lang_names table. e.g. so that we can have a query for \"go private function net router\"\n-- match the tags string \"private function\" without knowing which query terms are tags or not.\n--\n-- The entire sequence of space-separated tags are stored, in part so that lookups in the search table\n-- are faster (single ID lookup rather than array ALL lookup) and partly to allow for more complex\n-- tag matching options in the future.\nCREATE TABLE lsif_data_docs_search_tags_public (\n    id BIGSERIAL PRIMARY KEY,\n    tags TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_tags_public_tsv_idx ON lsif_data_docs_search_tags_public USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_tags_public IS 'Each uniques sequence of space-separated tags being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.id IS 'The ID of the tags.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.tags IS 'The full sequence of space-separated tags. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_public.tsv IS 'Indexed tsvector for the tags field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- The actual search index over API docs, one entry per symbol/section of API docs.\nCREATE TABLE lsif_data_docs_search_public (\n    -- Metadata fields\n    id BIGSERIAL PRIMARY KEY,\n    repo_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    repo_name_id INTEGER NOT NULL,\n    tags_id INTEGER NOT NULL,\n\n    -- FTS-enabled fields\n    search_key TEXT NOT NULL,\n    search_key_tsv TSVECTOR NOT NULL,\n    search_key_reverse_tsv TSVECTOR NOT NULL,\n\n    label TEXT NOT NULL,\n    label_tsv TSVECTOR NOT NULL,\n    label_reverse_tsv TSVECTOR NOT NULL,\n\n    CONSTRAINT lsif_data_docs_search_public_lang_name_id_fk FOREIGN KEY(lang_name_id) REFERENCES lsif_data_docs_search_lang_names_public(id),\n    CONSTRAINT lsif_data_docs_search_public_repo_name_id_fk FOREIGN KEY(repo_name_id) REFERENCES lsif_data_docs_search_repo_names_public(id),\n    CONSTRAINT lsif_data_docs_search_public_tags_id_fk FOREIGN KEY(tags_id) REFERENCES lsif_data_docs_search_tags_public(id)\n);\n\n-- This pair of fields is used to purge stale data from the search index, so use a btree index on it.\nCREATE INDEX lsif_data_docs_search_public_repo_id_idx ON lsif_data_docs_search_public USING BTREE(repo_id);\nCREATE INDEX lsif_data_docs_search_public_dump_id_idx ON lsif_data_docs_search_public USING BTREE(dump_id);\nCREATE INDEX lsif_data_docs_search_public_dump_root_idx ON lsif_data_docs_search_public USING BTREE(dump_root);\n\n-- tsvector indexes\nCREATE INDEX lsif_data_docs_search_public_search_key_tsv_idx ON lsif_data_docs_search_public USING BTREE(search_key_tsv);\nCREATE INDEX lsif_data_docs_search_public_search_key_reverse_tsv_idx ON lsif_data_docs_search_public USING BTREE(search_key_reverse_tsv);\nCREATE INDEX lsif_data_docs_search_public_label_tsv_idx ON lsif_data_docs_search_public USING BTREE(label_tsv);\nCREATE INDEX lsif_data_docs_search_public_label_reverse_tsv_idx ON lsif_data_docs_search_public USING BTREE(label_reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_public IS 'A tsvector search index over API documentation (public repos only)';\nCOMMENT ON COLUMN lsif_data_docs_search_public.id IS 'The row ID of the search result.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_docs_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_public.lang_name_id IS 'The programming language (or indexer name) that produced the result. Foreign key into lsif_data_docs_search_lang_names_public.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.repo_name_id IS 'The repository name that produced the result. Foreign key into lsif_data_docs_search_repo_names_public.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.tags_id IS 'The tags from the documentation node. Foreign key into lsif_data_docs_search_tags_public.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key_tsv IS 'Indexed tsvector for the search_key field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.search_key_reverse_tsv IS 'Indexed tsvector for the reverse of the search_key field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_public.label_tsv IS 'Indexed tsvector for the label field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_public.label_reverse_tsv IS 'Indexed tsvector for the reverse of the label field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- ************************************************************************************************\n-- Below here is a direct copy of the above, but with \"public\" replaced with \"private\" for the    *\n-- private variant of the table.                                                                  *\n-- ************************************************************************************************\n\n-- We're completely redefining the table.\nDROP TABLE IF EXISTS lsif_data_documentation_search_private;\n\n-- Each unique language name being stored in the search index.\n--\n-- Contains a tsvector index for matching a logical OR of query terms against the language name\n-- (e.g. \"http router go\" to match \"go\" without knowing if \"http\", \"router\", or \"go\" are actually\n-- a language name or not.)\nCREATE TABLE lsif_data_docs_search_lang_names_private (\n    id BIGSERIAL PRIMARY KEY,\n    lang_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_lang_names_private_tsv_idx ON lsif_data_docs_search_lang_names_private USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_lang_names_private IS 'Each unique language name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.id IS 'The ID of the language name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.lang_name IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name.';\nCOMMENT ON COLUMN lsif_data_docs_search_lang_names_private.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique repository name being stored in the search index.\n--\n-- Contains a tsvector index for matching against repository names, with both prefix and suffix\n-- (reverse prefix) matching within lexemes (words).\nCREATE TABLE lsif_data_docs_search_repo_names_private (\n    id BIGSERIAL PRIMARY KEY,\n    repo_name TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL,\n    reverse_tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_repo_names_private_tsv_idx ON lsif_data_docs_search_repo_names_private USING GIN(tsv);\nCREATE INDEX lsif_data_docs_search_repo_names_private_reverse_tsv_idx ON lsif_data_docs_search_repo_names_private USING GIN(reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_repo_names_private IS 'Each unique repository name being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.id IS 'The ID of the repository name.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.repo_name IS 'The fully qualified name of the repository.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.tsv IS 'Indexed tsvector for the lang_name field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_repo_names_private.reverse_tsv IS 'Indexed tsvector for the reverse of the lang_name field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- Each unique sequence of space-separated tags being stored in the search index. This could be as\n-- many rows as the search table itself, because in theory each result could have a unique string\n-- of tags. In practice, though, they are frequently similar sequences.\n--\n-- The space separated tags have a tsvector for matching a logcal OR of query terms against, for\n-- the same reason as the lang_names table. e.g. so that we can have a query for \"go private function net router\"\n-- match the tags string \"private function\" without knowing which query terms are tags or not.\n--\n-- The entire sequence of space-separated tags are stored, in part so that lookups in the search table\n-- are faster (single ID lookup rather than array ALL lookup) and partly to allow for more complex\n-- tag matching options in the future.\nCREATE TABLE lsif_data_docs_search_tags_private (\n    id BIGSERIAL PRIMARY KEY,\n    tags TEXT NOT NULL UNIQUE,\n    tsv TSVECTOR NOT NULL\n);\nCREATE INDEX lsif_data_docs_search_tags_private_tsv_idx ON lsif_data_docs_search_tags_private USING GIN(tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_tags_private IS 'Each uniques sequence of space-separated tags being stored in the API docs search index.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.id IS 'The ID of the tags.';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.tags IS 'The full sequence of space-separated tags. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_tags_private.tsv IS 'Indexed tsvector for the tags field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\n-- The actual search index over API docs, one entry per symbol/section of API docs.\nCREATE TABLE lsif_data_docs_search_private (\n    -- Metadata fields\n    id BIGSERIAL PRIMARY KEY,\n    repo_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    repo_name_id INTEGER NOT NULL,\n    tags_id INTEGER NOT NULL,\n\n    -- FTS-enabled fields\n    search_key TEXT NOT NULL,\n    search_key_tsv TSVECTOR NOT NULL,\n    search_key_reverse_tsv TSVECTOR NOT NULL,\n\n    label TEXT NOT NULL,\n    label_tsv TSVECTOR NOT NULL,\n    label_reverse_tsv TSVECTOR NOT NULL,\n\n    CONSTRAINT lsif_data_docs_search_private_lang_name_id_fk FOREIGN KEY(lang_name_id) REFERENCES lsif_data_docs_search_lang_names_private(id),\n    CONSTRAINT lsif_data_docs_search_private_repo_name_id_fk FOREIGN KEY(repo_name_id) REFERENCES lsif_data_docs_search_repo_names_private(id),\n    CONSTRAINT lsif_data_docs_search_private_tags_id_fk FOREIGN KEY(tags_id) REFERENCES lsif_data_docs_search_tags_private(id)\n);\n\n-- This pair of fields is used to purge stale data from the search index, so use a btree index on it.\nCREATE INDEX lsif_data_docs_search_private_repo_id_idx ON lsif_data_docs_search_private USING BTREE(repo_id);\nCREATE INDEX lsif_data_docs_search_private_dump_id_idx ON lsif_data_docs_search_private USING BTREE(dump_id);\nCREATE INDEX lsif_data_docs_search_private_dump_root_idx ON lsif_data_docs_search_private USING BTREE(dump_root);\n\n-- tsvector indexes\nCREATE INDEX lsif_data_docs_search_private_search_key_tsv_idx ON lsif_data_docs_search_private USING BTREE(search_key_tsv);\nCREATE INDEX lsif_data_docs_search_private_search_key_reverse_tsv_idx ON lsif_data_docs_search_private USING BTREE(search_key_reverse_tsv);\nCREATE INDEX lsif_data_docs_search_private_label_tsv_idx ON lsif_data_docs_search_private USING BTREE(label_tsv);\nCREATE INDEX lsif_data_docs_search_private_label_reverse_tsv_idx ON lsif_data_docs_search_private USING BTREE(label_reverse_tsv);\n\nCOMMENT ON TABLE lsif_data_docs_search_private IS 'A tsvector search index over API documentation (private repos only)';\nCOMMENT ON COLUMN lsif_data_docs_search_private.id IS 'The row ID of the search result.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_docs_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_private.lang_name_id IS 'The programming language (or indexer name) that produced the result. Foreign key into lsif_data_docs_search_lang_names_private.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.repo_name_id IS 'The repository name that produced the result. Foreign key into lsif_data_docs_search_repo_names_private.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.tags_id IS 'The tags from the documentation node. Foreign key into lsif_data_docs_search_tags_private.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key_tsv IS 'Indexed tsvector for the search_key field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.search_key_reverse_tsv IS 'Indexed tsvector for the reverse of the search_key field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\n\nCOMMENT ON COLUMN lsif_data_docs_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_docs_search_private.label_tsv IS 'Indexed tsvector for the label field. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';\nCOMMENT ON COLUMN lsif_data_docs_search_private.label_reverse_tsv IS 'Indexed tsvector for the reverse of the label field, for suffix lexeme/word matching. Crafted for ordered, case, and punctuation sensitivity, see data_write_documentation.go:textSearchVector.';",
				"DownQuery": "-- We've alterd tables beyond rollback in our up migration. The best we can do for a down migration\n-- is bring back the old schema so the previous version of Sourcegraph runs properly.\nDROP TABLE IF EXISTS lsif_data_docs_search_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_lang_names_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_repo_names_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_tags_public;\n\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_public (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_search_public ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE INDEX lsif_data_documentation_search_public_repo_id_idx ON lsif_data_documentation_search_public USING BTREE(repo_id);\nCREATE INDEX lsif_data_documentation_search_public_lang_trgm ON lsif_data_documentation_search_public USING gin(lang gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_repo_name_trgm ON lsif_data_documentation_search_public USING gin(repo_name gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_search_key_trgm ON lsif_data_documentation_search_public USING gin(search_key gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_label_trgm ON lsif_data_documentation_search_public USING gin(label gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_public_tags_trgm ON lsif_data_documentation_search_public USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_public IS 'A trigram index over documentation for search (public repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_public.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';\n\nALTER TABLE lsif_data_documentation_search_public ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_public.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_public_dump_root_idx ON lsif_data_documentation_search_public USING BTREE(dump_root);\n\n-- ************************************************************************************************\n-- Below here is a direct copy of the above, but with \"public\" replaced with \"private\" for the    *\n-- private variant of the table.                                                                  *\n-- ************************************************************************************************\n\n-- We've alterd tables beyond rollback in our up migration. The best we can do for a down migration\n-- is bring back the old schema so the previous version of Sourcegraph runs properly.\nDROP TABLE IF EXISTS lsif_data_docs_search_private;\nDROP TABLE IF EXISTS lsif_data_docs_search_lang_names_private;\nDROP TABLE IF EXISTS lsif_data_docs_search_repo_names_private;\nDROP TABLE IF EXISTS lsif_data_docs_search_tags_private;\n\nCREATE TABLE IF NOT EXISTS lsif_data_documentation_search_private (\n    -- Metadata fields\n    dump_id integer NOT NULL,\n    repo_id integer NOT NULL,\n    path_id TEXT NOT NULL,\n    detail TEXT NOT NULL,\n\n    -- FTS-enabled fields\n    lang TEXT NOT NULL,\n    repo_name TEXT NOT NULL,\n    search_key TEXT NOT NULL,\n    label TEXT NOT NULL,\n    tags TEXT NOT NULL\n);\n\nALTER TABLE lsif_data_documentation_search_private ADD PRIMARY KEY (dump_id, path_id);\n\nCREATE INDEX lsif_data_documentation_search_private_repo_id_idx ON lsif_data_documentation_search_private USING BTREE(repo_id);\nCREATE INDEX lsif_data_documentation_search_private_lang_trgm ON lsif_data_documentation_search_private USING gin(lang gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_repo_name_trgm ON lsif_data_documentation_search_private USING gin(repo_name gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_search_key_trgm ON lsif_data_documentation_search_private USING gin(search_key gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_label_trgm ON lsif_data_documentation_search_private USING gin(label gin_trgm_ops);\nCREATE INDEX lsif_data_documentation_search_private_tags_trgm ON lsif_data_documentation_search_private USING gin(tags gin_trgm_ops);\n\nCOMMENT ON TABLE lsif_data_documentation_search_private IS 'A trigram index over documentation for search (private repos only)';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_id IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_id IS 'The repo ID, from the main app DB repo table. Used to search over a select set of repos by ID.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.path_id IS 'The fully qualified documentation page path ID, e.g. including \"#section\". See GraphQL codeintel.schema:documentationPage for what this is.';\n\nCOMMENT ON COLUMN lsif_data_documentation_search_private.lang IS 'The lowercase language name (go, java, etc.) OR, if unknown, the LSIF indexer name';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.repo_name IS 'The name of the repository containing this search key.';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.search_key IS 'The search key generated by the indexer, e.g. mux.Router.ServeHTTP. It is language-specific, and likely unique within a repository (but not always.) See protocol/documentation.go:Documentation.SearchKey';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.label IS 'The label string of the result, e.g. a one-line function signature. See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.detail IS 'The detail string (e.g. the full function signature and its docs). See protocol/documentation.go:Documentation';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.tags IS 'A space separated list of tags from the documentation node. See protocol/documentation.go:Documentation';\n\nALTER TABLE lsif_data_documentation_search_private ADD COLUMN dump_root TEXT NOT NULL DEFAULT '';\nCOMMENT ON COLUMN lsif_data_documentation_search_private.dump_root IS 'Identical to lsif_dumps.root; The working directory of the indexer image relative to the repository root.';\nCREATE INDEX lsif_data_documentation_search_private_dump_root_idx ON lsif_data_documentation_search_private USING BTREE(dump_root);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000023
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000025,
				"Name": "apidocs materialized stats",
				"UpQuery": "--------------------------------------------------------\n-- Stats for the lsif_data_documentation_pages table. --\n--------------------------------------------------------\nCREATE TABLE lsif_data_apidocs_num_pages AS SELECT count(*) FROM lsif_data_documentation_pages;\nCREATE TABLE lsif_data_apidocs_num_dumps AS SELECT count(DISTINCT dump_id) FROM lsif_data_documentation_pages;\nCREATE TABLE lsif_data_apidocs_num_dumps_indexed AS SELECT count(DISTINCT dump_id) FROM lsif_data_documentation_pages WHERE search_indexed='true';\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_delete()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_pages SET count = count - (select count(*) from oldtbl);\nUPDATE lsif_data_apidocs_num_dumps SET count = count - (select count(DISTINCT dump_id) from oldtbl);\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count = count - (select count(DISTINCT dump_id) from oldtbl WHERE search_indexed='true');\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_documentation_pages_delete\nAFTER DELETE ON lsif_data_documentation_pages\nREFERENCING OLD TABLE AS oldtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_documentation_pages_delete();\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_insert()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_pages SET count = count + (select count(*) from newtbl);\nUPDATE lsif_data_apidocs_num_dumps SET count = count + (select count(DISTINCT dump_id) from newtbl);\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count = count + (select count(DISTINCT dump_id) from newtbl WHERE search_indexed='true');\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_documentation_pages_insert\nAFTER INSERT ON lsif_data_documentation_pages\nREFERENCING NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_documentation_pages_insert();\n\nCREATE OR REPLACE FUNCTION lsif_data_documentation_pages_update()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nWITH\n    beforeIndexed AS (SELECT count(DISTINCT dump_id) FROM oldtbl WHERE search_indexed='true'),\n    afterIndexed AS (SELECT count(DISTINCT dump_id) FROM newtbl WHERE search_indexed='true')\nUPDATE lsif_data_apidocs_num_dumps_indexed SET count=count + ((select * from afterIndexed) - (select * from beforeIndexed));\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_documentation_pages_update\nAFTER UPDATE ON lsif_data_documentation_pages\nREFERENCING OLD TABLE AS oldtbl NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_documentation_pages_update();\n\n-------------------------------------------------------\n-- Stats for the lsif_data_docs_search_public table. --\n-------------------------------------------------------\nCREATE TABLE lsif_data_apidocs_num_search_results_public AS SELECT count(*) FROM lsif_data_docs_search_public;\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_public_delete()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_public SET count = count - (select count(*) from oldtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_public_delete\nAFTER DELETE\nON lsif_data_docs_search_public\nREFERENCING OLD TABLE AS oldtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_public_delete();\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_public_insert()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_public SET count = count + (select count(*) from newtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_public_insert\nAFTER INSERT\nON lsif_data_docs_search_public\nREFERENCING NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_public_insert();\n\n-------------------------------------------------------\n-- Stats for the lsif_data_docs_search_private table. --\n-------------------------------------------------------\nCREATE TABLE lsif_data_apidocs_num_search_results_private AS SELECT count(*) FROM lsif_data_docs_search_private;\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_private_delete()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_private SET count = count - (select count(*) from oldtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_private_delete\nAFTER DELETE\nON lsif_data_docs_search_private\nREFERENCING OLD TABLE AS oldtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_private_delete();\n\nCREATE OR REPLACE FUNCTION lsif_data_docs_search_private_insert()\nRETURNS TRIGGER LANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE lsif_data_apidocs_num_search_results_private SET count = count + (select count(*) from newtbl);\nRETURN NULL;\nEND $$;\n\nCREATE TRIGGER lsif_data_docs_search_private_insert\nAFTER INSERT\nON lsif_data_docs_search_private\nREFERENCING NEW TABLE AS newtbl\nFOR EACH STATEMENT EXECUTE PROCEDURE lsif_data_docs_search_private_insert();",
				"DownQuery": "DROP TABLE lsif_data_apidocs_num_pages;\nDROP TABLE lsif_data_apidocs_num_dumps;\nDROP TABLE lsif_data_apidocs_num_dumps_indexed;\nDROP TRIGGER lsif_data_documentation_pages_delete ON lsif_data_documentation_pages;\nDROP TRIGGER lsif_data_documentation_pages_insert ON lsif_data_documentation_pages;\nDROP TRIGGER lsif_data_documentation_pages_update ON lsif_data_documentation_pages;\nDROP FUNCTION lsif_data_documentation_pages_delete;\nDROP FUNCTION lsif_data_documentation_pages_insert;\nDROP FUNCTION lsif_data_documentation_pages_update;\n\nDROP TABLE lsif_data_apidocs_num_search_results_public;\nDROP TRIGGER lsif_data_docs_search_public_delete ON lsif_data_docs_search_public;\nDROP TRIGGER lsif_data_docs_search_public_insert ON lsif_data_docs_search_public;\nDROP FUNCTION lsif_data_docs_search_public_delete;\nDROP FUNCTION lsif_data_docs_search_public_insert;\n\nDROP TABLE lsif_data_apidocs_num_search_results_private;\nDROP TRIGGER lsif_data_docs_search_private_delete ON lsif_data_docs_search_private;\nDROP TRIGGER lsif_data_docs_search_private_insert ON lsif_data_docs_search_private;\nDROP FUNCTION lsif_data_docs_search_private_delete;\nDROP FUNCTION lsif_data_docs_search_private_insert;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000024
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000026,
				"Name": "add lsif data docs search current",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_data_docs_search_current_public (\n    repo_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    last_cleanup_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY (repo_id, dump_root, lang_name_id)\n);\n\nCOMMENT ON TABLE lsif_data_docs_search_current_public IS 'A table indicating the most current search index for a unique repository, root, and language.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.repo_id IS 'The repository identifier of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_root IS 'The root of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.lang_name_id IS 'The interned index name of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_public table.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_public table have been cleaned.';\n\nCREATE TABLE IF NOT EXISTS lsif_data_docs_search_current_private (\n    repo_id INTEGER NOT NULL,\n    dump_root TEXT NOT NULL,\n    lang_name_id INTEGER NOT NULL,\n    dump_id INTEGER NOT NULL,\n    last_cleanup_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY (repo_id, dump_root, lang_name_id)\n);\n\nCOMMENT ON TABLE lsif_data_docs_search_current_private IS 'A table indicating the most current search index for a unique repository, root, and language.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.repo_id IS 'The repository identifier of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_root IS 'The root of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.lang_name_id IS 'The interned index name of the associated dump.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_private table.';\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_private table have been cleaned.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_data_docs_search_current_public;\nDROP TABLE IF EXISTS lsif_data_docs_search_current_private;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000025
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000027,
				"Name": "add search repo names index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS lsif_data_documentation_pages_dump_id_unindexed ON lsif_data_documentation_pages(dump_id) WHERE NOT search_indexed;",
				"DownQuery": "DROP INDEX lsif_data_documentation_pages_dump_id_unindexed;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000026
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000028,
				"Name": "lsif non unique docs search current tables",
				"UpQuery": "--\n-- Public\n\n-- Change comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The associated dump identifier.';\n\n-- Create new created_at column to decide a leader\nALTER TABLE lsif_data_docs_search_current_public ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.created_at IS 'The time this record was inserted. The records with the latest created_at value for the same repository, root, and language is the only visible one and others will be deleted asynchronously.';\n\n-- Add default to last_cleanup_scan_at column\nALTER TABLE lsif_data_docs_search_current_public ALTER COLUMN last_cleanup_scan_at SET DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time this record was checked as part of a data retention scan.';\n\n-- Create new indexes\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_public_lookup\nON lsif_data_docs_search_current_public(repo_id, dump_root, lang_name_id, created_at)\nINCLUDE (dump_id);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_public_last_cleanup_scan_at ON lsif_data_docs_search_current_public(last_cleanup_scan_at);\n\n-- Drop existing primary key\nALTER TABLE lsif_data_docs_search_current_public DROP CONSTRAINT IF EXISTS lsif_data_docs_search_current_public_pkey;\n\n-- Create new serial primary key\nALTER TABLE lsif_data_docs_search_current_public ADD COLUMN IF NOT EXISTS id SERIAL PRIMARY KEY;\n\n--\n-- Private\n\n-- Change comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The associated dump identifier.';\n\n-- Create new created_at column to decide a leader\nALTER TABLE lsif_data_docs_search_current_private ADD COLUMN IF NOT EXISTS created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.created_at IS 'The time this record was inserted. The records with the latest created_at value for the same repository, root, and language is the only visible one and others will be deleted asynchronously.';\n\n-- Add default to last_cleanup_scan_at column\nALTER TABLE lsif_data_docs_search_current_private ALTER COLUMN last_cleanup_scan_at SET DEFAULT NOW();\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time this record was checked as part of a data retention scan.';\n\n-- Add index to last_cleanup_scan_at\n\n\n-- Create new indexes\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_private_lookup\nON lsif_data_docs_search_current_private(repo_id, dump_root, lang_name_id, created_at)\nINCLUDE (dump_id);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_current_private_last_cleanup_scan_at ON lsif_data_docs_search_current_private(last_cleanup_scan_at);\n\n-- Drop existing primary key\nALTER TABLE lsif_data_docs_search_current_private DROP CONSTRAINT IF EXISTS lsif_data_docs_search_current_private_pkey;\n\n-- Create new serial primary key\nALTER TABLE lsif_data_docs_search_current_private ADD COLUMN IF NOT EXISTS id SERIAL PRIMARY KEY;",
				"DownQuery": "--\n-- Public\n\n-- De-duplicate records before adding the unique index\nDELETE FROM lsif_data_docs_search_current_public WHERE id NOT IN (\n    SELECT MAX(id) as max_id\n    FROM lsif_data_docs_search_current_public\n    GROUP BY repo_id, dump_root, lang_name_id\n);\n\n-- Drop new columns\nALTER TABLE lsif_data_docs_search_current_public DROP COLUMN IF EXISTS id;\nALTER TABLE lsif_data_docs_search_current_public DROP COLUMN IF EXISTS created_at;\n\n-- Drop new index\nDROP INDEX IF EXISTS lsif_data_docs_search_current_public_last_cleanup_scan_at;\n\n-- Re-create old primary key\nALTER TABLE lsif_data_docs_search_current_public ADD PRIMARY KEY (repo_id, dump_root, lang_name_id);\n\n-- Restore old comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_public table.';\n\n-- Restore old last_cleanup_scan_at column\nCOMMENT ON COLUMN lsif_data_docs_search_current_public.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_public table have been cleaned.';\nALTER TABLE lsif_data_docs_search_current_public ALTER COLUMN last_cleanup_scan_at DROP DEFAULT;\n\n--\n-- Private\n\n-- De-duplicate records before adding the unique index\nDELETE FROM lsif_data_docs_search_current_private WHERE id NOT IN (\n    SELECT MAX(id) as max_id\n    FROM lsif_data_docs_search_current_private\n    GROUP BY repo_id, dump_root, lang_name_id\n);\n\n-- Drop new columns\nALTER TABLE lsif_data_docs_search_current_private DROP COLUMN IF EXISTS id;\nALTER TABLE lsif_data_docs_search_current_private DROP COLUMN IF EXISTS created_at;\n\n-- Drop new index\nDROP INDEX IF EXISTS lsif_data_docs_search_current_private_last_cleanup_scan_at;\n\n-- Re-create old primary key\nALTER TABLE lsif_data_docs_search_current_private ADD PRIMARY KEY (repo_id, dump_root, lang_name_id);\n\n-- Restore old comment\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.dump_id IS 'The most recent dump identifier for this key. See associated content in the lsif_data_docs_search_public table.';\n\n-- Restore old last_cleanup_scan_at column\nCOMMENT ON COLUMN lsif_data_docs_search_current_private.last_cleanup_scan_at IS 'The last time outdated records in the lsif_data_docs_search_public table have been cleaned.';\nALTER TABLE lsif_data_docs_search_current_private ALTER COLUMN last_cleanup_scan_at DROP DEFAULT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000027
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000029,
				"Name": "apidocs missing fts indexes",
				"UpQuery": "-- Drop the btree indexes that we intended to be GIN indexes.\n-- btree indexes are no where near as performant for tsvector indexing.\nDROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx;\n\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx;\n\n-- Recreate indexes with GIN instead.\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_search_key_tsv_idx ON lsif_data_docs_search_public USING GIN (search_key_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx ON lsif_data_docs_search_public USING GIN (search_key_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_label_tsv_idx ON lsif_data_docs_search_public USING GIN (label_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx ON lsif_data_docs_search_public USING GIN (label_reverse_tsv);\n\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_search_key_tsv_idx ON lsif_data_docs_search_private USING GIN (search_key_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx ON lsif_data_docs_search_private USING GIN (search_key_reverse_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_label_tsv_idx ON lsif_data_docs_search_private USING GIN (label_tsv);\nCREATE INDEX IF NOT EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx ON lsif_data_docs_search_private USING GIN (label_reverse_tsv);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_public_label_reverse_tsv_idx;\n\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_search_key_reverse_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_tsv_idx;\nDROP INDEX IF EXISTS lsif_data_docs_search_private_label_reverse_tsv_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000028
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000030,
				"Name": "lsif data implementations",
				"UpQuery": "CREATE TABLE lsif_data_implementations (\n    dump_id        INTEGER NOT NULL,\n    scheme         TEXT    NOT NULL,\n    identifier     TEXT    NOT NULL,\n    data           BYTEA           ,\n    schema_version INTEGER NOT NULL,\n    num_locations  INTEGER NOT NULL\n);\n\nCOMMENT ON TABLE  lsif_data_implementations                IS 'Associates (document, range) pairs with the implementation monikers attached to the range.';\nCOMMENT ON COLUMN lsif_data_implementations.dump_id        IS 'The identifier of the associated dump in the lsif_uploads table (state=completed).';\nCOMMENT ON COLUMN lsif_data_implementations.scheme         IS 'The moniker scheme.';\nCOMMENT ON COLUMN lsif_data_implementations.identifier     IS 'The moniker identifier.';\nCOMMENT ON COLUMN lsif_data_implementations.data           IS 'A gob-encoded payload conforming to an array of [LocationData](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.26/-/blob/enterprise/lib/codeintel/semantic/types.go#L106:6) types.';\nCOMMENT ON COLUMN lsif_data_implementations.schema_version IS 'The schema version of this row - used to determine presence and encoding of data.';\nCOMMENT ON COLUMN lsif_data_implementations.num_locations  IS 'The number of locations stored in the data field.';\n\nALTER TABLE ONLY lsif_data_implementations ADD CONSTRAINT lsif_data_implementations_pkey PRIMARY KEY (dump_id, scheme, identifier);\n\nCREATE INDEX lsif_data_implementations_dump_id_schema_version ON lsif_data_implementations (dump_id, schema_version);\n\nCREATE TABLE lsif_data_implementations_schema_versions (\n    dump_id            INTEGER NOT NULL,\n    min_schema_version INTEGER         ,\n    max_schema_version INTEGER\n);\n\nCOMMENT ON TABLE lsif_data_implementations_schema_versions                     IS 'Tracks the range of schema_versions for each upload in the lsif_data_implementations table.';\nCOMMENT ON COLUMN lsif_data_implementations_schema_versions.dump_id            IS 'The identifier of the associated dump in the lsif_uploads table.';\nCOMMENT ON COLUMN lsif_data_implementations_schema_versions.min_schema_version IS 'A lower-bound on the `lsif_data_implementations.schema_version` where `lsif_data_implementations.dump_id = dump_id`.';\nCOMMENT ON COLUMN lsif_data_implementations_schema_versions.max_schema_version IS 'An upper-bound on the `lsif_data_implementations.schema_version` where `lsif_data_implementations.dump_id = dump_id`.';\n\nALTER TABLE ONLY lsif_data_implementations_schema_versions ADD CONSTRAINT lsif_data_implementations_schema_versions_pkey PRIMARY KEY (dump_id);\n\nCREATE INDEX lsif_data_implementations_schema_versions_dump_id_schema_version_bounds ON lsif_data_implementations_schema_versions (dump_id, min_schema_version, max_schema_version);\n\n-- On every insert into lsif_data_implementations, we need to make sure we have an associated row in the\n-- lsif_data_implementations_schema_versions table. We do not currently care about cleaning the table up\n-- (we will do this asynchronously).\n--\n-- We use FOR EACH STATEMENT here because we batch insert into this table. Running the trigger per\n-- statement rather than per row will save a ton of extra work. Running over batch inserts lets us\n-- do a GROUP BY on the new table and effectively upsert our new ranges.\n--\n-- Note that the only places where data is _modified_ in this database is during migrations, which\n-- will necessarily update this table's bounds for any migrated index records.\n\nCREATE OR REPLACE FUNCTION update_lsif_data_implementations_schema_versions_insert() RETURNS trigger AS $$ BEGIN\n    INSERT INTO\n        lsif_data_implementations_schema_versions\n    SELECT\n        dump_id,\n        MIN(schema_version) as min_schema_version,\n        MAX(schema_version) as max_schema_version\n    FROM\n        newtab\n    GROUP BY\n        dump_id\n    ON CONFLICT (dump_id) DO UPDATE SET\n        -- Update with min(old_min, new_min) and max(old_max, new_max)\n        min_schema_version = LEAST   (lsif_data_implementations_schema_versions.min_schema_version, EXCLUDED.min_schema_version),\n        max_schema_version = GREATEST(lsif_data_implementations_schema_versions.max_schema_version, EXCLUDED.max_schema_version);\n\n    RETURN NULL;\nEND $$ LANGUAGE plpgsql;\n\nCREATE TRIGGER lsif_data_implementations_schema_versions_insert\n    AFTER INSERT ON lsif_data_implementations REFERENCING NEW TABLE AS newtab\n    FOR EACH STATEMENT EXECUTE PROCEDURE update_lsif_data_implementations_schema_versions_insert();",
				"DownQuery": "DROP TABLE lsif_data_implementations_schema_versions;\nDROP TRIGGER lsif_data_implementations_schema_versions_insert ON lsif_data_implementations;\nDROP FUNCTION update_lsif_data_implementations_schema_versions_insert;\n\nDROP TABLE lsif_data_implementations;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000029
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000031,
				"Name": "intarray extension",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS intarray;\n\nCOMMENT ON EXTENSION intarray IS 'functions, operators, and index support for 1-D arrays of integers';",
				"DownQuery": "DROP EXTENSION IF EXISTS intarray;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1000000030
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000032,
				"Name": "rockskip",
				"UpQuery": "CREATE TABLE IF NOT EXISTS rockskip_repos (\n    id               SERIAL    PRIMARY KEY,\n    repo             TEXT      NOT NULL,\n    last_accessed_at TIMESTAMP WITH TIME ZONE NOT NULL,\n    UNIQUE (repo)\n);\n\nCREATE TABLE IF NOT EXISTS rockskip_ancestry (\n    id          SERIAL      PRIMARY KEY,\n    repo_id     INTEGER     NOT NULL,\n    commit_id   VARCHAR(40) NOT NULL,\n    height      INTEGER     NOT NULL,\n    ancestor    INTEGER     NOT NULL,\n    UNIQUE (repo_id, commit_id)\n);\n\n-- Insert the null commit. repo_id 0 will not conflict with other repos because SERIAL's MINVALUE\n-- defaults to 1.\nINSERT INTO rockskip_ancestry\n       (id, commit_id                                 , repo_id    , height, ancestor)\nVALUES (0 , '0000000000000000000000000000000000000000', 0          , 0     , 0       )\nON CONFLICT DO NOTHING;\n\nCREATE TABLE IF NOT EXISTS rockskip_symbols (\n    -- Globally unique ID of this instance of the symbol.\n    id           SERIAL        PRIMARY KEY,\n    added        INTEGER[]     NOT NULL,\n    deleted      INTEGER[]     NOT NULL,\n\n    -- Since we only support searching by symbol name and we re-parse the file at query time, symbols\n    -- with the same name in the same file only need to be stored once. Upon re-parsing the file at query\n    -- time we will discover all symbols that match.\n    repo_id      INTEGER       NOT NULL,\n    path         TEXT          NOT NULL,\n    name         TEXT          NOT NULL\n);\n\nCREATE OR REPLACE FUNCTION singleton(value TEXT) RETURNS TEXT[] AS $$ BEGIN\n    RETURN ARRAY[value];\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE OR REPLACE FUNCTION singleton_integer(value INTEGER) RETURNS INTEGER[] AS $$ BEGIN\n    RETURN ARRAY[value];\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE OR REPLACE FUNCTION path_prefixes(path TEXT) RETURNS TEXT[] AS $$ BEGIN\n    RETURN (\n        SELECT array_agg(array_to_string(components[:len], '/')) prefixes\n        FROM\n            (SELECT regexp_split_to_array(path, E'/') components) t,\n            generate_series(1, array_length(components, 1)) AS len\n    );\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE INDEX IF NOT EXISTS rockskip_repos_repo ON rockskip_repos(repo);\n\nCREATE INDEX IF NOT EXISTS rockskip_repos_last_accessed_at ON rockskip_repos(last_accessed_at);\n\nCREATE INDEX IF NOT EXISTS rockskip_ancestry_repo_commit_id ON rockskip_ancestry(repo_id, commit_id);\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_repo_id_path_name ON rockskip_symbols(repo_id, path, name);\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    singleton_integer(repo_id) gin__int_ops,\n    added gin__int_ops,\n    deleted gin__int_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(name),\n    name gin_trgm_ops\n);",
				"DownQuery": "DROP TABLE IF EXISTS rockskip_ancestry;\nDROP TABLE IF EXISTS rockskip_symbols;\nDROP TABLE IF EXISTS rockskip_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000031
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000033,
				"Name": "rockskip file extension",
				"UpQuery": "DROP INDEX IF EXISTS rockskip_symbols_gin;\n\nCREATE OR REPLACE FUNCTION get_file_extension(path TEXT) RETURNS TEXT AS $$ BEGIN\n    RETURN substring(path FROM '\\.([^\\.]*)$');\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    singleton_integer(repo_id) gin__int_ops,\n    added gin__int_ops,\n    deleted gin__int_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(name),\n    name gin_trgm_ops,\n    singleton(get_file_extension(path))\n);",
				"DownQuery": "DROP INDEX IF EXISTS rockskip_symbols_gin;\n\nDROP FUNCTION IF EXISTS get_file_extension;\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    singleton_integer(repo_id) gin__int_ops,\n    added gin__int_ops,\n    deleted gin__int_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(name),\n    name gin_trgm_ops\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000032
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1000000034,
				"Name": "rockskip lowercase",
				"UpQuery": "DROP INDEX IF EXISTS rockskip_symbols_gin;\n\nCREATE OR REPLACE FUNCTION get_file_extension(path TEXT) RETURNS TEXT AS $$ BEGIN\n    RETURN substring(path FROM '\\.([^\\.]*)$');\nEND; $$ IMMUTABLE language plpgsql;\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    -- repo_id\n    singleton_integer(repo_id) gin__int_ops,\n\n    -- added,deleted\n    added gin__int_ops,\n    deleted gin__int_ops,\n\n    -- name\n    name gin_trgm_ops,\n    singleton(name),\n    singleton(lower(name)),\n\n    -- path\n    path gin_trgm_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(lower(path)),\n    path_prefixes(lower(path)),\n\n    -- file extension\n    singleton(get_file_extension(path)),\n    singleton(get_file_extension(lower(path)))\n);",
				"DownQuery": "DROP INDEX IF EXISTS rockskip_symbols_gin;\n\nCREATE INDEX IF NOT EXISTS rockskip_symbols_gin ON rockskip_symbols USING GIN (\n    singleton_integer(repo_id) gin__int_ops,\n    added gin__int_ops,\n    deleted gin__int_ops,\n    singleton(path),\n    path_prefixes(path),\n    singleton(name),\n    name gin_trgm_ops,\n    singleton(get_file_extension(path))\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1000000033
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			}
		],
		"BoundsByRev": {
			"v3.29.0": {
				"RootID": -1000000005,
				"LeafIDs": [
					1000000015
				]
			},
			"v3.30.0": {
				"RootID": -1000000005,
				"LeafIDs": [
					1000000018
				]
			},
			"v3.31.0": {
				"RootID": -1000000005,
				"LeafIDs": [
					1000000019
				]
			},
			"v3.32.0": {
				"RootID": -1000000005,
				"LeafIDs": [
					1000000019
				]
			},
			"v3.33.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000025
				]
			},
			"v3.34.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000030
				]
			},
			"v3.35.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000030
				]
			},
			"v3.36.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000030
				]
			},
			"v3.37.0": {
				"RootID": -1000000015,
				"LeafIDs": [
					1000000030
				]
			},
			"v3.38.0": {
				"RootID": 1000000029,
				"LeafIDs": [
					1000000034
				]
			},
			"v3.39.0": {
				"RootID": 1000000029,
				"LeafIDs": [
					1000000034
				]
			},
			"v3.40.0": {
				"RootID": 1000000029,
				"LeafIDs": [
					1000000034
				]
			},
			"v3.41.0": {
				"RootID": 1000000029,
				"LeafIDs": [
					1000000034
				]
			},
			"v3.42.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1000000034
				]
			},
			"v3.43.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1000000034
				]
			},
			"v4.0.0": {
				"RootID": 1000000033,
				"LeafIDs": [
					1000000034
				]
			}
		}
	},
	"frontend": {
		"Definitions": [
			{
				"ID": -1528395787,
				"Name": "squashed migrations (privileged)",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS citext;\n\nCOMMENT ON EXTENSION citext IS 'data type for case-insensitive character strings';\n\nCREATE EXTENSION IF NOT EXISTS hstore;\n\nCOMMENT ON EXTENSION hstore IS 'data type for storing sets of (key, value) pairs';\n\nCREATE EXTENSION IF NOT EXISTS intarray;\n\nCOMMENT ON EXTENSION intarray IS 'functions, operators, and index support for 1-D arrays of integers';\n\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n\nCOMMENT ON EXTENSION pg_stat_statements IS 'track execution statistics of all SQL statements executed';\n\nCREATE EXTENSION IF NOT EXISTS pg_trgm;\n\nCOMMENT ON EXTENSION pg_trgm IS 'text similarity measurement and index searching based on trigrams';",
				"DownQuery": "",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": null,
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395787,
				"Name": "squashed migrations",
				"UpQuery": "CREATE TYPE cm_email_priority AS ENUM (\n    'NORMAL',\n    'CRITICAL'\n);\n\nCREATE TYPE critical_or_site AS ENUM (\n    'critical',\n    'site'\n);\n\nCREATE TYPE lsif_index_state AS ENUM (\n    'queued',\n    'processing',\n    'completed',\n    'errored',\n    'failed'\n);\n\nCREATE TYPE lsif_upload_state AS ENUM (\n    'uploading',\n    'queued',\n    'processing',\n    'completed',\n    'errored',\n    'deleted',\n    'failed'\n);\n\nCREATE FUNCTION delete_campaign_reference_on_changesets() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        UPDATE\n          changesets\n        SET\n          campaign_ids = changesets.campaign_ids - OLD.id::text\n        WHERE\n          changesets.campaign_ids ? OLD.id::text;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE FUNCTION delete_external_service_ref_on_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        -- if an external service is soft-deleted, delete every row that references it\n        IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n          DELETE FROM\n            external_service_repos\n          WHERE\n            external_service_id = OLD.id;\n        END IF;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE FUNCTION delete_repo_ref_on_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        -- if a repo is soft-deleted, delete every row that references that repo\n        IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n        DELETE FROM\n            external_service_repos\n        WHERE\n            repo_id = OLD.id;\n        END IF;\n\n        RETURN OLD;\n    END;\n$$;\n\nCREATE FUNCTION invalidate_session_for_userid_on_password_change() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        IF OLD.passwd != NEW.passwd THEN\n            NEW.invalidated_sessions_at = now() + (1 * interval '1 second');\n            RETURN NEW;\n        END IF;\n    RETURN NEW;\n    END;\n$$;\n\nCREATE FUNCTION soft_delete_orphan_repo_by_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\n    -- When an external service is soft or hard-deleted,\n    -- performs a clean up to soft-delete orphan repositories.\n    UPDATE\n        repo\n    SET\n        name = soft_deleted_repository_name(name),\n        deleted_at = transaction_timestamp()\n    WHERE\n      deleted_at IS NULL\n      AND NOT EXISTS (\n        SELECT FROM external_service_repos WHERE repo_id = repo.id\n    );\n\n    RETURN NULL;\nEND;\n$$;\n\nCREATE FUNCTION soft_delete_user_reference_on_external_service() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\nBEGIN\n    -- If a user is soft-deleted, delete every row that references that user\n    IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n        UPDATE external_services\n        SET deleted_at = NOW()\n        WHERE namespace_user_id = OLD.id;\n    END IF;\n\n    RETURN OLD;\nEND;\n$$;\n\nCREATE FUNCTION soft_deleted_repository_name(name text) RETURNS text\n    LANGUAGE plpgsql STRICT\n    AS $$\nBEGIN\n    RETURN 'DELETED-' || extract(epoch from transaction_timestamp()) || '-' || name;\nEND;\n$$;\n\nCREATE TABLE access_tokens (\n    id bigint NOT NULL,\n    subject_user_id integer NOT NULL,\n    value_sha256 bytea NOT NULL,\n    note text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    last_used_at timestamp with time zone,\n    deleted_at timestamp with time zone,\n    creator_user_id integer NOT NULL,\n    scopes text[] NOT NULL\n);\n\nCREATE SEQUENCE access_tokens_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE access_tokens_id_seq OWNED BY access_tokens.id;\n\nCREATE TABLE changeset_specs (\n    id bigint NOT NULL,\n    rand_id text NOT NULL,\n    raw_spec text NOT NULL,\n    spec jsonb DEFAULT '{}'::jsonb NOT NULL,\n    campaign_spec_id bigint,\n    repo_id integer NOT NULL,\n    user_id integer,\n    diff_stat_added integer,\n    diff_stat_changed integer,\n    diff_stat_deleted integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    head_ref text,\n    title text,\n    external_id text\n);\n\nCREATE TABLE changesets (\n    id bigint NOT NULL,\n    campaign_ids jsonb DEFAULT '{}'::jsonb NOT NULL,\n    repo_id integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    metadata jsonb DEFAULT '{}'::jsonb,\n    external_id text,\n    external_service_type text NOT NULL,\n    external_deleted_at timestamp with time zone,\n    external_branch text,\n    external_updated_at timestamp with time zone,\n    external_state text,\n    external_review_state text,\n    external_check_state text,\n    diff_stat_added integer,\n    diff_stat_changed integer,\n    diff_stat_deleted integer,\n    sync_state jsonb DEFAULT '{}'::jsonb NOT NULL,\n    current_spec_id bigint,\n    previous_spec_id bigint,\n    publication_state text DEFAULT 'UNPUBLISHED'::text,\n    owned_by_campaign_id bigint,\n    reconciler_state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    closing boolean DEFAULT false NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    log_contents text,\n    execution_logs json[],\n    syncer_error text,\n    CONSTRAINT changesets_campaign_ids_check CHECK ((jsonb_typeof(campaign_ids) = 'object'::text)),\n    CONSTRAINT changesets_external_id_check CHECK ((external_id \u003c\u003e ''::text)),\n    CONSTRAINT changesets_external_service_type_not_blank CHECK ((external_service_type \u003c\u003e ''::text)),\n    CONSTRAINT changesets_metadata_check CHECK ((jsonb_typeof(metadata) = 'object'::text)),\n    CONSTRAINT external_branch_ref_prefix CHECK ((external_branch ~~ 'refs/heads/%'::text))\n);\n\nCREATE TABLE repo (\n    id integer NOT NULL,\n    name citext NOT NULL,\n    description text,\n    fork boolean,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone,\n    external_id text,\n    external_service_type text,\n    external_service_id text,\n    archived boolean DEFAULT false NOT NULL,\n    uri citext,\n    deleted_at timestamp with time zone,\n    metadata jsonb DEFAULT '{}'::jsonb NOT NULL,\n    private boolean DEFAULT false NOT NULL,\n    cloned boolean DEFAULT false NOT NULL,\n    CONSTRAINT check_name_nonempty CHECK ((name OPERATOR(\u003c\u003e) ''::citext)),\n    CONSTRAINT repo_metadata_check CHECK ((jsonb_typeof(metadata) = 'object'::text))\n);\n\nCREATE VIEW branch_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.campaign_spec_id,\n    changesets.owned_by_campaign_id AS owner_campaign_id,\n    repo.name AS repo_name,\n    changeset_specs.title AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.current_spec_id IS NOT NULL) AND (EXISTS ( SELECT 1\n           FROM changeset_specs changeset_specs_1\n          WHERE ((changeset_specs_1.id = changesets.current_spec_id) AND (changeset_specs_1.head_ref = changeset_specs.head_ref)))))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NULL) AND (repo.deleted_at IS NULL));\n\nCREATE TABLE campaign_specs (\n    id bigint NOT NULL,\n    rand_id text NOT NULL,\n    raw_spec text NOT NULL,\n    spec jsonb DEFAULT '{}'::jsonb NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer,\n    user_id integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT campaign_specs_has_1_namespace CHECK (((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL)))\n);\n\nCREATE SEQUENCE campaign_specs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE campaign_specs_id_seq OWNED BY campaign_specs.id;\n\nCREATE TABLE campaigns (\n    id bigint NOT NULL,\n    name text NOT NULL,\n    description text,\n    initial_applier_id integer,\n    namespace_user_id integer,\n    namespace_org_id integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    closed_at timestamp with time zone,\n    campaign_spec_id bigint NOT NULL,\n    last_applier_id bigint,\n    last_applied_at timestamp with time zone NOT NULL,\n    CONSTRAINT campaigns_has_1_namespace CHECK (((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL))),\n    CONSTRAINT campaigns_name_not_blank CHECK ((name \u003c\u003e ''::text))\n);\n\nCREATE SEQUENCE campaigns_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE campaigns_id_seq OWNED BY campaigns.id;\n\nCREATE TABLE changeset_events (\n    id bigint NOT NULL,\n    changeset_id bigint NOT NULL,\n    kind text NOT NULL,\n    key text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    metadata jsonb DEFAULT '{}'::jsonb NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT changeset_events_key_check CHECK ((key \u003c\u003e ''::text)),\n    CONSTRAINT changeset_events_kind_check CHECK ((kind \u003c\u003e ''::text)),\n    CONSTRAINT changeset_events_metadata_check CHECK ((jsonb_typeof(metadata) = 'object'::text))\n);\n\nCREATE SEQUENCE changeset_events_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changeset_events_id_seq OWNED BY changeset_events.id;\n\nCREATE SEQUENCE changeset_specs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changeset_specs_id_seq OWNED BY changeset_specs.id;\n\nCREATE SEQUENCE changesets_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE changesets_id_seq OWNED BY changesets.id;\n\nCREATE TABLE cm_action_jobs (\n    id integer NOT NULL,\n    email bigint NOT NULL,\n    state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    log_contents text,\n    trigger_event integer\n);\n\nCREATE SEQUENCE cm_action_jobs_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_action_jobs_id_seq OWNED BY cm_action_jobs.id;\n\nCREATE TABLE cm_emails (\n    id bigint NOT NULL,\n    monitor bigint NOT NULL,\n    enabled boolean NOT NULL,\n    priority cm_email_priority NOT NULL,\n    header text NOT NULL,\n    created_by integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    changed_by integer NOT NULL,\n    changed_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE SEQUENCE cm_emails_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_emails_id_seq OWNED BY cm_emails.id;\n\nCREATE TABLE cm_monitors (\n    id bigint NOT NULL,\n    created_by integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    description text NOT NULL,\n    changed_at timestamp with time zone DEFAULT now() NOT NULL,\n    changed_by integer NOT NULL,\n    enabled boolean DEFAULT true NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer\n);\n\nCREATE SEQUENCE cm_monitors_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_monitors_id_seq OWNED BY cm_monitors.id;\n\nCREATE TABLE cm_queries (\n    id bigint NOT NULL,\n    monitor bigint NOT NULL,\n    query text NOT NULL,\n    created_by integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    changed_by integer NOT NULL,\n    changed_at timestamp with time zone DEFAULT now() NOT NULL,\n    next_run timestamp with time zone DEFAULT now(),\n    latest_result timestamp with time zone\n);\n\nCREATE SEQUENCE cm_queries_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_queries_id_seq OWNED BY cm_queries.id;\n\nCREATE TABLE cm_recipients (\n    id bigint NOT NULL,\n    email bigint NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer\n);\n\nCREATE SEQUENCE cm_recipients_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_recipients_id_seq OWNED BY cm_recipients.id;\n\nCREATE TABLE cm_trigger_jobs (\n    id integer NOT NULL,\n    query bigint NOT NULL,\n    state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    log_contents text,\n    query_string text,\n    results boolean,\n    num_results integer\n);\n\nCREATE SEQUENCE cm_trigger_jobs_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE cm_trigger_jobs_id_seq OWNED BY cm_trigger_jobs.id;\n\nCREATE TABLE critical_and_site_config (\n    id integer NOT NULL,\n    type critical_or_site NOT NULL,\n    contents text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE SEQUENCE critical_and_site_config_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE critical_and_site_config_id_seq OWNED BY critical_and_site_config.id;\n\nCREATE TABLE default_repos (\n    repo_id integer NOT NULL\n);\n\nCREATE TABLE discussion_comments (\n    id bigint NOT NULL,\n    thread_id bigint NOT NULL,\n    author_user_id integer NOT NULL,\n    contents text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    reports text[] DEFAULT '{}'::text[] NOT NULL\n);\n\nCREATE SEQUENCE discussion_comments_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE discussion_comments_id_seq OWNED BY discussion_comments.id;\n\nCREATE TABLE discussion_mail_reply_tokens (\n    token text NOT NULL,\n    user_id integer NOT NULL,\n    thread_id bigint NOT NULL,\n    deleted_at timestamp with time zone\n);\n\nCREATE TABLE discussion_threads (\n    id bigint NOT NULL,\n    author_user_id integer NOT NULL,\n    title text,\n    target_repo_id bigint,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    archived_at timestamp with time zone,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone\n);\n\nCREATE SEQUENCE discussion_threads_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE discussion_threads_id_seq OWNED BY discussion_threads.id;\n\nCREATE TABLE discussion_threads_target_repo (\n    id bigint NOT NULL,\n    thread_id bigint NOT NULL,\n    repo_id integer NOT NULL,\n    path text,\n    branch text,\n    revision text,\n    start_line integer,\n    end_line integer,\n    start_character integer,\n    end_character integer,\n    lines_before text,\n    lines text,\n    lines_after text\n);\n\nCREATE SEQUENCE discussion_threads_target_repo_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE discussion_threads_target_repo_id_seq OWNED BY discussion_threads_target_repo.id;\n\nCREATE TABLE event_logs (\n    id bigint NOT NULL,\n    name text NOT NULL,\n    url text NOT NULL,\n    user_id integer NOT NULL,\n    anonymous_user_id text NOT NULL,\n    source text NOT NULL,\n    argument jsonb NOT NULL,\n    version text NOT NULL,\n    \"timestamp\" timestamp with time zone NOT NULL,\n    CONSTRAINT event_logs_check_has_user CHECK ((((user_id = 0) AND (anonymous_user_id \u003c\u003e ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id = ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id \u003c\u003e ''::text)))),\n    CONSTRAINT event_logs_check_name_not_empty CHECK ((name \u003c\u003e ''::text)),\n    CONSTRAINT event_logs_check_source_not_empty CHECK ((source \u003c\u003e ''::text)),\n    CONSTRAINT event_logs_check_version_not_empty CHECK ((version \u003c\u003e ''::text))\n);\n\nCREATE SEQUENCE event_logs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE event_logs_id_seq OWNED BY event_logs.id;\n\nCREATE TABLE external_service_repos (\n    external_service_id bigint NOT NULL,\n    repo_id integer NOT NULL,\n    clone_url text NOT NULL\n);\n\nCREATE SEQUENCE external_service_sync_jobs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nCREATE TABLE external_service_sync_jobs (\n    id integer DEFAULT nextval('external_service_sync_jobs_id_seq'::regclass) NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    external_service_id bigint,\n    num_failures integer DEFAULT 0 NOT NULL,\n    log_contents text,\n    execution_logs json[]\n);\n\nCREATE TABLE external_services (\n    id bigint NOT NULL,\n    kind text NOT NULL,\n    display_name text NOT NULL,\n    config text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    last_sync_at timestamp with time zone,\n    next_sync_at timestamp with time zone,\n    namespace_user_id integer,\n    unrestricted boolean DEFAULT false NOT NULL,\n    cloud_default boolean DEFAULT false NOT NULL,\n    CONSTRAINT check_non_empty_config CHECK ((btrim(config) \u003c\u003e ''::text))\n);\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS\n SELECT j.id,\n    j.state,\n    j.failure_message,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.execution_logs,\n    j.external_service_id,\n    e.next_sync_at\n   FROM (external_services e\n     JOIN external_service_sync_jobs j ON ((e.id = j.external_service_id)));\n\nCREATE SEQUENCE external_services_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE external_services_id_seq OWNED BY external_services.id;\n\nCREATE TABLE global_state (\n    site_id uuid NOT NULL,\n    initialized boolean DEFAULT false NOT NULL,\n    mgmt_password_plaintext text DEFAULT ''::text NOT NULL,\n    mgmt_password_bcrypt text DEFAULT ''::text NOT NULL\n);\n\nCREATE TABLE insights_query_runner_jobs (\n    id integer NOT NULL,\n    series_id text NOT NULL,\n    search_query text NOT NULL,\n    state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[]\n);\n\nCOMMENT ON TABLE insights_query_runner_jobs IS 'See [enterprise/internal/insights/background/queryrunner/worker.go:Job](https://sourcegraph.com/search?q=repo:%5Egithub%5C.com/sourcegraph/sourcegraph%24+file:enterprise/internal/insights/background/queryrunner/worker.go+type+Job\u0026patternType=literal)';\n\nCREATE SEQUENCE insights_query_runner_jobs_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE insights_query_runner_jobs_id_seq OWNED BY insights_query_runner_jobs.id;\n\nCREATE TABLE lsif_dirty_repositories (\n    repository_id integer NOT NULL,\n    dirty_token integer NOT NULL,\n    update_token integer NOT NULL,\n    updated_at timestamp with time zone\n);\n\nCOMMENT ON TABLE lsif_dirty_repositories IS 'Stores whether or not the nearest upload data for a repository is out of date (when update_token \u003e dirty_token).';\n\nCOMMENT ON COLUMN lsif_dirty_repositories.dirty_token IS 'Set to the value of update_token visible to the transaction that updates the commit graph. Updates of dirty_token during this time will cause a second update.';\n\nCOMMENT ON COLUMN lsif_dirty_repositories.update_token IS 'This value is incremented on each request to update the commit graph for the repository.';\n\nCOMMENT ON COLUMN lsif_dirty_repositories.updated_at IS 'The time the update_token value was last updated.';\n\nCREATE TABLE lsif_uploads (\n    id integer NOT NULL,\n    commit text NOT NULL,\n    root text DEFAULT ''::text NOT NULL,\n    uploaded_at timestamp with time zone DEFAULT now() NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    repository_id integer NOT NULL,\n    indexer text NOT NULL,\n    num_parts integer NOT NULL,\n    uploaded_parts integer[] NOT NULL,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    upload_size bigint,\n    num_failures integer DEFAULT 0 NOT NULL,\n    associated_index_id bigint,\n    CONSTRAINT lsif_uploads_commit_valid_chars CHECK ((commit ~ '^[a-z0-9]{40}$'::text))\n);\n\nCOMMENT ON TABLE lsif_uploads IS 'Stores metadata about an LSIF index uploaded by a user.';\n\nCOMMENT ON COLUMN lsif_uploads.id IS 'Used as a logical foreign key with the (disjoint) codeintel database.';\n\nCOMMENT ON COLUMN lsif_uploads.commit IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_uploads.root IS 'The path for which the index can resolve code intelligence relative to the repository root.';\n\nCOMMENT ON COLUMN lsif_uploads.indexer IS 'The name of the indexer that produced the index file. If not supplied by the user it will be pulled from the index metadata.';\n\nCOMMENT ON COLUMN lsif_uploads.num_parts IS 'The number of parts src-cli split the upload file into.';\n\nCOMMENT ON COLUMN lsif_uploads.uploaded_parts IS 'The index of parts that have been successfully uploaded.';\n\nCOMMENT ON COLUMN lsif_uploads.upload_size IS 'The size of the index file (in bytes).';\n\nCREATE VIEW lsif_dumps AS\n SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.finished_at AS processed_at\n   FROM lsif_uploads u\n  WHERE (u.state = 'completed'::text);\n\nCREATE SEQUENCE lsif_dumps_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_dumps_id_seq OWNED BY lsif_uploads.id;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.processed_at,\n    r.name AS repository_name\n   FROM (lsif_dumps u\n     JOIN repo r ON ((r.id = u.repository_id)))\n  WHERE (r.deleted_at IS NULL);\n\nCREATE TABLE lsif_index_configuration (\n    id bigint NOT NULL,\n    repository_id integer NOT NULL,\n    data bytea NOT NULL\n);\n\nCOMMENT ON TABLE lsif_index_configuration IS 'Stores the configuration used for code intel index jobs for a repository.';\n\nCOMMENT ON COLUMN lsif_index_configuration.data IS 'The raw user-supplied [configuration](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/autoindex/config/types.go#L3:6) (encoded in JSONC).';\n\nCREATE SEQUENCE lsif_index_configuration_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_index_configuration_id_seq OWNED BY lsif_index_configuration.id;\n\nCREATE TABLE lsif_indexable_repositories (\n    id integer NOT NULL,\n    repository_id integer NOT NULL,\n    search_count integer DEFAULT 0 NOT NULL,\n    precise_count integer DEFAULT 0 NOT NULL,\n    last_index_enqueued_at timestamp with time zone,\n    last_updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    enabled boolean\n);\n\nCOMMENT ON TABLE lsif_indexable_repositories IS 'Stores the number of code intel events for repositories. Used for auto-index scheduling heursitics Sourcegraph Cloud.';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.search_count IS 'The number of search-based code intel events for the repository in the past week.';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.precise_count IS 'The number of precise code intel events for the repository in the past week.';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.last_index_enqueued_at IS 'The last time an index for the repository was enqueued (for basic rate limiting).';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.last_updated_at IS 'The last time the event counts were updated for this repository.';\n\nCOMMENT ON COLUMN lsif_indexable_repositories.enabled IS '**Column unused.**';\n\nCREATE SEQUENCE lsif_indexable_repositories_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_indexable_repositories_id_seq OWNED BY lsif_indexable_repositories.id;\n\nCREATE TABLE lsif_indexes (\n    id bigint NOT NULL,\n    commit text NOT NULL,\n    queued_at timestamp with time zone DEFAULT now() NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    repository_id integer NOT NULL,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    docker_steps jsonb[] NOT NULL,\n    root text NOT NULL,\n    indexer text NOT NULL,\n    indexer_args text[] NOT NULL,\n    outfile text NOT NULL,\n    log_contents text,\n    execution_logs json[],\n    local_steps text[] NOT NULL,\n    CONSTRAINT lsif_uploads_commit_valid_chars CHECK ((commit ~ '^[a-z0-9]{40}$'::text))\n);\n\nCOMMENT ON TABLE lsif_indexes IS 'Stores metadata about a code intel index job.';\n\nCOMMENT ON COLUMN lsif_indexes.commit IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_indexes.docker_steps IS 'An array of pre-index [steps](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/stores/dbstore/docker_step.go#L9:6) to run.';\n\nCOMMENT ON COLUMN lsif_indexes.root IS 'The working directory of the indexer image relative to the repository root.';\n\nCOMMENT ON COLUMN lsif_indexes.indexer IS 'The docker image used to run the index command (e.g. sourcegraph/lsif-go).';\n\nCOMMENT ON COLUMN lsif_indexes.indexer_args IS 'The command run inside the indexer image to produce the index file (e.g. [''lsif-node'', ''-p'', ''.''])';\n\nCOMMENT ON COLUMN lsif_indexes.outfile IS 'The path to the index file produced by the index command relative to the working directory.';\n\nCOMMENT ON COLUMN lsif_indexes.log_contents IS '**Column deprecated in favor of execution_logs.**';\n\nCOMMENT ON COLUMN lsif_indexes.execution_logs IS 'An array of [log entries](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/internal/workerutil/store.go#L48:6) (encoded as JSON) from the most recent execution.';\n\nCOMMENT ON COLUMN lsif_indexes.local_steps IS 'A list of commands to run inside the indexer image prior to running the indexer command.';\n\nCREATE SEQUENCE lsif_indexes_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_indexes_id_seq OWNED BY lsif_indexes.id;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\n SELECT u.id,\n    u.commit,\n    u.queued_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.process_after,\n    u.num_resets,\n    u.num_failures,\n    u.docker_steps,\n    u.root,\n    u.indexer,\n    u.indexer_args,\n    u.outfile,\n    u.log_contents,\n    u.execution_logs,\n    u.local_steps,\n    r.name AS repository_name\n   FROM (lsif_indexes u\n     JOIN repo r ON ((r.id = u.repository_id)))\n  WHERE (r.deleted_at IS NULL);\n\nCREATE TABLE lsif_nearest_uploads (\n    repository_id integer NOT NULL,\n    commit_bytea bytea NOT NULL,\n    uploads jsonb NOT NULL\n);\n\nCOMMENT ON TABLE lsif_nearest_uploads IS 'Associates commits with the complete set of uploads visible from that commit. Every commit with upload data is present in this table.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads.commit_bytea IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads.uploads IS 'Encodes an {upload_id =\u003e distance} map that includes an entry for every upload visible from the commit. There is always at least one entry with a distance of zero.';\n\nCREATE TABLE lsif_nearest_uploads_links (\n    repository_id integer NOT NULL,\n    commit_bytea bytea NOT NULL,\n    ancestor_commit_bytea bytea NOT NULL,\n    distance integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_nearest_uploads_links IS 'Associates commits with the closest ancestor commit with usable upload data. Together, this table and lsif_nearest_uploads cover all commits with resolvable code intelligence.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads_links.commit_bytea IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads_links.ancestor_commit_bytea IS 'The 40-char revhash of the ancestor. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN lsif_nearest_uploads_links.distance IS 'The distance bewteen the commits. Parent = 1, Grandparent = 2, etc.';\n\nCREATE TABLE lsif_packages (\n    id integer NOT NULL,\n    scheme text NOT NULL,\n    name text NOT NULL,\n    version text,\n    dump_id integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_packages IS 'Associates an upload with the set of packages they provide within a given packages management scheme.';\n\nCOMMENT ON COLUMN lsif_packages.scheme IS 'The (export) moniker scheme.';\n\nCOMMENT ON COLUMN lsif_packages.name IS 'The package name.';\n\nCOMMENT ON COLUMN lsif_packages.version IS 'The package version.';\n\nCOMMENT ON COLUMN lsif_packages.dump_id IS 'The identifier of the upload that provides the package.';\n\nCREATE SEQUENCE lsif_packages_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_packages_id_seq OWNED BY lsif_packages.id;\n\nCREATE TABLE lsif_references (\n    id integer NOT NULL,\n    scheme text NOT NULL,\n    name text NOT NULL,\n    version text,\n    filter bytea NOT NULL,\n    dump_id integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_references IS 'Associates an upload with the set of packages they require within a given packages management scheme.';\n\nCOMMENT ON COLUMN lsif_references.scheme IS 'The (import) moniker scheme.';\n\nCOMMENT ON COLUMN lsif_references.name IS 'The package name.';\n\nCOMMENT ON COLUMN lsif_references.version IS 'The package version.';\n\nCOMMENT ON COLUMN lsif_references.filter IS 'A [bloom filter](https://sourcegraph.com/github.com/sourcegraph/sourcegraph@3.23/-/blob/enterprise/internal/codeintel/bloomfilter/bloom_filter.go#L27:6) encoded as gzipped JSON. This bloom filter stores the set of identifiers imported from the package.';\n\nCOMMENT ON COLUMN lsif_references.dump_id IS 'The identifier of the upload that references the package.';\n\nCREATE SEQUENCE lsif_references_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE lsif_references_id_seq OWNED BY lsif_references.id;\n\nCREATE TABLE lsif_uploads_visible_at_tip (\n    repository_id integer NOT NULL,\n    upload_id integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_uploads_visible_at_tip IS 'Associates a repository with the set of LSIF upload identifiers that can serve intelligence for the tip of the default branch.';\n\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.upload_id IS 'The identifier of an upload visible at the tip of the default branch.';\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    r.name AS repository_name\n   FROM (lsif_uploads u\n     JOIN repo r ON ((r.id = u.repository_id)))\n  WHERE (r.deleted_at IS NULL);\n\nCREATE TABLE names (\n    name citext NOT NULL,\n    user_id integer,\n    org_id integer,\n    CONSTRAINT names_check CHECK (((user_id IS NOT NULL) OR (org_id IS NOT NULL)))\n);\n\nCREATE TABLE org_invitations (\n    id bigint NOT NULL,\n    org_id integer NOT NULL,\n    sender_user_id integer NOT NULL,\n    recipient_user_id integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    notified_at timestamp with time zone,\n    responded_at timestamp with time zone,\n    response_type boolean,\n    revoked_at timestamp with time zone,\n    deleted_at timestamp with time zone,\n    CONSTRAINT check_atomic_response CHECK (((responded_at IS NULL) = (response_type IS NULL))),\n    CONSTRAINT check_single_use CHECK ((((responded_at IS NULL) AND (response_type IS NULL)) OR (revoked_at IS NULL)))\n);\n\nCREATE SEQUENCE org_invitations_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE org_invitations_id_seq OWNED BY org_invitations.id;\n\nCREATE TABLE org_members (\n    id integer NOT NULL,\n    org_id integer NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    user_id integer NOT NULL\n);\n\nCREATE TABLE org_members_bkup_1514536731 (\n    id integer,\n    org_id integer,\n    user_id_old text,\n    created_at timestamp with time zone,\n    updated_at timestamp with time zone,\n    user_id integer\n);\n\nCREATE SEQUENCE org_members_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE org_members_id_seq OWNED BY org_members.id;\n\nCREATE TABLE orgs (\n    id integer NOT NULL,\n    name citext NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    display_name text,\n    slack_webhook_url text,\n    deleted_at timestamp with time zone,\n    CONSTRAINT orgs_display_name_max_length CHECK ((char_length(display_name) \u003c= 255)),\n    CONSTRAINT orgs_name_max_length CHECK ((char_length((name)::text) \u003c= 255)),\n    CONSTRAINT orgs_name_valid_chars CHECK ((name OPERATOR(~) '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[-.](?=[a-zA-Z0-9]))*-?$'::citext))\n);\n\nCREATE SEQUENCE orgs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE orgs_id_seq OWNED BY orgs.id;\n\nCREATE TABLE out_of_band_migrations (\n    id integer NOT NULL,\n    team text NOT NULL,\n    component text NOT NULL,\n    description text NOT NULL,\n    introduced text NOT NULL,\n    deprecated text,\n    progress double precision DEFAULT 0 NOT NULL,\n    created timestamp with time zone DEFAULT now() NOT NULL,\n    last_updated timestamp with time zone,\n    non_destructive boolean NOT NULL,\n    apply_reverse boolean DEFAULT false NOT NULL,\n    CONSTRAINT out_of_band_migrations_component_nonempty CHECK ((component \u003c\u003e ''::text)),\n    CONSTRAINT out_of_band_migrations_deprecated_valid_version CHECK ((deprecated ~ '^(\\d+)\\.(\\d+)\\.(\\d+)$'::text)),\n    CONSTRAINT out_of_band_migrations_description_nonempty CHECK ((description \u003c\u003e ''::text)),\n    CONSTRAINT out_of_band_migrations_introduced_valid_version CHECK ((introduced ~ '^(\\d+)\\.(\\d+)\\.(\\d+)$'::text)),\n    CONSTRAINT out_of_band_migrations_progress_range CHECK (((progress \u003e= (0)::double precision) AND (progress \u003c= (1)::double precision))),\n    CONSTRAINT out_of_band_migrations_team_nonempty CHECK ((team \u003c\u003e ''::text))\n);\n\nCOMMENT ON TABLE out_of_band_migrations IS 'Stores metadata and progress about an out-of-band migration routine.';\n\nCOMMENT ON COLUMN out_of_band_migrations.id IS 'A globally unique primary key for this migration. The same key is used consistently across all Sourcegraph instances for the same migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations.team IS 'The name of the engineering team responsible for the migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations.component IS 'The name of the component undergoing a migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations.description IS 'A brief description about the migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations.introduced IS 'The Sourcegraph version in which this migration was first introduced.';\n\nCOMMENT ON COLUMN out_of_band_migrations.deprecated IS 'The lowest Sourcegraph version that assumes the migration has completed.';\n\nCOMMENT ON COLUMN out_of_band_migrations.progress IS 'The percentage progress in the up direction (0=0%, 1=100%).';\n\nCOMMENT ON COLUMN out_of_band_migrations.created IS 'The date and time the migration was inserted into the database (via an upgrade).';\n\nCOMMENT ON COLUMN out_of_band_migrations.last_updated IS 'The date and time the migration was last updated.';\n\nCOMMENT ON COLUMN out_of_band_migrations.non_destructive IS 'Whether or not this migration alters data so it can no longer be read by the previous Sourcegraph instance.';\n\nCOMMENT ON COLUMN out_of_band_migrations.apply_reverse IS 'Whether this migration should run in the opposite direction (to support an upcoming downgrade).';\n\nCREATE TABLE out_of_band_migrations_errors (\n    id integer NOT NULL,\n    migration_id integer NOT NULL,\n    message text NOT NULL,\n    created timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT out_of_band_migrations_errors_message_nonempty CHECK ((message \u003c\u003e ''::text))\n);\n\nCOMMENT ON TABLE out_of_band_migrations_errors IS 'Stores errors that occurred while performing an out-of-band migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations_errors.id IS 'A unique identifer.';\n\nCOMMENT ON COLUMN out_of_band_migrations_errors.migration_id IS 'The identifier of the migration.';\n\nCOMMENT ON COLUMN out_of_band_migrations_errors.message IS 'The error message.';\n\nCOMMENT ON COLUMN out_of_band_migrations_errors.created IS 'The date and time the error occurred.';\n\nCREATE SEQUENCE out_of_band_migrations_errors_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE out_of_band_migrations_errors_id_seq OWNED BY out_of_band_migrations_errors.id;\n\nCREATE SEQUENCE out_of_band_migrations_id_seq\n    AS integer\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE out_of_band_migrations_id_seq OWNED BY out_of_band_migrations.id;\n\nCREATE TABLE phabricator_repos (\n    id integer NOT NULL,\n    callsign citext NOT NULL,\n    repo_name citext NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    url text DEFAULT ''::text NOT NULL\n);\n\nCREATE SEQUENCE phabricator_repos_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE phabricator_repos_id_seq OWNED BY phabricator_repos.id;\n\nCREATE TABLE product_licenses (\n    id uuid NOT NULL,\n    product_subscription_id uuid NOT NULL,\n    license_key text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE TABLE product_subscriptions (\n    id uuid NOT NULL,\n    user_id integer NOT NULL,\n    billing_subscription_id text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    archived_at timestamp with time zone\n);\n\nCREATE TABLE query_runner_state (\n    query text,\n    last_executed timestamp with time zone,\n    latest_result timestamp with time zone,\n    exec_duration_ns bigint\n);\n\nCREATE TABLE users (\n    id integer NOT NULL,\n    username citext NOT NULL,\n    display_name text,\n    avatar_url text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    invite_quota integer DEFAULT 15 NOT NULL,\n    passwd text,\n    passwd_reset_code text,\n    passwd_reset_time timestamp with time zone,\n    site_admin boolean DEFAULT false NOT NULL,\n    page_views integer DEFAULT 0 NOT NULL,\n    search_queries integer DEFAULT 0 NOT NULL,\n    tags text[] DEFAULT '{}'::text[],\n    billing_customer_id text,\n    invalidated_sessions_at timestamp with time zone DEFAULT now() NOT NULL,\n    CONSTRAINT users_display_name_max_length CHECK ((char_length(display_name) \u003c= 255)),\n    CONSTRAINT users_username_max_length CHECK ((char_length((username)::text) \u003c= 255)),\n    CONSTRAINT users_username_valid_chars CHECK ((username OPERATOR(~) '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[-.](?=[a-zA-Z0-9]))*-?$'::citext))\n);\n\nCREATE VIEW reconciler_changesets AS\n SELECT c.id,\n    c.campaign_ids,\n    c.repo_id,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_changed,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_campaign_id,\n    c.reconciler_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error\n   FROM (changesets c\n     JOIN repo r ON ((r.id = c.repo_id)))\n  WHERE ((r.deleted_at IS NULL) AND (EXISTS ( SELECT 1\n           FROM ((campaigns\n             LEFT JOIN users namespace_user ON ((campaigns.namespace_user_id = namespace_user.id)))\n             LEFT JOIN orgs namespace_org ON ((campaigns.namespace_org_id = namespace_org.id)))\n          WHERE ((c.campaign_ids ? (campaigns.id)::text) AND (namespace_user.deleted_at IS NULL) AND (namespace_org.deleted_at IS NULL)))));\n\nCREATE TABLE registry_extension_releases (\n    id bigint NOT NULL,\n    registry_extension_id integer NOT NULL,\n    creator_user_id integer NOT NULL,\n    release_version citext,\n    release_tag citext NOT NULL,\n    manifest jsonb NOT NULL,\n    bundle text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    source_map text\n);\n\nCREATE SEQUENCE registry_extension_releases_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE registry_extension_releases_id_seq OWNED BY registry_extension_releases.id;\n\nCREATE TABLE registry_extensions (\n    id integer NOT NULL,\n    uuid uuid NOT NULL,\n    publisher_user_id integer,\n    publisher_org_id integer,\n    name citext NOT NULL,\n    manifest text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    CONSTRAINT registry_extensions_name_length CHECK (((char_length((name)::text) \u003e 0) AND (char_length((name)::text) \u003c= 128))),\n    CONSTRAINT registry_extensions_name_valid_chars CHECK ((name OPERATOR(~) '^[a-zA-Z0-9](?:[a-zA-Z0-9]|[_.-](?=[a-zA-Z0-9]))*$'::citext)),\n    CONSTRAINT registry_extensions_single_publisher CHECK (((publisher_user_id IS NULL) \u003c\u003e (publisher_org_id IS NULL)))\n);\n\nCREATE SEQUENCE registry_extensions_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE registry_extensions_id_seq OWNED BY registry_extensions.id;\n\nCREATE SEQUENCE repo_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE repo_id_seq OWNED BY repo.id;\n\nCREATE TABLE repo_pending_permissions (\n    repo_id integer NOT NULL,\n    permission text NOT NULL,\n    user_ids bytea DEFAULT '\\x'::bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    user_ids_ints integer[] DEFAULT '{}'::integer[] NOT NULL\n);\n\nCREATE TABLE repo_permissions (\n    repo_id integer NOT NULL,\n    permission text NOT NULL,\n    user_ids bytea DEFAULT '\\x'::bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    synced_at timestamp with time zone,\n    user_ids_ints integer[] DEFAULT '{}'::integer[] NOT NULL\n);\n\nCREATE TABLE saved_searches (\n    id integer NOT NULL,\n    description text NOT NULL,\n    query text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    notify_owner boolean NOT NULL,\n    notify_slack boolean NOT NULL,\n    user_id integer,\n    org_id integer,\n    slack_webhook_url text,\n    CONSTRAINT user_or_org_id_not_null CHECK ((((user_id IS NOT NULL) AND (org_id IS NULL)) OR ((org_id IS NOT NULL) AND (user_id IS NULL))))\n);\n\nCREATE SEQUENCE saved_searches_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE saved_searches_id_seq OWNED BY saved_searches.id;\n\nCREATE TABLE settings (\n    id integer NOT NULL,\n    org_id integer,\n    contents text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    user_id integer,\n    author_user_id integer\n);\n\nCREATE TABLE settings_bkup_1514702776 (\n    id integer,\n    org_id integer,\n    author_user_id_old text,\n    contents text,\n    created_at timestamp with time zone,\n    user_id integer,\n    author_user_id integer\n);\n\nCREATE SEQUENCE settings_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE settings_id_seq OWNED BY settings.id;\n\nCREATE VIEW site_config AS\n SELECT global_state.site_id,\n    global_state.initialized\n   FROM global_state;\n\nCREATE TABLE survey_responses (\n    id bigint NOT NULL,\n    user_id integer,\n    email text,\n    score integer NOT NULL,\n    reason text,\n    better text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE SEQUENCE survey_responses_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE survey_responses_id_seq OWNED BY survey_responses.id;\n\nCREATE VIEW tracking_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.campaign_spec_id,\n    repo.name AS repo_name,\n    COALESCE((changesets.metadata -\u003e\u003e 'Title'::text), (changesets.metadata -\u003e\u003e 'title'::text)) AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.external_id = changeset_specs.external_id))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NOT NULL) AND (repo.deleted_at IS NULL));\n\nCREATE TABLE user_credentials (\n    id bigint NOT NULL,\n    domain text NOT NULL,\n    user_id integer NOT NULL,\n    external_service_type text NOT NULL,\n    external_service_id text NOT NULL,\n    credential text NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nCREATE SEQUENCE user_credentials_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE user_credentials_id_seq OWNED BY user_credentials.id;\n\nCREATE TABLE user_emails (\n    user_id integer NOT NULL,\n    email citext NOT NULL,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    verification_code text,\n    verified_at timestamp with time zone,\n    last_verification_sent_at timestamp with time zone,\n    is_primary boolean DEFAULT false NOT NULL\n);\n\nCREATE TABLE user_external_accounts (\n    id integer NOT NULL,\n    user_id integer NOT NULL,\n    service_type text NOT NULL,\n    service_id text NOT NULL,\n    account_id text NOT NULL,\n    auth_data text,\n    account_data text,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n    client_id text NOT NULL,\n    expired_at timestamp with time zone,\n    last_valid_at timestamp with time zone\n);\n\nCREATE SEQUENCE user_external_accounts_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE user_external_accounts_id_seq OWNED BY user_external_accounts.id;\n\nCREATE TABLE user_pending_permissions (\n    id integer NOT NULL,\n    bind_id text NOT NULL,\n    permission text NOT NULL,\n    object_type text NOT NULL,\n    object_ids bytea DEFAULT '\\x'::bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    service_type text NOT NULL,\n    service_id text NOT NULL,\n    object_ids_ints integer[] DEFAULT '{}'::integer[] NOT NULL\n);\n\nCREATE SEQUENCE user_pending_permissions_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE user_pending_permissions_id_seq OWNED BY user_pending_permissions.id;\n\nCREATE TABLE user_permissions (\n    user_id integer NOT NULL,\n    permission text NOT NULL,\n    object_type text NOT NULL,\n    object_ids bytea DEFAULT '\\x'::bytea NOT NULL,\n    updated_at timestamp with time zone NOT NULL,\n    synced_at timestamp with time zone,\n    object_ids_ints integer[] DEFAULT '{}'::integer[] NOT NULL\n);\n\nCREATE SEQUENCE users_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nALTER SEQUENCE users_id_seq OWNED BY users.id;\n\nCREATE TABLE versions (\n    service text NOT NULL,\n    version text NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL\n);\n\nALTER TABLE ONLY access_tokens ALTER COLUMN id SET DEFAULT nextval('access_tokens_id_seq'::regclass);\n\nALTER TABLE ONLY campaign_specs ALTER COLUMN id SET DEFAULT nextval('campaign_specs_id_seq'::regclass);\n\nALTER TABLE ONLY campaigns ALTER COLUMN id SET DEFAULT nextval('campaigns_id_seq'::regclass);\n\nALTER TABLE ONLY changeset_events ALTER COLUMN id SET DEFAULT nextval('changeset_events_id_seq'::regclass);\n\nALTER TABLE ONLY changeset_specs ALTER COLUMN id SET DEFAULT nextval('changeset_specs_id_seq'::regclass);\n\nALTER TABLE ONLY changesets ALTER COLUMN id SET DEFAULT nextval('changesets_id_seq'::regclass);\n\nALTER TABLE ONLY cm_action_jobs ALTER COLUMN id SET DEFAULT nextval('cm_action_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY cm_emails ALTER COLUMN id SET DEFAULT nextval('cm_emails_id_seq'::regclass);\n\nALTER TABLE ONLY cm_monitors ALTER COLUMN id SET DEFAULT nextval('cm_monitors_id_seq'::regclass);\n\nALTER TABLE ONLY cm_queries ALTER COLUMN id SET DEFAULT nextval('cm_queries_id_seq'::regclass);\n\nALTER TABLE ONLY cm_recipients ALTER COLUMN id SET DEFAULT nextval('cm_recipients_id_seq'::regclass);\n\nALTER TABLE ONLY cm_trigger_jobs ALTER COLUMN id SET DEFAULT nextval('cm_trigger_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY critical_and_site_config ALTER COLUMN id SET DEFAULT nextval('critical_and_site_config_id_seq'::regclass);\n\nALTER TABLE ONLY discussion_comments ALTER COLUMN id SET DEFAULT nextval('discussion_comments_id_seq'::regclass);\n\nALTER TABLE ONLY discussion_threads ALTER COLUMN id SET DEFAULT nextval('discussion_threads_id_seq'::regclass);\n\nALTER TABLE ONLY discussion_threads_target_repo ALTER COLUMN id SET DEFAULT nextval('discussion_threads_target_repo_id_seq'::regclass);\n\nALTER TABLE ONLY event_logs ALTER COLUMN id SET DEFAULT nextval('event_logs_id_seq'::regclass);\n\nALTER TABLE ONLY external_services ALTER COLUMN id SET DEFAULT nextval('external_services_id_seq'::regclass);\n\nALTER TABLE ONLY insights_query_runner_jobs ALTER COLUMN id SET DEFAULT nextval('insights_query_runner_jobs_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_index_configuration ALTER COLUMN id SET DEFAULT nextval('lsif_index_configuration_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_indexable_repositories ALTER COLUMN id SET DEFAULT nextval('lsif_indexable_repositories_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_indexes ALTER COLUMN id SET DEFAULT nextval('lsif_indexes_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_packages ALTER COLUMN id SET DEFAULT nextval('lsif_packages_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_references ALTER COLUMN id SET DEFAULT nextval('lsif_references_id_seq'::regclass);\n\nALTER TABLE ONLY lsif_uploads ALTER COLUMN id SET DEFAULT nextval('lsif_dumps_id_seq'::regclass);\n\nALTER TABLE ONLY org_invitations ALTER COLUMN id SET DEFAULT nextval('org_invitations_id_seq'::regclass);\n\nALTER TABLE ONLY org_members ALTER COLUMN id SET DEFAULT nextval('org_members_id_seq'::regclass);\n\nALTER TABLE ONLY orgs ALTER COLUMN id SET DEFAULT nextval('orgs_id_seq'::regclass);\n\nALTER TABLE ONLY out_of_band_migrations ALTER COLUMN id SET DEFAULT nextval('out_of_band_migrations_id_seq'::regclass);\n\nALTER TABLE ONLY out_of_band_migrations_errors ALTER COLUMN id SET DEFAULT nextval('out_of_band_migrations_errors_id_seq'::regclass);\n\nALTER TABLE ONLY phabricator_repos ALTER COLUMN id SET DEFAULT nextval('phabricator_repos_id_seq'::regclass);\n\nALTER TABLE ONLY registry_extension_releases ALTER COLUMN id SET DEFAULT nextval('registry_extension_releases_id_seq'::regclass);\n\nALTER TABLE ONLY registry_extensions ALTER COLUMN id SET DEFAULT nextval('registry_extensions_id_seq'::regclass);\n\nALTER TABLE ONLY repo ALTER COLUMN id SET DEFAULT nextval('repo_id_seq'::regclass);\n\nALTER TABLE ONLY saved_searches ALTER COLUMN id SET DEFAULT nextval('saved_searches_id_seq'::regclass);\n\nALTER TABLE ONLY settings ALTER COLUMN id SET DEFAULT nextval('settings_id_seq'::regclass);\n\nALTER TABLE ONLY survey_responses ALTER COLUMN id SET DEFAULT nextval('survey_responses_id_seq'::regclass);\n\nALTER TABLE ONLY user_credentials ALTER COLUMN id SET DEFAULT nextval('user_credentials_id_seq'::regclass);\n\nALTER TABLE ONLY user_external_accounts ALTER COLUMN id SET DEFAULT nextval('user_external_accounts_id_seq'::regclass);\n\nALTER TABLE ONLY user_pending_permissions ALTER COLUMN id SET DEFAULT nextval('user_pending_permissions_id_seq'::regclass);\n\nALTER TABLE ONLY users ALTER COLUMN id SET DEFAULT nextval('users_id_seq'::regclass);\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_value_sha256_key UNIQUE (value_sha256);\n\nALTER TABLE ONLY campaign_specs\n    ADD CONSTRAINT campaign_specs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changeset_events\n    ADD CONSTRAINT changeset_events_changeset_id_kind_key_unique UNIQUE (changeset_id, kind, key);\n\nALTER TABLE ONLY changeset_events\n    ADD CONSTRAINT changeset_events_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changeset_specs\n    ADD CONSTRAINT changeset_specs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_repo_external_id_unique UNIQUE (repo_id, external_id);\n\nALTER TABLE ONLY cm_action_jobs\n    ADD CONSTRAINT cm_action_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_emails\n    ADD CONSTRAINT cm_emails_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_queries\n    ADD CONSTRAINT cm_queries_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_recipients\n    ADD CONSTRAINT cm_recipients_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY cm_trigger_jobs\n    ADD CONSTRAINT cm_trigger_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY critical_and_site_config\n    ADD CONSTRAINT critical_and_site_config_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY default_repos\n    ADD CONSTRAINT default_repos_pkey PRIMARY KEY (repo_id);\n\nALTER TABLE ONLY discussion_comments\n    ADD CONSTRAINT discussion_comments_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY discussion_mail_reply_tokens\n    ADD CONSTRAINT discussion_mail_reply_tokens_pkey PRIMARY KEY (token);\n\nALTER TABLE ONLY discussion_threads\n    ADD CONSTRAINT discussion_threads_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY discussion_threads_target_repo\n    ADD CONSTRAINT discussion_threads_target_repo_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY event_logs\n    ADD CONSTRAINT event_logs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY external_service_repos\n    ADD CONSTRAINT external_service_repos_repo_id_external_service_id_unique UNIQUE (repo_id, external_service_id);\n\nALTER TABLE ONLY external_services\n    ADD CONSTRAINT external_services_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY global_state\n    ADD CONSTRAINT global_state_pkey PRIMARY KEY (site_id);\n\nALTER TABLE ONLY insights_query_runner_jobs\n    ADD CONSTRAINT insights_query_runner_jobs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_dirty_repositories\n    ADD CONSTRAINT lsif_dirty_repositories_pkey PRIMARY KEY (repository_id);\n\nALTER TABLE ONLY lsif_index_configuration\n    ADD CONSTRAINT lsif_index_configuration_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_index_configuration\n    ADD CONSTRAINT lsif_index_configuration_repository_id_key UNIQUE (repository_id);\n\nALTER TABLE ONLY lsif_indexable_repositories\n    ADD CONSTRAINT lsif_indexable_repositories_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_indexable_repositories\n    ADD CONSTRAINT lsif_indexable_repositories_repository_id_key UNIQUE (repository_id);\n\nALTER TABLE ONLY lsif_indexes\n    ADD CONSTRAINT lsif_indexes_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_packages\n    ADD CONSTRAINT lsif_packages_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_references\n    ADD CONSTRAINT lsif_references_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY lsif_uploads\n    ADD CONSTRAINT lsif_uploads_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY names\n    ADD CONSTRAINT names_pkey PRIMARY KEY (name);\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_org_id_user_id_key UNIQUE (org_id, user_id);\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY orgs\n    ADD CONSTRAINT orgs_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY out_of_band_migrations_errors\n    ADD CONSTRAINT out_of_band_migrations_errors_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY out_of_band_migrations\n    ADD CONSTRAINT out_of_band_migrations_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY phabricator_repos\n    ADD CONSTRAINT phabricator_repos_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY phabricator_repos\n    ADD CONSTRAINT phabricator_repos_repo_name_key UNIQUE (repo_name);\n\nALTER TABLE ONLY product_licenses\n    ADD CONSTRAINT product_licenses_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY product_subscriptions\n    ADD CONSTRAINT product_subscriptions_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY registry_extension_releases\n    ADD CONSTRAINT registry_extension_releases_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY registry_extensions\n    ADD CONSTRAINT registry_extensions_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY repo\n    ADD CONSTRAINT repo_name_unique UNIQUE (name) DEFERRABLE;\n\nALTER TABLE ONLY repo_pending_permissions\n    ADD CONSTRAINT repo_pending_permissions_perm_unique UNIQUE (repo_id, permission);\n\nALTER TABLE ONLY repo_permissions\n    ADD CONSTRAINT repo_permissions_perm_unique UNIQUE (repo_id, permission);\n\nALTER TABLE ONLY repo\n    ADD CONSTRAINT repo_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY saved_searches\n    ADD CONSTRAINT saved_searches_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY survey_responses\n    ADD CONSTRAINT survey_responses_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY user_credentials\n    ADD CONSTRAINT user_credentials_domain_user_id_external_service_type_exter_key UNIQUE (domain, user_id, external_service_type, external_service_id);\n\nALTER TABLE ONLY user_credentials\n    ADD CONSTRAINT user_credentials_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY user_emails\n    ADD CONSTRAINT user_emails_no_duplicates_per_user UNIQUE (user_id, email);\n\nALTER TABLE ONLY user_emails\n    ADD CONSTRAINT user_emails_unique_verified_email EXCLUDE USING btree (email WITH OPERATOR(=)) WHERE ((verified_at IS NOT NULL));\n\nALTER TABLE ONLY user_external_accounts\n    ADD CONSTRAINT user_external_accounts_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY user_pending_permissions\n    ADD CONSTRAINT user_pending_permissions_service_perm_object_unique UNIQUE (service_type, service_id, permission, object_type, bind_id);\n\nALTER TABLE ONLY user_permissions\n    ADD CONSTRAINT user_permissions_perm_object_unique UNIQUE (user_id, permission, object_type);\n\nALTER TABLE ONLY users\n    ADD CONSTRAINT users_pkey PRIMARY KEY (id);\n\nALTER TABLE ONLY versions\n    ADD CONSTRAINT versions_pkey PRIMARY KEY (service);\n\nCREATE INDEX access_tokens_lookup ON access_tokens USING hash (value_sha256) WHERE (deleted_at IS NULL);\n\nCREATE INDEX campaign_specs_rand_id ON campaign_specs USING btree (rand_id);\n\nCREATE INDEX campaigns_namespace_org_id ON campaigns USING btree (namespace_org_id);\n\nCREATE INDEX campaigns_namespace_user_id ON campaigns USING btree (namespace_user_id);\n\nCREATE INDEX changeset_specs_external_id ON changeset_specs USING btree (external_id);\n\nCREATE INDEX changeset_specs_head_ref ON changeset_specs USING btree (head_ref);\n\nCREATE INDEX changeset_specs_rand_id ON changeset_specs USING btree (rand_id);\n\nCREATE INDEX changeset_specs_title ON changeset_specs USING btree (title);\n\nCREATE INDEX changesets_external_state_idx ON changesets USING btree (external_state);\n\nCREATE INDEX changesets_publication_state_idx ON changesets USING btree (publication_state);\n\nCREATE INDEX changesets_reconciler_state_idx ON changesets USING btree (reconciler_state);\n\nCREATE UNIQUE INDEX critical_and_site_config_unique ON critical_and_site_config USING btree (id, type);\n\nCREATE INDEX discussion_comments_author_user_id_idx ON discussion_comments USING btree (author_user_id);\n\nCREATE INDEX discussion_comments_reports_array_length_idx ON discussion_comments USING btree (array_length(reports, 1));\n\nCREATE INDEX discussion_comments_thread_id_idx ON discussion_comments USING btree (thread_id);\n\nCREATE INDEX discussion_mail_reply_tokens_user_id_thread_id_idx ON discussion_mail_reply_tokens USING btree (user_id, thread_id);\n\nCREATE INDEX discussion_threads_author_user_id_idx ON discussion_threads USING btree (author_user_id);\n\nCREATE INDEX discussion_threads_target_repo_repo_id_path_idx ON discussion_threads_target_repo USING btree (repo_id, path);\n\nCREATE INDEX event_logs_anonymous_user_id ON event_logs USING btree (anonymous_user_id);\n\nCREATE INDEX event_logs_name ON event_logs USING btree (name);\n\nCREATE INDEX event_logs_source ON event_logs USING btree (source);\n\nCREATE INDEX event_logs_timestamp ON event_logs USING btree (\"timestamp\");\n\nCREATE INDEX event_logs_timestamp_at_utc ON event_logs USING btree (date(timezone('UTC'::text, \"timestamp\")));\n\nCREATE INDEX event_logs_user_id ON event_logs USING btree (user_id);\n\nCREATE INDEX external_service_repos_external_service_id ON external_service_repos USING btree (external_service_id);\n\nCREATE INDEX external_service_sync_jobs_state_idx ON external_service_sync_jobs USING btree (state);\n\nCREATE INDEX external_services_namespace_user_id_idx ON external_services USING btree (namespace_user_id);\n\nCREATE INDEX insights_query_runner_jobs_state_btree ON insights_query_runner_jobs USING btree (state);\n\nCREATE UNIQUE INDEX kind_cloud_default ON external_services USING btree (kind, cloud_default) WHERE (cloud_default = true);\n\nCREATE INDEX lsif_nearest_uploads_links_repository_id_commit_bytea ON lsif_nearest_uploads_links USING btree (repository_id, commit_bytea);\n\nCREATE INDEX lsif_nearest_uploads_repository_id_commit_bytea ON lsif_nearest_uploads USING btree (repository_id, commit_bytea);\n\nCREATE INDEX lsif_packages_scheme_name_version ON lsif_packages USING btree (scheme, name, version);\n\nCREATE INDEX lsif_references_package ON lsif_references USING btree (scheme, name, version);\n\nCREATE UNIQUE INDEX lsif_uploads_repository_id_commit_root_indexer ON lsif_uploads USING btree (repository_id, commit, root, indexer) WHERE (state = 'completed'::text);\n\nCREATE INDEX lsif_uploads_state ON lsif_uploads USING btree (state);\n\nCREATE INDEX lsif_uploads_uploaded_at ON lsif_uploads USING btree (uploaded_at);\n\nCREATE INDEX lsif_uploads_visible_at_tip_repository_id_upload_id ON lsif_uploads_visible_at_tip USING btree (repository_id, upload_id);\n\nCREATE INDEX org_invitations_org_id ON org_invitations USING btree (org_id) WHERE (deleted_at IS NULL);\n\nCREATE INDEX org_invitations_recipient_user_id ON org_invitations USING btree (recipient_user_id) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX org_invitations_singleflight ON org_invitations USING btree (org_id, recipient_user_id) WHERE ((responded_at IS NULL) AND (revoked_at IS NULL) AND (deleted_at IS NULL));\n\nCREATE UNIQUE INDEX orgs_name ON orgs USING btree (name) WHERE (deleted_at IS NULL);\n\nCREATE INDEX registry_extension_releases_registry_extension_id ON registry_extension_releases USING btree (registry_extension_id, release_tag, created_at DESC) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX registry_extension_releases_version ON registry_extension_releases USING btree (registry_extension_id, release_version) WHERE (release_version IS NOT NULL);\n\nCREATE UNIQUE INDEX registry_extensions_publisher_name ON registry_extensions USING btree (COALESCE(publisher_user_id, 0), COALESCE(publisher_org_id, 0), name) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX registry_extensions_uuid ON registry_extensions USING btree (uuid);\n\nCREATE INDEX repo_archived ON repo USING btree (archived);\n\nCREATE INDEX repo_cloned ON repo USING btree (cloned);\n\nCREATE INDEX repo_created_at ON repo USING btree (created_at);\n\nCREATE UNIQUE INDEX repo_external_unique_idx ON repo USING btree (external_service_type, external_service_id, external_id);\n\nCREATE INDEX repo_fork ON repo USING btree (fork);\n\nCREATE INDEX repo_metadata_gin_idx ON repo USING gin (metadata);\n\nCREATE INDEX repo_name_idx ON repo USING btree (lower((name)::text) COLLATE \"C\");\n\nCREATE INDEX repo_name_trgm ON repo USING gin (lower((name)::text) gin_trgm_ops);\n\nCREATE INDEX repo_private ON repo USING btree (private);\n\nCREATE INDEX repo_uri_idx ON repo USING btree (uri);\n\nCREATE INDEX settings_org_id_idx ON settings USING btree (org_id);\n\nCREATE UNIQUE INDEX user_emails_user_id_is_primary_idx ON user_emails USING btree (user_id, is_primary) WHERE (is_primary = true);\n\nCREATE UNIQUE INDEX user_external_accounts_account ON user_external_accounts USING btree (service_type, service_id, client_id, account_id) WHERE (deleted_at IS NULL);\n\nCREATE INDEX user_external_accounts_user_id ON user_external_accounts USING btree (user_id) WHERE (deleted_at IS NULL);\n\nCREATE UNIQUE INDEX users_billing_customer_id ON users USING btree (billing_customer_id) WHERE (deleted_at IS NULL);\n\nCREATE INDEX users_created_at_idx ON users USING btree (created_at);\n\nCREATE UNIQUE INDEX users_username ON users USING btree (username) WHERE (deleted_at IS NULL);\n\nCREATE TRIGGER trig_delete_campaign_reference_on_changesets AFTER DELETE ON campaigns FOR EACH ROW EXECUTE FUNCTION delete_campaign_reference_on_changesets();\n\nCREATE TRIGGER trig_delete_external_service_ref_on_external_service_repos AFTER UPDATE OF deleted_at ON external_services FOR EACH ROW EXECUTE FUNCTION delete_external_service_ref_on_external_service_repos();\n\nCREATE TRIGGER trig_delete_repo_ref_on_external_service_repos AFTER UPDATE OF deleted_at ON repo FOR EACH ROW EXECUTE FUNCTION delete_repo_ref_on_external_service_repos();\n\nCREATE TRIGGER trig_invalidate_session_on_password_change BEFORE UPDATE OF passwd ON users FOR EACH ROW EXECUTE FUNCTION invalidate_session_for_userid_on_password_change();\n\nCREATE TRIGGER trig_soft_delete_orphan_repo_by_external_service_repo AFTER DELETE ON external_service_repos FOR EACH STATEMENT EXECUTE FUNCTION soft_delete_orphan_repo_by_external_service_repos();\n\nCREATE TRIGGER trig_soft_delete_user_reference_on_external_service AFTER UPDATE OF deleted_at ON users FOR EACH ROW EXECUTE FUNCTION soft_delete_user_reference_on_external_service();\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_creator_user_id_fkey FOREIGN KEY (creator_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY access_tokens\n    ADD CONSTRAINT access_tokens_subject_user_id_fkey FOREIGN KEY (subject_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY campaign_specs\n    ADD CONSTRAINT campaign_specs_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_campaign_spec_id_fkey FOREIGN KEY (campaign_spec_id) REFERENCES campaign_specs(id) DEFERRABLE;\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_initial_applier_id_fkey FOREIGN KEY (initial_applier_id) REFERENCES users(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_last_applier_id_fkey FOREIGN KEY (last_applier_id) REFERENCES users(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_namespace_org_id_fkey FOREIGN KEY (namespace_org_id) REFERENCES orgs(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY campaigns\n    ADD CONSTRAINT campaigns_namespace_user_id_fkey FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_events\n    ADD CONSTRAINT changeset_events_changeset_id_fkey FOREIGN KEY (changeset_id) REFERENCES changesets(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY changeset_specs\n    ADD CONSTRAINT changeset_specs_campaign_spec_id_fkey FOREIGN KEY (campaign_spec_id) REFERENCES campaign_specs(id) DEFERRABLE;\n\nALTER TABLE ONLY changeset_specs\n    ADD CONSTRAINT changeset_specs_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) DEFERRABLE;\n\nALTER TABLE ONLY changeset_specs\n    ADD CONSTRAINT changeset_specs_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_changeset_spec_id_fkey FOREIGN KEY (current_spec_id) REFERENCES changeset_specs(id) DEFERRABLE;\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_owned_by_campaign_id_fkey FOREIGN KEY (owned_by_campaign_id) REFERENCES campaigns(id) ON DELETE SET NULL DEFERRABLE;\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_previous_spec_id_fkey FOREIGN KEY (previous_spec_id) REFERENCES changeset_specs(id) DEFERRABLE;\n\nALTER TABLE ONLY changesets\n    ADD CONSTRAINT changesets_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY cm_action_jobs\n    ADD CONSTRAINT cm_action_jobs_email_fk FOREIGN KEY (email) REFERENCES cm_emails(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_action_jobs\n    ADD CONSTRAINT cm_action_jobs_trigger_event_fk FOREIGN KEY (trigger_event) REFERENCES cm_trigger_jobs(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_emails\n    ADD CONSTRAINT cm_emails_changed_by_fk FOREIGN KEY (changed_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_emails\n    ADD CONSTRAINT cm_emails_created_by_fk FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_emails\n    ADD CONSTRAINT cm_emails_monitor FOREIGN KEY (monitor) REFERENCES cm_monitors(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_changed_by_fk FOREIGN KEY (changed_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_created_by_fk FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_org_id_fk FOREIGN KEY (namespace_org_id) REFERENCES orgs(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_monitors\n    ADD CONSTRAINT cm_monitors_user_id_fk FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_recipients\n    ADD CONSTRAINT cm_recipients_emails FOREIGN KEY (email) REFERENCES cm_emails(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_recipients\n    ADD CONSTRAINT cm_recipients_org_id_fk FOREIGN KEY (namespace_org_id) REFERENCES orgs(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_recipients\n    ADD CONSTRAINT cm_recipients_user_id_fk FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_trigger_jobs\n    ADD CONSTRAINT cm_trigger_jobs_query_fk FOREIGN KEY (query) REFERENCES cm_queries(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_queries\n    ADD CONSTRAINT cm_triggers_changed_by_fk FOREIGN KEY (changed_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_queries\n    ADD CONSTRAINT cm_triggers_created_by_fk FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY cm_queries\n    ADD CONSTRAINT cm_triggers_monitor FOREIGN KEY (monitor) REFERENCES cm_monitors(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY default_repos\n    ADD CONSTRAINT default_repos_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_comments\n    ADD CONSTRAINT discussion_comments_author_user_id_fkey FOREIGN KEY (author_user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY discussion_comments\n    ADD CONSTRAINT discussion_comments_thread_id_fkey FOREIGN KEY (thread_id) REFERENCES discussion_threads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_mail_reply_tokens\n    ADD CONSTRAINT discussion_mail_reply_tokens_thread_id_fkey FOREIGN KEY (thread_id) REFERENCES discussion_threads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_mail_reply_tokens\n    ADD CONSTRAINT discussion_mail_reply_tokens_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY discussion_threads\n    ADD CONSTRAINT discussion_threads_author_user_id_fkey FOREIGN KEY (author_user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY discussion_threads\n    ADD CONSTRAINT discussion_threads_target_repo_id_fk FOREIGN KEY (target_repo_id) REFERENCES discussion_threads_target_repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_threads_target_repo\n    ADD CONSTRAINT discussion_threads_target_repo_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY discussion_threads_target_repo\n    ADD CONSTRAINT discussion_threads_target_repo_thread_id_fkey FOREIGN KEY (thread_id) REFERENCES discussion_threads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY external_service_repos\n    ADD CONSTRAINT external_service_repos_external_service_id_fkey FOREIGN KEY (external_service_id) REFERENCES external_services(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY external_service_repos\n    ADD CONSTRAINT external_service_repos_repo_id_fkey FOREIGN KEY (repo_id) REFERENCES repo(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY external_service_sync_jobs\n    ADD CONSTRAINT external_services_id_fk FOREIGN KEY (external_service_id) REFERENCES external_services(id);\n\nALTER TABLE ONLY external_services\n    ADD CONSTRAINT external_services_namepspace_user_id_fkey FOREIGN KEY (namespace_user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY lsif_index_configuration\n    ADD CONSTRAINT lsif_index_configuration_repository_id_fkey FOREIGN KEY (repository_id) REFERENCES repo(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY lsif_packages\n    ADD CONSTRAINT lsif_packages_dump_id_fkey FOREIGN KEY (dump_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY lsif_references\n    ADD CONSTRAINT lsif_references_dump_id_fkey FOREIGN KEY (dump_id) REFERENCES lsif_uploads(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY names\n    ADD CONSTRAINT names_org_id_fkey FOREIGN KEY (org_id) REFERENCES orgs(id) ON UPDATE CASCADE ON DELETE CASCADE;\n\nALTER TABLE ONLY names\n    ADD CONSTRAINT names_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON UPDATE CASCADE ON DELETE CASCADE;\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_org_id_fkey FOREIGN KEY (org_id) REFERENCES orgs(id);\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_recipient_user_id_fkey FOREIGN KEY (recipient_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY org_invitations\n    ADD CONSTRAINT org_invitations_sender_user_id_fkey FOREIGN KEY (sender_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_references_orgs FOREIGN KEY (org_id) REFERENCES orgs(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY org_members\n    ADD CONSTRAINT org_members_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY out_of_band_migrations_errors\n    ADD CONSTRAINT out_of_band_migrations_errors_migration_id_fkey FOREIGN KEY (migration_id) REFERENCES out_of_band_migrations(id) ON DELETE CASCADE;\n\nALTER TABLE ONLY product_licenses\n    ADD CONSTRAINT product_licenses_product_subscription_id_fkey FOREIGN KEY (product_subscription_id) REFERENCES product_subscriptions(id);\n\nALTER TABLE ONLY product_subscriptions\n    ADD CONSTRAINT product_subscriptions_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY registry_extension_releases\n    ADD CONSTRAINT registry_extension_releases_creator_user_id_fkey FOREIGN KEY (creator_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY registry_extension_releases\n    ADD CONSTRAINT registry_extension_releases_registry_extension_id_fkey FOREIGN KEY (registry_extension_id) REFERENCES registry_extensions(id) ON UPDATE CASCADE ON DELETE CASCADE;\n\nALTER TABLE ONLY registry_extensions\n    ADD CONSTRAINT registry_extensions_publisher_org_id_fkey FOREIGN KEY (publisher_org_id) REFERENCES orgs(id);\n\nALTER TABLE ONLY registry_extensions\n    ADD CONSTRAINT registry_extensions_publisher_user_id_fkey FOREIGN KEY (publisher_user_id) REFERENCES users(id);\n\nALTER TABLE ONLY saved_searches\n    ADD CONSTRAINT saved_searches_org_id_fkey FOREIGN KEY (org_id) REFERENCES orgs(id);\n\nALTER TABLE ONLY saved_searches\n    ADD CONSTRAINT saved_searches_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_author_user_id_fkey FOREIGN KEY (author_user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_references_orgs FOREIGN KEY (org_id) REFERENCES orgs(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY settings\n    ADD CONSTRAINT settings_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE RESTRICT;\n\nALTER TABLE ONLY survey_responses\n    ADD CONSTRAINT survey_responses_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY user_credentials\n    ADD CONSTRAINT user_credentials_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nALTER TABLE ONLY user_emails\n    ADD CONSTRAINT user_emails_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nALTER TABLE ONLY user_external_accounts\n    ADD CONSTRAINT user_external_accounts_user_id_fkey FOREIGN KEY (user_id) REFERENCES users(id);\n\nINSERT INTO out_of_band_migrations VALUES (1, 'code-intelligence', 'codeintel-db.lsif_data_documents', 'Populate num_diagnostics from gob-encoded payload', '3.25.0', NULL, 0, '2021-06-03 23:21:34.031614+00', NULL, true, false);\n\nSELECT pg_catalog.setval('out_of_band_migrations_id_seq', 1, false);",
				"DownQuery": "-- Nothing",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					-1528395787
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395788,
				"Name": "campaigns ssh key migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, deprecated, non_destructive)\nVALUES (2, 'campaigns', 'frontend-db.authenticators', 'Prepare for SSH pushes to code hosts', '3.26.0', '3.27.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395787
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395789,
				"Name": "add encryption key ident",
				"UpQuery": "ALTER TABLE external_services ADD COLUMN IF NOT EXISTS encryption_key_id text NOT NULL DEFAULT '';",
				"DownQuery": "ALTER TABLE external_services DROP COLUMN IF EXISTS encryption_key_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395788
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395790,
				"Name": "create gitserver repos",
				"UpQuery": "CREATE TABLE IF NOT EXISTS gitserver_repos\n(\n    repo_id int REFERENCES repo(id) PRIMARY KEY,\n    clone_status text NOT NULL default 'not_cloned',\n    last_external_service bigint,\n    shard_id text NOT NULL,\n    last_error text,\n    updated_at timestamp WITH TIME ZONE default now() not null\n);",
				"DownQuery": "DROP TABLE IF EXISTS gitserver_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395789
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395791,
				"Name": "insights query runner jobs record time",
				"UpQuery": "ALTER TABLE insights_query_runner_jobs ADD COLUMN record_time timestamptz;",
				"DownQuery": "ALTER TABLE insights_query_runner_jobs DROP COLUMN record_time;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395790
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395792,
				"Name": "add user public repos",
				"UpQuery": "CREATE TABLE IF NOT EXISTS user_public_repos (\n    user_id integer NOT NULL,\n    repo_uri text NOT NULL,\n    repo_id integer NOT NULL,\n    UNIQUE(user_id, repo_id),\n    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE,\n    FOREIGN KEY (repo_id) REFERENCES repo (id) ON DELETE CASCADE\n);",
				"DownQuery": "DROP TABLE IF EXISTS user_public_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395791
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395793,
				"Name": "fix invalid changeset reconciler states",
				"UpQuery": "UPDATE changesets SET reconciler_state = 'queued' WHERE reconciler_state = 'QUEUED';",
				"DownQuery": "UPDATE changesets SET reconciler_state = 'QUEUED' WHERE reconciler_state = 'queued';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395792
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395794,
				"Name": "campaigns rename",
				"UpQuery": "UPDATE user_credentials SET domain = 'batches' WHERE domain = 'campaigns';\nALTER TABLE IF EXISTS campaign_specs RENAME TO batch_specs;\nALTER TABLE IF EXISTS campaigns RENAME TO batch_changes;\nALTER TABLE IF EXISTS batch_changes RENAME COLUMN campaign_spec_id TO batch_spec_id;\nALTER TABLE IF EXISTS changeset_specs RENAME COLUMN campaign_spec_id TO batch_spec_id;\nDROP VIEW IF EXISTS reconciler_changesets;\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\nALTER TABLE IF EXISTS changesets RENAME COLUMN campaign_ids TO batch_change_ids;\nALTER TABLE IF EXISTS changesets RENAME COLUMN owned_by_campaign_id TO owned_by_batch_change_id;\nCREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.batch_spec_id,\n        repo.name AS repo_name,\n        COALESCE(changesets.metadata -\u003e\u003e 'Title'::text, changesets.metadata -\u003e\u003e 'title'::text) AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM\n        changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.external_id = changeset_specs.external_id\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NOT NULL\n        AND\n        repo.deleted_at IS NULL\n);\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.batch_spec_id,\n        changesets.owned_by_batch_change_id AS owner_batch_change_id,\n        repo.name AS repo_name,\n        changeset_specs.title AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.current_spec_id IS NOT NULL\n        AND\n        EXISTS (\n            SELECT 1\n            FROM changeset_specs changeset_specs_1\n            WHERE\n                changeset_specs_1.id = changesets.current_spec_id\n                AND\n                changeset_specs_1.head_ref = changeset_specs.head_ref\n        )\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NULL\n        AND\n        repo.deleted_at IS NULL\n);\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\nDROP TRIGGER IF EXISTS trig_delete_campaign_reference_on_changesets ON batch_changes;\nDROP FUNCTION IF EXISTS delete_campaign_reference_on_changesets();\nCREATE FUNCTION delete_batch_change_reference_on_changesets() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        UPDATE\n          changesets\n        SET\n          batch_change_ids = changesets.batch_change_ids - OLD.id::text\n        WHERE\n          changesets.batch_change_ids ? OLD.id::text;\n\n        RETURN OLD;\n    END;\n$$;\nCREATE TRIGGER trig_delete_batch_change_reference_on_changesets AFTER DELETE ON batch_changes FOR EACH ROW EXECUTE PROCEDURE delete_batch_change_reference_on_changesets();\nALTER SEQUENCE campaigns_id_seq RENAME TO batch_changes_id_seq;\nALTER SEQUENCE campaign_specs_id_seq RENAME TO batch_specs_id_seq;\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_campaign_spec_id_fkey\" TO \"batch_changes_batch_spec_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_initial_applier_id_fkey\" TO \"batch_changes_initial_applier_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_last_applier_id_fkey\" TO \"batch_changes_last_applier_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_namespace_org_id_fkey\" TO \"batch_changes_namespace_org_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_namespace_user_id_fkey\" TO \"batch_changes_namespace_user_id_fkey\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_has_1_namespace\" TO \"batch_changes_has_1_namespace\";\nALTER TABLE batch_changes RENAME CONSTRAINT \"campaigns_name_not_blank\" TO \"batch_changes_name_not_blank\";\nALTER INDEX IF EXISTS campaigns_pkey RENAME TO batch_changes_pkey;\nALTER INDEX IF EXISTS campaigns_namespace_org_id RENAME TO batch_changes_namespace_org_id;\nALTER INDEX IF EXISTS campaigns_namespace_user_id RENAME TO batch_changes_namespace_user_id;\nALTER TABLE batch_specs RENAME CONSTRAINT \"campaign_specs_has_1_namespace\" TO \"batch_specs_has_1_namespace\";\nALTER TABLE batch_specs RENAME CONSTRAINT \"campaign_specs_user_id_fkey\" TO \"batch_specs_user_id_fkey\";\nALTER INDEX IF EXISTS campaign_specs_pkey RENAME TO batch_specs_pkey;\nALTER INDEX IF EXISTS campaign_specs_rand_id RENAME TO batch_specs_rand_id;\nALTER TABLE changeset_specs RENAME CONSTRAINT \"changeset_specs_campaign_spec_id_fkey\" TO \"changeset_specs_batch_spec_id_fkey\";\nALTER TABLE changesets RENAME CONSTRAINT \"changesets_owned_by_campaign_id_fkey\" TO \"changesets_owned_by_batch_spec_id_fkey\";\nALTER TABLE changesets RENAME CONSTRAINT \"changesets_campaign_ids_check\" TO \"changesets_batch_change_ids_check\";",
				"DownQuery": "UPDATE user_credentials SET domain = 'campaigns' WHERE domain = 'batches';\nALTER TABLE IF EXISTS batch_specs RENAME TO campaign_specs;\nALTER TABLE IF EXISTS batch_changes RENAME TO campaigns;\nALTER TABLE IF EXISTS campaigns RENAME COLUMN batch_spec_id TO campaign_spec_id;\nALTER TABLE IF EXISTS changeset_specs RENAME COLUMN batch_spec_id TO campaign_spec_id;\nDROP VIEW IF EXISTS reconciler_changesets;\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\nALTER TABLE IF EXISTS changesets RENAME COLUMN batch_change_ids TO campaign_ids;\nALTER TABLE IF EXISTS changesets RENAME COLUMN owned_by_batch_change_id TO owned_by_campaign_id;\nCREATE VIEW tracking_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        repo.name AS repo_name,\n        COALESCE(changesets.metadata -\u003e\u003e 'Title'::text, changesets.metadata -\u003e\u003e 'title'::text) AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM\n        changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.external_id = changeset_specs.external_id\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NOT NULL\n        AND\n        repo.deleted_at IS NULL\n);\nCREATE VIEW branch_changeset_specs_and_changesets AS (\n    SELECT\n        changeset_specs.id AS changeset_spec_id,\n        COALESCE(changesets.id, 0::bigint) AS changeset_id,\n        changeset_specs.repo_id,\n        changeset_specs.campaign_spec_id,\n        changesets.owned_by_campaign_id AS owner_campaign_id,\n        repo.name AS repo_name,\n        changeset_specs.title AS changeset_name,\n        changesets.external_state,\n        changesets.publication_state,\n        changesets.reconciler_state\n    FROM changeset_specs\n    LEFT JOIN\n        changesets\n    ON\n        changesets.repo_id = changeset_specs.repo_id\n        AND\n        changesets.current_spec_id IS NOT NULL\n        AND\n        EXISTS (\n            SELECT 1\n            FROM changeset_specs changeset_specs_1\n            WHERE\n                changeset_specs_1.id = changesets.current_spec_id\n                AND\n                changeset_specs_1.head_ref = changeset_specs.head_ref\n        )\n    JOIN\n        repo\n    ON\n        changeset_specs.repo_id = repo.id\n    WHERE\n        changeset_specs.external_id IS NULL\n        AND\n        repo.deleted_at IS NULL\n);\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM campaigns\n            LEFT JOIN users namespace_user ON campaigns.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON campaigns.namespace_org_id = namespace_org.id\n            WHERE\n                c.campaign_ids ? campaigns.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\nDROP TRIGGER IF EXISTS trig_delete_batch_change_reference_on_changesets ON campaigns;\nDROP FUNCTION IF EXISTS delete_batch_change_reference_on_changesets();\nCREATE FUNCTION delete_campaign_reference_on_changesets() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$\n    BEGIN\n        UPDATE\n          changesets\n        SET\n          batch_change_ids = changesets.batch_change_ids - OLD.id::text\n        WHERE\n          changesets.batch_change_ids ? OLD.id::text;\n\n        RETURN OLD;\n    END;\n$$;\nCREATE TRIGGER trig_delete_campaign_reference_on_changesets AFTER DELETE ON campaigns FOR EACH ROW EXECUTE PROCEDURE delete_campaign_reference_on_changesets();\nALTER SEQUENCE batch_changes_id_seq RENAME TO campaigns_id_seq;\nALTER SEQUENCE batch_specs_id_seq RENAME TO campaign_specs_id_seq;\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_batch_spec_id_fkey\" TO \"campaigns_campaign_spec_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_initial_applier_id_fkey\" TO \"campaigns_initial_applier_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_last_applier_id_fkey\" TO \"campaigns_last_applier_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_namespace_org_id_fkey\" TO \"campaigns_namespace_org_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_namespace_user_id_fkey\" TO \"campaigns_namespace_user_id_fkey\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_has_1_namespace\" TO \"campaigns_has_1_namespace\";\nALTER TABLE campaigns RENAME CONSTRAINT \"batch_changes_name_not_blank\" TO \"campaigns_name_not_blank\";\nALTER INDEX IF EXISTS batch_changes_pkey RENAME TO campaigns_pkey;\nALTER INDEX IF EXISTS batch_changes_namespace_org_id RENAME TO campaigns_namespace_org_id;\nALTER INDEX IF EXISTS batch_changes_namespace_user_id RENAME TO campaigns_namespace_user_id;\nALTER TABLE campaign_specs RENAME CONSTRAINT \"batch_specs_has_1_namespace\" TO \"campaign_specs_has_1_namespace\";\nALTER TABLE campaign_specs RENAME CONSTRAINT \"batch_specs_user_id_fkey\" TO \"campaign_specs_user_id_fkey\";\nALTER INDEX IF EXISTS batch_specs_pkey RENAME TO campaign_specs_pkey;\nALTER INDEX IF EXISTS batch_specs_rand_id RENAME TO campaign_specs_rand_id;\nALTER TABLE changeset_specs RENAME CONSTRAINT \"changeset_specs_batch_spec_id_fkey\" TO \"changeset_specs_campaign_spec_id_fkey\";\nALTER TABLE changesets RENAME CONSTRAINT \"changesets_owned_by_batch_spec_id_fkey\" TO \"changesets_owned_by_campaign_id_fkey\";\nALTER TABLE changesets RENAME CONSTRAINT \"changesets_batch_change_ids_check\" TO \"changesets_campaign_ids_check\";",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395793
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395795,
				"Name": "add clone status index to gitserver repos",
				"UpQuery": "CREATE INDEX IF NOT EXISTS gitserver_repos_clone_status_idx ON gitserver_repos (clone_status);",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_clone_status_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395794
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395796,
				"Name": "alter cloud default constraint",
				"UpQuery": "DROP INDEX IF EXISTS kind_cloud_default;\nCREATE UNIQUE INDEX IF NOT EXISTS kind_cloud_default ON external_services (kind, cloud_default)\n    WHERE cloud_default = true AND deleted_at IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS kind_cloud_default;\nCREATE UNIQUE INDEX IF NOT EXISTS kind_cloud_default ON external_services (kind, cloud_default)\n    WHERE cloud_default = true;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395795
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395797,
				"Name": "faster changeset lookups",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS changesets_batch_change_ids ON changesets USING GIN (batch_change_ids jsonb_ops);",
				"DownQuery": "DROP INDEX IF EXISTS changesets_batch_change_ids;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395796
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changesets",
					"IndexName": "changesets_batch_change_ids"
				}
			},
			{
				"ID": 1528395798,
				"Name": "changeset title",
				"UpQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS external_title text;\nCOMMENT ON COLUMN changesets.external_title IS 'Normalized property generated on save using Changeset.Title()';\n\nUPDATE changesets SET external_title = COALESCE(changesets.metadata-\u003e\u003e'Title', changesets.metadata-\u003e\u003e'title', NULL);\n\nCREATE INDEX IF NOT EXISTS changesets_external_title_idx ON changesets USING BTREE(external_title);\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nDROP INDEX IF EXISTS changesets_external_title_idx;\nALTER TABLE changesets DROP COLUMN IF EXISTS external_title;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395797
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395799,
				"Name": "add clone status conditional indexes",
				"UpQuery": "-- Having three partial indexes should be faster since when the condition is met the index used will be\n-- smaller meaning it will be faster to scan.\nCREATE INDEX IF NOT EXISTS gitserver_repos_cloned_status_idx ON gitserver_repos (repo_id) WHERE clone_status = 'cloned';\nCREATE INDEX IF NOT EXISTS gitserver_repos_not_cloned_status_idx ON gitserver_repos (repo_id) WHERE clone_status = 'not_cloned';\nCREATE INDEX IF NOT EXISTS gitserver_repos_cloning_status_idx ON gitserver_repos (repo_id) WHERE clone_status = 'cloning';\n\nDROP INDEX IF EXISTS gitserver_repos_clone_status_idx;",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_cloned_status_idx;\nDROP INDEX IF EXISTS gitserver_repos_not_cloned_status_idx;\nDROP INDEX IF EXISTS gitserver_repos_cloning_status_idx;\nCREATE INDEX IF NOT EXISTS gitserver_repos_clone_status_idx ON gitserver_repos (repo_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395798
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395800,
				"Name": "add external service repos index",
				"UpQuery": "CREATE INDEX external_service_repos_idx ON external_service_repos(external_service_id, repo_id);",
				"DownQuery": "DROP INDEX IF EXISTS external_service_repos_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395799
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395801,
				"Name": "search contexts",
				"UpQuery": "CREATE TABLE IF NOT EXISTS search_contexts (\n    id BIGSERIAL PRIMARY KEY,\n    name citext NOT NULL,\n    description text NOT NULL,\n    public boolean NOT NULL,\n    namespace_user_id integer,\n    namespace_org_id integer,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    deleted_at timestamp with time zone,\n\n    CONSTRAINT search_contexts_has_one_or_no_namespace CHECK (((namespace_user_id IS NULL) OR (namespace_org_id IS NULL))),\n\n    CONSTRAINT search_contexts_namespace_user_id_fk\n        FOREIGN KEY (namespace_user_id)\n            REFERENCES users (id)\n            ON DELETE CASCADE,\n\n    CONSTRAINT search_contexts_namespace_org_id_fk\n        FOREIGN KEY (namespace_org_id)\n            REFERENCES orgs (id)\n            ON DELETE CASCADE\n);\n\nCREATE UNIQUE INDEX search_contexts_name_namespace_user_id_unique\n    ON search_contexts (name, namespace_user_id)\n    WHERE namespace_user_id IS NOT NULL;\n\nCREATE UNIQUE INDEX search_contexts_name_namespace_org_id_unique\n    ON search_contexts (name, namespace_org_id)\n    WHERE namespace_org_id IS NOT NULL;\n\nCREATE UNIQUE INDEX search_contexts_name_without_namespace_unique\n    ON search_contexts (name)\n    WHERE namespace_user_id IS NULL AND namespace_org_id IS NULL;\n\nCREATE TABLE IF NOT EXISTS search_context_repos (\n    search_context_id bigint NOT NULL,\n    repo_id integer NOT NULL,\n    revision text NOT NULL,\n\n    CONSTRAINT search_context_repos_search_context_id_fk\n        FOREIGN KEY (search_context_id)\n            REFERENCES search_contexts (id)\n            ON DELETE CASCADE,\n\n    CONSTRAINT search_context_repos_repo_id_fk\n        FOREIGN KEY (repo_id)\n            REFERENCES repo (id)\n            ON DELETE CASCADE,\n\n    CONSTRAINT search_context_repos_search_context_id_repo_id_revision_unique UNIQUE (search_context_id, repo_id, revision)\n);",
				"DownQuery": "DROP TABLE IF EXISTS search_context_repos;\n\nDROP TABLE IF EXISTS search_contexts;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395800
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395802,
				"Name": "external service config migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, deprecated, non_destructive)\nVALUES (3, 'core-application', 'frontend-db.external-services', 'Encrypt configuration', '3.26.0', '3.27.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395801
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395803,
				"Name": "drop trig soft delete orphan repo by external service repo",
				"UpQuery": "-- Drop trigger as we don't want it to fire anymore.\nDROP TRIGGER IF EXISTS trig_soft_delete_orphan_repo_by_external_service_repo ON external_service_repos;\nDROP FUNCTION IF EXISTS soft_delete_orphan_repo_by_external_service_repos() ;\n\n-- Rewrite the previous function as a standalone function.\n-- The function will be run manually whenever we delete an external service.\nCREATE FUNCTION soft_delete_orphan_repo_by_external_service_repos() RETURNS void\n    AS $$\nBEGIN\n    -- When an external service is soft or hard-deleted,\n    -- performs a clean up to soft-delete orphan repositories.\n    UPDATE\n        repo\n    SET\n        name = soft_deleted_repository_name(name),\n        deleted_at = transaction_timestamp()\n    WHERE\n      deleted_at IS NULL\n      AND NOT EXISTS (\n        SELECT FROM external_service_repos WHERE repo_id = repo.id\n      );\nEND;\n$$ LANGUAGE plpgsql;",
				"DownQuery": "DROP FUNCTION IF EXISTS soft_delete_orphan_repo_by_external_service_repos();\n\nCREATE FUNCTION soft_delete_orphan_repo_by_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\nAS $$\nBEGIN\n    -- When an external service is soft or hard-deleted,\n    -- performs a clean up to soft-delete orphan repositories.\n    UPDATE\n        repo\n    SET\n        name = soft_deleted_repository_name(name),\n        deleted_at = transaction_timestamp()\n    WHERE\n      deleted_at IS NULL\n      AND NOT EXISTS (\n        SELECT FROM external_service_repos WHERE repo_id = repo.id\n    );\n\n    RETURN NULL;\nEND;\n$$;\n\nCREATE TRIGGER trig_soft_delete_orphan_repo_by_external_service_repo\n    AFTER DELETE ON external_service_repos\n    FOR EACH STATEMENT EXECUTE PROCEDURE soft_delete_orphan_repo_by_external_service_repos();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395802
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395804,
				"Name": "batch changes site credentials",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_changes_site_credentials (\n    id BIGSERIAL PRIMARY KEY,\n    external_service_type text NOT NULL,\n    external_service_id text NOT NULL,\n    credential text NOT NULL,\n    created_at timestamp with time zone NOT NULL DEFAULT now(),\n    updated_at timestamp with time zone NOT NULL DEFAULT now()\n);\n\nCREATE UNIQUE INDEX batch_changes_site_credentials_unique ON batch_changes_site_credentials(external_service_type, external_service_id);",
				"DownQuery": "DROP TABLE IF EXISTS batch_changes_site_credentials;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395803
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395805,
				"Name": "delete external service trigger",
				"UpQuery": "DROP TRIGGER IF EXISTS trig_delete_external_service_ref_on_external_service_repos\nON external_services;\n\nDROP FUNCTION IF EXISTS delete_external_service_ref_on_external_service_repos();",
				"DownQuery": "CREATE FUNCTION delete_external_service_ref_on_external_service_repos() RETURNS trigger\n    LANGUAGE plpgsql\nAS $$\nBEGIN\n    -- if an external service is soft-deleted, delete every row that references it\n    IF (OLD.deleted_at IS NULL AND NEW.deleted_at IS NOT NULL) THEN\n        DELETE FROM\n            external_service_repos\n        WHERE\n                external_service_id = OLD.id;\n    END IF;\n\n    RETURN OLD;\nEND;\n$$;\n\nCREATE TRIGGER trig_delete_external_service_ref_on_external_service_repos\n    AFTER UPDATE OF deleted_at ON external_services FOR EACH ROW EXECUTE PROCEDURE delete_external_service_ref_on_external_service_repos();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395804
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395806,
				"Name": "add encryption key ident",
				"UpQuery": "ALTER TABLE user_external_accounts ADD COLUMN IF NOT EXISTS encryption_key_id text NOT NULL DEFAULT '';",
				"DownQuery": "ALTER TABLE user_external_accounts DROP COLUMN IF EXISTS encryption_key_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395805
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395807,
				"Name": "lsif locations migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (4, 'code-intelligence', 'codeintel-db.lsif_data_definitions', 'Populate num_locations from gob-encoded payload', '3.26.0', true)\nON CONFLICT DO NOTHING;\n\nINSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (5, 'code-intelligence', 'codeintel-db.lsif_data_references', 'Populate num_locations from gob-encoded payload', '3.26.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395806
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395808,
				"Name": "add user id column to external service repos",
				"UpQuery": "ALTER TABLE external_service_repos ADD COLUMN user_id int REFERENCES users(id) ON DELETE CASCADE DEFERRABLE;\n\nUPDATE external_service_repos\nSET user_id = es.namespace_user_id\nFROM external_services es\nWHERE es.id = external_service_id AND es.namespace_user_id IS NOT NULL;\n\nCREATE INDEX external_service_user_repos_idx ON external_service_repos(user_id, repo_id) WHERE user_id IS NOT NULL;",
				"DownQuery": "DROP INDEX external_service_user_repos_idx;\nALTER TABLE external_service_repos DROP COLUMN user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395807
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395809,
				"Name": "external account migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (6, 'core-application', 'frontend-db.external-accounts', 'Encrypt auth data', '3.26.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395808
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395810,
				"Name": "split document payload",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (7, 'code-intelligence', 'codeintel-db.lsif_data_documents', 'Split payload into multiple columns', '3.27.0', false)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395809
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395811,
				"Name": "add gitserver repos last error idx",
				"UpQuery": "CREATE INDEX IF NOT EXISTS\n    gitserver_repos_last_error_idx ON gitserver_repos(last_error) WHERE last_error IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_last_error_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395810
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395812,
				"Name": "drop global state mgmt password columns",
				"UpQuery": "ALTER TABLE global_state\nDROP COLUMN IF EXISTS mgmt_password_plaintext,\nDROP COLUMN IF EXISTS mgmt_password_bcrypt;",
				"DownQuery": "ALTER TABLE global_state\nADD COLUMN IF NOT EXISTS mgmt_password_plaintext TEXT NOT NULL DEFAULT '',\nADD COLUMN IF NOT EXISTS mgmt_password_bcrypt TEXT NOT NULL DEFAULT '';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395811
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395813,
				"Name": "gitserver repos add cascade delete",
				"UpQuery": "SET CONSTRAINTS ALL DEFERRED;\n\nALTER TABLE gitserver_repos\n    DROP CONSTRAINT gitserver_repos_repo_id_fkey,\n    ADD CONSTRAINT gitserver_repos_repo_id_fkey\n        FOREIGN KEY (repo_id)\n            REFERENCES repo (id)\n            ON DELETE CASCADE;",
				"DownQuery": "SET CONSTRAINTS ALL DEFERRED;\n\nALTER TABLE gitserver_repos\n    DROP CONSTRAINT gitserver_repos_repo_id_fkey,\n    ADD CONSTRAINT gitserver_repos_repo_id_fkey\n        FOREIGN KEY (repo_id)\n            REFERENCES repo (id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395812
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395814,
				"Name": "add cascase delete on external service sync jobs",
				"UpQuery": "SET CONSTRAINTS ALL DEFERRED;\n\nALTER TABLE external_service_sync_jobs\n    DROP CONSTRAINT external_services_id_fk,\n    ADD CONSTRAINT external_services_id_fk\n        FOREIGN KEY (external_service_id)\n            REFERENCES external_services (id)\n            ON DELETE CASCADE;",
				"DownQuery": "SET CONSTRAINTS ALL DEFERRED;\n\nALTER TABLE external_service_sync_jobs\n    DROP CONSTRAINT external_services_id_fk,\n    ADD CONSTRAINT external_services_id_fk\n        FOREIGN KEY (external_service_id)\n            REFERENCES external_services (id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395813
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395815,
				"Name": "undeprecate oob migrations",
				"UpQuery": "-- No out of band migrations should be marked as deprecated yet\n-- as we don't have any utilities in place to check whether or\n-- not migrations have yet completed.\n\nUPDATE out_of_band_migrations SET deprecated = NULL;",
				"DownQuery": "-- Nothing to do.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395814
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395816,
				"Name": "changeset bulk jobs table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS changeset_jobs (\n    id BIGSERIAL PRIMARY KEY,\n    bulk_group text NOT NULL,\n    user_id integer NOT NULL REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n    batch_change_id integer NOT NULL REFERENCES batch_changes(id) ON DELETE CASCADE DEFERRABLE,\n    changeset_id integer NOT NULL REFERENCES changesets(id) ON DELETE CASCADE DEFERRABLE,\n\n    job_type text NOT NULL,\n    payload jsonb DEFAULT '{}'::jsonb CHECK (jsonb_typeof(payload) = 'object'::text),\n\n    state text DEFAULT 'queued'::text,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer NOT NULL DEFAULT 0,\n    num_failures integer NOT NULL DEFAULT 0,\n    execution_logs json[],\n\n    created_at timestamp with time zone NOT NULL DEFAULT now(),\n    updated_at timestamp with time zone NOT NULL DEFAULT now()\n);",
				"DownQuery": "DROP TABLE IF EXISTS changeset_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395815
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395817,
				"Name": "lsif uploads committed at",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN committed_at timestamp with time zone;\nCREATE INDEX lsif_uploads_committed_at ON lsif_uploads (committed_at) WHERE state = 'completed';\n\nINSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (8, 'code-intelligence', 'frontend-db.lsif_uploads', 'Backfill committed_at', '3.28.0', true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "DROP INDEX lsif_uploads_committed_at;\nALTER TABLE lsif_uploads DROP COLUMN committed_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395816
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395818,
				"Name": "commit last checked at",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN commit_last_checked_at timestamp with time zone;\nCREATE INDEX lsif_uploads_commit_last_checked_at ON lsif_uploads (commit_last_checked_at) WHERE state != 'deleted';\nALTER TABLE lsif_indexes ADD COLUMN commit_last_checked_at timestamp with time zone;\nCREATE INDEX lsif_indexes_commit_last_checked_at ON lsif_indexes (commit_last_checked_at) WHERE state != 'deleted';",
				"DownQuery": "DROP INDEX lsif_uploads_commit_last_checked_at;\nALTER TABLE lsif_uploads DROP COLUMN commit_last_checked_at;\nDROP INDEX lsif_indexes_commit_last_checked_at;\nALTER TABLE lsif_indexes DROP COLUMN commit_last_checked_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395817
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395819,
				"Name": "oob credential encryption",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (\n    9,                                          -- This must be consistent across all Sourcegraph instances\n    'batch-changes',                            -- Team owning migration\n    'frontend-db.user-credentials',             -- Component being migrated\n    'Encrypt batch changes user credentials',   -- Description\n    '3.28.0',                                   -- The next minor release\n    false                                       -- Can be read with previous version without down migration\n)\nON CONFLICT DO NOTHING;\n\nALTER TABLE\n    user_credentials\nADD COLUMN IF NOT EXISTS\n    credential_enc BYTEA NULL,\nADD COLUMN IF NOT EXISTS\n    ssh_migration_applied BOOLEAN NOT NULL DEFAULT FALSE,\nALTER COLUMN\n    credential DROP NOT NULL,\nDROP CONSTRAINT IF EXISTS\n    user_credentials_there_can_be_only_one,\nADD CONSTRAINT\n    user_credentials_there_can_be_only_one\n    CHECK\n    (num_nonnulls(credential, credential_enc) = 1);\n\n-- Calculate the ssh_migration_applied field using the same algorithm as the\n-- previous version of the SSH migrator.\nUPDATE\n    user_credentials\nSET\n    ssh_migration_applied = TRUE\nWHERE\n    credential IS NOT NULL\n    AND domain = 'batches'\n    AND (credential::json-\u003e'Type')::text NOT IN (\n        'BasicAuth',\n        'OAuthBearerToken'\n    );\n\n-- Create an index on credential_enc, since we want to quickly check its null\n-- state when calculating the progress of the OOB migration. Note that we can't\n-- apply an index to the actual field because it may be (and in many cases\n-- probably is) beyond the limit for a B-tree index.\nCREATE INDEX IF NOT EXISTS\n    user_credentials_credential_enc_idx\nON\n    user_credentials ((credential_enc IS NULL));",
				"DownQuery": "-- We need to leave the new column in place here for the OOB down migration, so\n-- no changes here.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395818
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395820,
				"Name": "changeset job indexes",
				"UpQuery": "-- Create an index on state, so the dbworker can fetch pending jobs faster.\nCREATE INDEX IF NOT EXISTS changeset_jobs_state_idx ON changeset_jobs USING BTREE(state);\n-- Create an index on the bulk_group column. We use this as sort of a second-line\n-- primary key, because the bulk_group entity doesn't really exist.\nCREATE INDEX IF NOT EXISTS changeset_jobs_bulk_group_idx ON changeset_jobs USING BTREE(bulk_group);",
				"DownQuery": "DROP INDEX IF EXISTS changeset_jobs_state_idx;\nDROP INDEX IF EXISTS changeset_jobs_bulk_group_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395819
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395821,
				"Name": "oob site credential encryption",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced, non_destructive)\nVALUES (\n    10,                                         -- This must be consistent across all Sourcegraph instances\n    'batch-changes',                            -- Team owning migration\n    'frontend-db.site-credentials',             -- Component being migrated\n    'Encrypt batch changes site credentials',   -- Description\n    '3.28.0',                                   -- The next minor release\n    false                                       -- Can be read with previous version without down migration\n)\nON CONFLICT DO NOTHING;\n\nALTER TABLE\n    batch_changes_site_credentials\nADD COLUMN IF NOT EXISTS\n    credential_enc BYTEA NULL,\nALTER COLUMN\n    credential DROP NOT NULL,\nDROP CONSTRAINT IF EXISTS\n    batch_changes_site_credentials_there_can_be_only_one,\nADD CONSTRAINT\n    batch_changes_site_credentials_there_can_be_only_one\n    CHECK\n    (num_nonnulls(credential, credential_enc) = 1);\n\n-- Create an index on credential_enc, since we want to quickly check its null\n-- state when calculating the progress of the OOB migration. Note that we can't\n-- apply an index to the actual field because it may be (and in many cases\n-- probably is) beyond the limit for a B-tree index.\nCREATE INDEX IF NOT EXISTS\n    batch_changes_site_credentials_credential_enc_idx\nON\n    batch_changes_site_credentials ((credential_enc IS NULL));",
				"DownQuery": "-- We need to leave the new column in place here for the OOB down migration, so\n-- no changes here.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395820
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395822,
				"Name": "track encryption key",
				"UpQuery": "-- We're going to unify the credential columns here. This means that we need to\n-- preserve the value in credential if the OOB migrator hasn't run since the\n-- previous credential migrations.\n--\n-- Since this will break the constraint we added previously, first we have to\n-- drop that.\n\nALTER TABLE\n    batch_changes_site_credentials\nADD COLUMN IF NOT EXISTS\n    encryption_key_id TEXT NOT NULL DEFAULT '',\nDROP CONSTRAINT IF EXISTS\n    batch_changes_site_credentials_there_can_be_only_one;\n\nALTER TABLE\n    user_credentials\nADD COLUMN IF NOT EXISTS\n    encryption_key_id TEXT NOT NULL DEFAULT '',\nDROP CONSTRAINT IF EXISTS\n    user_credentials_there_can_be_only_one;\n\n-- Previously upgraded credentials with encryption need a placeholder encryption\n-- ID so that we can replace it with a real one later in the OOB migrator.\n--\n-- Unfortunately, the lack of inline metadata means that we have to use a\n-- heuristic to determine if the credential was _actually_ encrypted or not.\n-- Practically speaking, this only matters for users who (a) enabled encryption\n-- for Batch Changes, and (b) ran a version of Sourcegraph between May 4 and May\n-- 6. That's only going to be two developers on the Batch Changes team, so this\n-- leaky heuristic should be fine.\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    encryption_key_id = 'previously-migrated'\nWHERE\n    credential_enc IS NOT NULL\n    AND NOT (\n        LEFT(ENCODE(credential_enc, 'escape'), 1) = '{'\n        AND RIGHT(ENCODE(credential_enc, 'escape'), 1) = '}'\n    );\n\nUPDATE\n    user_credentials\nSET\n    encryption_key_id = 'previously-migrated'\nWHERE\n    credential_enc IS NOT NULL\n    AND NOT (\n        LEFT(ENCODE(credential_enc, 'escape'), 1) = '{'\n        AND RIGHT(ENCODE(credential_enc, 'escape'), 1) = '}'\n    );\n\n-- Now we shift credentials into the new field.\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    credential_enc = CONVERT_TO(credential, 'UTF8')\nWHERE\n    credential_enc IS NULL;\n\nUPDATE\n    user_credentials\nSET\n    credential_enc = CONVERT_TO(credential, 'UTF8')\nWHERE\n    credential_enc IS NULL;\n\n-- And finally we can rename the field and update the indexes on the tables.\n\nDROP INDEX IF EXISTS\n    batch_changes_site_credentials_credential_enc_idx,\n    batch_changes_site_credentials_credential_idx,\n    user_credentials_credential_enc_idx,\n    user_credentials_credential_idx;\n\nALTER TABLE\n    batch_changes_site_credentials\nDROP COLUMN IF EXISTS\n    credential,\nALTER COLUMN\n    credential_enc SET NOT NULL;\n\nALTER TABLE\n    batch_changes_site_credentials\nRENAME COLUMN\n    credential_enc TO credential;\n\nALTER TABLE\n    user_credentials\nDROP COLUMN IF EXISTS\n    credential,\nALTER COLUMN\n    credential_enc SET NOT NULL;\n\nALTER TABLE\n    user_credentials\nRENAME COLUMN\n    credential_enc TO credential;\n\nCREATE INDEX IF NOT EXISTS\n    batch_changes_site_credentials_credential_idx\nON\n    batch_changes_site_credentials ((encryption_key_id IN ('', 'previously-migrated')));\n\nCREATE INDEX IF NOT EXISTS\n    user_credentials_credential_idx\nON\n    user_credentials ((encryption_key_id IN ('', 'previously-migrated')));",
				"DownQuery": "-- Where we're going, we don't need indexes. (Yet.)\n\nDROP INDEX IF EXISTS\n    batch_changes_site_credentials_credential_enc_idx,\n    batch_changes_site_credentials_credential_idx,\n    user_credentials_credential_enc_idx,\n    user_credentials_credential_idx;\n\n-- Reinstate the old credential field.\n\nALTER TABLE\n    batch_changes_site_credentials\nRENAME COLUMN\n    credential TO credential_enc;\n\nALTER TABLE\n    batch_changes_site_credentials\nADD COLUMN IF NOT EXISTS\n    credential TEXT NULL DEFAULT NULL,\nALTER COLUMN\n    credential_enc DROP NOT NULL,\nDROP CONSTRAINT IF EXISTS\n    batch_changes_site_credentials_there_can_be_only_one,\nADD CONSTRAINT\n    batch_changes_site_credentials_there_can_be_only_one\n    CHECK\n    (num_nonnulls(credential, credential_enc) = 1);\n\nALTER TABLE\n    user_credentials\nRENAME COLUMN\n    credential TO credential_enc;\n\nALTER TABLE\n    user_credentials\nADD COLUMN IF NOT EXISTS\n    credential TEXT NULL DEFAULT NULL,\nALTER COLUMN\n    credential_enc DROP NOT NULL,\nDROP CONSTRAINT IF EXISTS\n    user_credentials_there_can_be_only_one,\nADD CONSTRAINT\n    user_credentials_there_can_be_only_one\n    CHECK\n    (num_nonnulls(credential, credential_enc) = 1);\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    credential = ENCODE(credential_enc, 'escape'),\n    credential_enc = NULL\nWHERE\n    encryption_key_id = '';\n\nUPDATE\n    user_credentials\nSET\n    credential = ENCODE(credential_enc, 'escape'),\n    credential_enc = NULL\nWHERE\n    encryption_key_id = '';\n\n-- Put the indexes back.\n\nCREATE INDEX IF NOT EXISTS\n    user_credentials_credential_enc_idx\nON\n    user_credentials ((credential_enc IS NULL));\n\nCREATE INDEX IF NOT EXISTS\n    batch_changes_site_credentials_credential_enc_idx\nON\n    batch_changes_site_credentials ((credential_enc IS NULL));\n\n-- Get rid of the new encryption_key_id field.\n\nALTER TABLE\n    batch_changes_site_credentials\nDROP COLUMN IF EXISTS\n    encryption_key_id;\n\nALTER TABLE\n    user_credentials\nDROP COLUMN IF EXISTS\n    encryption_key_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395821
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395823,
				"Name": "feature flags",
				"UpQuery": "CREATE TYPE feature_flag_type AS ENUM ('bool', 'rollout');\n\nCREATE TABLE IF NOT EXISTS feature_flags (\n\tflag_name text NOT NULL PRIMARY KEY,\n\tflag_type feature_flag_type NOT NULL,\n\tbool_value boolean,\n\trollout integer CHECK (rollout \u003e= 0 AND rollout \u003c= 10000),\n\n\tcreated_at timestamp with time zone DEFAULT now() NOT NULL,\n\tupdated_at timestamp with time zone DEFAULT now() NOT NULL,\n\tdeleted_at timestamp with time zone,\n\n\tCONSTRAINT required_bool_fields\tCHECK ( 1 = CASE\n\t\tWHEN flag_type = 'bool' AND bool_value IS NULL THEN 0\n\t\tWHEN flag_type \u003c\u003e 'bool' AND bool_value IS NOT NULL THEN 0\n\t\tELSE 1\n\tEND),\n\n\tCONSTRAINT required_rollout_fields CHECK (1 = CASE\n\t\tWHEN flag_type = 'rollout' AND rollout IS NULL THEN 0\n\t\tWHEN flag_type \u003c\u003e 'rollout' AND rollout IS NOT NULL THEN 0\n\t\tELSE 1\n\tEND)\n);\n\nCOMMENT ON COLUMN feature_flags.bool_value IS 'Bool value only defined when flag_type is bool';\nCOMMENT ON COLUMN feature_flags.rollout IS 'Rollout only defined when flag_type is rollout. Increments of 0.01%';\nCOMMENT ON CONSTRAINT required_bool_fields ON feature_flags IS 'Checks that bool_value is set IFF flag_type = bool';\nCOMMENT ON CONSTRAINT required_rollout_fields ON feature_flags IS 'Checks that rollout is set IFF flag_type = rollout';\n\nCREATE TABLE IF NOT EXISTS feature_flag_overrides (\n\tnamespace_org_id integer,\n\tnamespace_user_id integer,\n\tflag_name text NOT NULL,\n\tflag_value boolean NOT NULL,\n\tcreated_at timestamp with time zone DEFAULT now() NOT NULL,\n\tupdated_at timestamp with time zone DEFAULT now() NOT NULL,\n\tdeleted_at timestamp with time zone,\n\n\tCONSTRAINT feature_flag_overrides_unique_user_flag \n\t\tUNIQUE (namespace_user_id, flag_name),\n\n\tCONSTRAINT feature_flag_overrides_unique_org_flag \n\t\tUNIQUE (namespace_org_id, flag_name),\n\n\tCONSTRAINT feature_flag_overrides_has_org_or_user_id CHECK(\n\t\t(namespace_org_id IS NOT NULL) OR (namespace_user_id IS NOT NULL)),\n\n\tFOREIGN KEY (flag_name) REFERENCES feature_flags (flag_name) ON DELETE CASCADE,\n\tFOREIGN KEY (namespace_org_id) REFERENCES orgs (id) ON DELETE CASCADE,\n\tFOREIGN KEY (namespace_user_id) REFERENCES users (id) ON DELETE CASCADE\n);\n\nCREATE INDEX feature_flag_overrides_org_id\n\tON feature_flag_overrides (namespace_org_id)\n\tWHERE namespace_org_id IS NOT NULL;\n\nCREATE INDEX feature_flag_overrides_user_id\n\tON feature_flag_overrides (namespace_user_id)\n\tWHERE namespace_user_id IS NOT NULL;",
				"DownQuery": "DROP TABLE IF EXISTS feature_flag_overrides;\n\nDROP TABLE IF EXISTS feature_flags;\n\nDROP TYPE feature_flag_type;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395822
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395824,
				"Name": "fix lsif upload state casing",
				"UpQuery": "UPDATE lsif_uploads SET state = 'deleted' WHERE state = 'DELETED';",
				"DownQuery": "-- Nothing to do",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395823
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395825,
				"Name": "add upload dependency indexing jobs",
				"UpQuery": "CREATE TABLE lsif_dependency_indexing_jobs (\n    id serial PRIMARY KEY,\n    state text DEFAULT 'queued' NOT NULL,\n    failure_message text,\n    queued_at timestamp with time zone DEFAULT NOW() NOT NULL,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    upload_id integer REFERENCES lsif_uploads(id) ON DELETE CASCADE\n);\n\nCOMMENT ON TABLE lsif_dependency_indexing_jobs IS 'Tracks jobs that scan imports of indexes to schedule auto-index jobs.';\nCOMMENT ON COLUMN lsif_dependency_indexing_jobs.upload_id IS 'The identifier of the triggering upload record.';",
				"DownQuery": "DROP TABLE lsif_dependency_indexing_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395824
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395826,
				"Name": "track first version",
				"UpQuery": "ALTER TABLE versions ADD COLUMN first_version text;\nUPDATE versions set first_version = version;\nALTER TABLE versions ALTER COLUMN first_version SET NOT NULL;",
				"DownQuery": "ALTER TABLE versions DROP COLUMN first_version;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395825
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395827,
				"Name": "oob enterprise flag",
				"UpQuery": "-- Add enterprise flag to out of band migrations so we know what to ignore in OSS\n-- If we don't run the migrators but the progress for the enterprise migration\n-- record stays at 0% it will block all upgrades after the migration deprecation.\n\nALTER TABLE out_of_band_migrations ADD COLUMN is_enterprise boolean DEFAULT false;\nUPDATE out_of_band_migrations SET is_enterprise = true WHERE id NOT IN (3, 6);\nALTER TABLE out_of_band_migrations ALTER COLUMN is_enterprise SET NOT NULL;\n\nCOMMENT ON COLUMN out_of_band_migrations.is_enterprise IS 'When true, these migrations are invisible to OSS mode.';",
				"DownQuery": "ALTER TABLE out_of_band_migrations DROP COLUMN is_enterprise;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395826
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395828,
				"Name": "split oob version columns",
				"UpQuery": "--\n-- Switch out introduced column\n\nALTER TABLE out_of_band_migrations ADD COLUMN introduced_version_major int;\nALTER TABLE out_of_band_migrations ADD COLUMN introduced_version_minor int;\n\nWITH t(id, parts) AS (\n    SELECT\n        id,\n        regexp_matches(introduced, E'^(\\\\d+)\\.(\\\\d+)')\n    FROM\n        out_of_band_migrations\n)\nUPDATE out_of_band_migrations SET\n    introduced_version_major = parts[1]::int,\n    introduced_version_minor = parts[2]::int\nFROM t WHERE t.id = out_of_band_migrations.id;\n\nALTER TABLE out_of_band_migrations ALTER COLUMN introduced_version_major SET NOT NULL;\nALTER TABLE out_of_band_migrations ALTER COLUMN introduced_version_minor SET NOT NULL;\nALTER TABLE out_of_band_migrations DROP COLUMN introduced;\n\n--\n-- Switch out deprecation column (keep nullable, no data exists yet)\n\nALTER TABLE out_of_band_migrations ADD COLUMN deprecated_version_major int;\nALTER TABLE out_of_band_migrations ADD COLUMN deprecated_version_minor int;\nALTER TABLE out_of_band_migrations DROP COLUMN deprecated;\n\nCOMMENT ON COLUMN out_of_band_migrations.introduced_version_major IS 'The Sourcegraph version (major component) in which this migration was first introduced.';\nCOMMENT ON COLUMN out_of_band_migrations.introduced_version_minor IS 'The Sourcegraph version (minor component) in which this migration was first introduced.';\nCOMMENT ON COLUMN out_of_band_migrations.deprecated_version_major IS 'The lowest Sourcegraph version (major component) that assumes the migration has completed.';\nCOMMENT ON COLUMN out_of_band_migrations.deprecated_version_minor IS 'The lowest Sourcegraph version (minor component) that assumes the migration has completed.';",
				"DownQuery": "ALTER TABLE out_of_band_migrations ADD COLUMN introduced text;\nUPDATE out_of_band_migrations SET introduced = concat(introduced_version_major, '.', introduced_version_minor);\nALTER TABLE out_of_band_migrations ALTER COLUMN introduced SET NOT NULL;\nALTER TABLE out_of_band_migrations DROP COLUMN introduced_version_major;\nALTER TABLE out_of_band_migrations DROP COLUMN introduced_version_minor;\n\nALTER TABLE out_of_band_migrations ADD COLUMN deprecated text;\nUPDATE out_of_band_migrations SET deprecated = concat(deprecated_version_major, '.', deprecated_version_minor) WHERE deprecated_version_major IS NOT NULL;\nALTER TABLE out_of_band_migrations DROP COLUMN deprecated_version_major;\nALTER TABLE out_of_band_migrations DROP COLUMN deprecated_version_minor;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395827
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395829,
				"Name": "first version trigger",
				"UpQuery": "CREATE OR REPLACE FUNCTION versions_insert_row_trigger() RETURNS trigger LANGUAGE plpgsql AS $lang$\nBEGIN\n    NEW.first_version = NEW.version;\n    RETURN NEW;\nEND $lang$;\n\nCREATE TRIGGER versions_insert BEFORE INSERT ON versions FOR EACH ROW EXECUTE PROCEDURE versions_insert_row_trigger();",
				"DownQuery": "DROP TRIGGER versions_insert ON versions;\nDROP FUNCTION versions_insert_row_trigger;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395828
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395830,
				"Name": "index associated index id",
				"UpQuery": "CREATE INDEX lsif_uploads_associated_index_id ON lsif_uploads(associated_index_id);",
				"DownQuery": "DROP INDEX lsif_uploads_associated_index_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395829
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395831,
				"Name": "add stars column to repo",
				"UpQuery": "ALTER TABLE repo ADD COLUMN IF NOT EXISTS stars int;\n\nUPDATE repo SET stars = (metadata-\u003e\u003e'StargazerCount')::int\nWHERE external_service_type = 'github'\nAND stars IS NULL\nAND metadata ? 'StargazerCount';\n\nCREATE INDEX IF NOT EXISTS repo_stars_idx ON repo USING BTREE (stars DESC NULLS LAST);",
				"DownQuery": "DROP INDEX IF EXISTS repo_stars_idx;\n\nALTER TABLE repo DROP COLUMN IF EXISTS stars;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395830
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395832,
				"Name": "create security event logs sql",
				"UpQuery": "CREATE TABLE IF NOT EXISTS security_event_logs (\n    id                BIGSERIAL PRIMARY KEY,\n    name              TEXT      NOT NULL,\n    url               TEXT      NOT NULL,\n    user_id           INTEGER   NOT NULL,\n    anonymous_user_id TEXT      NOT NULL,\n    source            TEXT      NOT NULL,\n    argument          JSONB     NOT NULL,\n    version           TEXT      NOT NULL,\n    \"timestamp\"       TIMESTAMP WITH TIME ZONE NOT NULL,\n\n    CONSTRAINT security_event_logs_check_has_user          CHECK ((((user_id = 0) AND (anonymous_user_id \u003c\u003e ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id = ''::text)) OR ((user_id \u003c\u003e 0) AND (anonymous_user_id \u003c\u003e ''::text)))),\n    CONSTRAINT security_event_logs_check_name_not_empty    CHECK ((name \u003c\u003e ''::text)),\n    CONSTRAINT security_event_logs_check_source_not_empty  CHECK ((source \u003c\u003e ''::text)),\n    CONSTRAINT security_event_logs_check_version_not_empty CHECK ((version \u003c\u003e ''::text))\n);\n\nCREATE INDEX security_event_logs_user_id           ON security_event_logs USING btree (user_id);\nCREATE INDEX security_event_logs_anonymous_user_id ON security_event_logs USING btree (anonymous_user_id);\nCREATE INDEX security_event_logs_name              ON security_event_logs USING btree (name);\nCREATE INDEX security_event_logs_source            ON security_event_logs USING btree (source);\nCREATE INDEX security_event_logs_timestamp         ON security_event_logs USING btree (\"timestamp\");\nCREATE INDEX security_event_logs_timestamp_at_utc  ON security_event_logs USING btree (date(timezone('UTC'::text, \"timestamp\")));\n\nCOMMENT ON TABLE  security_event_logs                   IS 'Contains security-relevant events with a long time horizon for storage.';\nCOMMENT ON COLUMN security_event_logs.name              IS 'The event name as a CAPITALIZED_SNAKE_CASE string.';\nCOMMENT ON COLUMN security_event_logs.url               IS 'The URL within the Sourcegraph app which generated the event.';\nCOMMENT ON COLUMN security_event_logs.user_id           IS 'The ID of the actor associated with the event.';\nCOMMENT ON COLUMN security_event_logs.anonymous_user_id IS 'The UUID of the actor associated with the event.';\nCOMMENT ON COLUMN security_event_logs.source            IS 'The site section (WEB, BACKEND, etc.) that generated the event.';\nCOMMENT ON COLUMN security_event_logs.argument          IS 'An arbitrary JSON blob containing event data.';\nCOMMENT ON COLUMN security_event_logs.version           IS 'The version of Sourcegraph which generated the event.';",
				"DownQuery": "DROP TABLE IF EXISTS security_event_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395831
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395833,
				"Name": "feature flag events",
				"UpQuery": "ALTER TABLE event_logs\nADD COLUMN feature_flags jsonb;",
				"DownQuery": "ALTER TABLE event_logs\nDROP COLUMN feature_flags;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395832
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395834,
				"Name": "add autoindex enable",
				"UpQuery": "ALTER TABLE lsif_index_configuration\n  ADD COLUMN \"autoindex_enabled\" BOOLEAN NOT NULL DEFAULT TRUE;\n\nCOMMENT ON COLUMN lsif_index_configuration.autoindex_enabled IS 'Whether or not auto-indexing should be attempted on this repo. Index jobs may be inferred from the repository contents if data is empty.';",
				"DownQuery": "ALTER TABLE lsif_index_configuration\n  DROP COLUMN IF EXISTS \"autoindex_enabled\";",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395833
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395835,
				"Name": "cohort id",
				"UpQuery": "ALTER TABLE event_logs\nADD COLUMN cohort_id date;",
				"DownQuery": "ALTER TABLE event_logs\nDROP COLUMN cohort_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395834
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395836,
				"Name": "dbworkers worker hostname",
				"UpQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\n\nALTER TABLE changeset_jobs ADD COLUMN worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE cm_action_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE cm_trigger_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE external_service_sync_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE insights_query_runner_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE lsif_dependency_indexing_jobs ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE lsif_indexes ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';\nALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS worker_hostname text NOT NULL DEFAULT '';",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE changesets DROP COLUMN IF EXISTS worker_hostname;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;\n\nALTER TABLE changeset_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE cm_action_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE cm_trigger_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE external_service_sync_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE insights_query_runner_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE lsif_dependency_indexing_jobs DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE lsif_indexes DROP COLUMN IF EXISTS worker_hostname;\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS worker_hostname;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395835
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395837,
				"Name": "mark unmigrated credentials",
				"UpQuery": "-- Previously, we conflated unmigrated user and site credentials with\n-- unencrypted ones. Instead, we should separate these states with a placeholder\n-- so the out of band migration responsible for encrypting credentials reports\n-- its progress correctly.\n\nUPDATE\n    user_credentials\nSET\n    encryption_key_id = 'unmigrated'\nWHERE\n    encryption_key_id = '';\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    encryption_key_id = 'unmigrated'\nWHERE\n    encryption_key_id = '';",
				"DownQuery": "UPDATE\n    user_credentials\nSET\n    encryption_key_id = ''\nWHERE\n    encryption_key_id = 'unmigrated';\n\nUPDATE\n    batch_changes_site_credentials\nSET\n    encryption_key_id = ''\nWHERE\n    encryption_key_id = 'unmigrated';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395836
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395838,
				"Name": "add blocked column to repo table",
				"UpQuery": "ALTER TABLE IF EXISTS repo ADD COLUMN blocked jsonb;\n\nCREATE OR REPLACE FUNCTION repo_block(reason text, at timestamptz) RETURNS jsonb AS\n$$\nSELECT jsonb_build_object(\n    'reason', reason,\n    'at', extract(epoch from timezone('utc', at))::bigint\n);\n$$ LANGUAGE SQL STRICT IMMUTABLE;\n\nCREATE INDEX repo_blocked_idx ON repo USING BTREE ((blocked IS NOT NULL));\nCREATE INDEX repo_is_not_blocked_idx ON repo USING BTREE ((blocked IS NULL));",
				"DownQuery": "DROP INDEX IF EXISTS repo_is_blocked_idx;\nDROP INDEX IF EXISTS repo_is_not_blocked_idx;\n\nDROP FUNCTION IF EXISTS repo_block;\n\nALTER TABLE IF EXISTS repo DROP COLUMN IF EXISTS blocked;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395837
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395839,
				"Name": "ui publish state",
				"UpQuery": "CREATE TYPE\n    batch_changes_changeset_ui_publication_state\nAS ENUM (\n    'UNPUBLISHED',\n    'DRAFT',\n    'PUBLISHED'\n);\n\n-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n    changesets\nADD COLUMN IF NOT EXISTS\n    ui_publication_state batch_changes_changeset_ui_publication_state NULL DEFAULT NULL;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n    changesets\nDROP COLUMN IF EXISTS\n    ui_publication_state;\n\nDROP TYPE IF EXISTS\n    batch_changes_changeset_ui_publication_state;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395838
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395840,
				"Name": "create sg service role",
				"UpQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"DownQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395839
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395841,
				"Name": "add repo table policy",
				"UpQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"DownQuery": "-- We encountered performance issues for our use cases when we deployed\n-- RLS to production. We made the decision to back that approach out and\n-- solve the security concerns in application-level code instead.\n--\n-- ref migrations/frontend/1528395860_remove_repo_table_policy.up.sql\n-- ref migrations/frontend/1528395861_remove_sg_service_grants.up.sql\n-- ref migrations/frontend/1528395862_remove_sg_service_role.up.sql",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395840
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395842,
				"Name": "add settings user id index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS settings_user_id_idx ON settings USING BTREE (user_id);",
				"DownQuery": "DROP INDEX IF EXISTS settings_user_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395841
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395843,
				"Name": "batch spec executions table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_executions (\n  id              BIGSERIAL PRIMARY KEY,\n  state           TEXT DEFAULT 'queued',\n  failure_message TEXT,\n  started_at      TIMESTAMP WITH TIME ZONE,\n  finished_at     TIMESTAMP WITH TIME ZONE,\n  process_after   TIMESTAMP WITH TIME ZONE,\n  num_resets      INTEGER NOT NULL DEFAULT 0,\n  num_failures    INTEGER NOT NULL DEFAULT 0,\n  execution_logs  JSON[],\n  worker_hostname TEXT NOT NULL DEFAULT '',\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n  batch_spec TEXT NOT NULL,\n  batch_spec_id integer REFERENCES batch_specs(id)\n);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_executions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395842
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395844,
				"Name": "add user id to bach spec executions",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS user_id int REFERENCES users(id) DEFERRABLE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395843
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395845,
				"Name": "batch spec execution namespace",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS namespace_user_id integer REFERENCES users(id) DEFERRABLE;\nALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS namespace_org_id integer REFERENCES orgs(id) DEFERRABLE;\nUPDATE batch_spec_executions SET namespace_user_id = user_id;\nALTER TABLE IF EXISTS batch_spec_executions ADD CONSTRAINT batch_spec_executions_has_1_namespace CHECK ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL));",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions DROP CONSTRAINT batch_spec_executions_has_1_namespace;\nALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS namespace_user_id;\nALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS namespace_org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395844
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395846,
				"Name": "expand visible lsif uploads",
				"UpQuery": "ALTER TABLE lsif_uploads_visible_at_tip ADD COLUMN branch_or_tag_name text NOT NULL DEFAULT '';\nALTER TABLE lsif_uploads_visible_at_tip ADD COLUMN is_default_branch boolean NOT NULL DEFAULT false;\n\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.upload_id IS 'The identifier of the upload visible from the tip of the specified branch or tag.';\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.branch_or_tag_name IS 'The name of the branch or tag.';\nCOMMENT ON COLUMN lsif_uploads_visible_at_tip.is_default_branch IS  'Whether the specified branch is the default of the repository. Always false for tags.';\n\n-- Update all existing visible uploads to be the default branch, which is true until\n-- we start recalcaulting the commit graph with tags and non-default branches.\nUPDATE lsif_uploads_visible_at_tip SET is_default_branch = true;\n\n-- Mark every graph as dirty so we recalculate retention correctly once the instance\n-- boots up.\nUPDATE lsif_dirty_repositories SET dirty_token = dirty_token + 1;",
				"DownQuery": "ALTER TABLE lsif_uploads_visible_at_tip DROP COLUMN branch_or_tag_name;\nALTER TABLE lsif_uploads_visible_at_tip DROP COLUMN is_default_branch;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395845
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395847,
				"Name": "codeintel eviction ages",
				"UpQuery": "CREATE TABLE lsif_retention_configuration (\n    id serial PRIMARY KEY,\n    repository_id integer UNIQUE NOT NULL REFERENCES repo(id) ON DELETE CASCADE,\n    max_age_for_non_stale_branches_seconds integer NOT NULL,\n    max_age_for_non_stale_tags_seconds integer NOT NULL\n);\n\nCOMMENT ON TABLE lsif_retention_configuration IS 'Stores the retention policy of code intellience data for a repository.';\nCOMMENT ON COLUMN lsif_retention_configuration.max_age_for_non_stale_branches_seconds IS 'The number of seconds since the last modification of a branch until it is considered stale.';\nCOMMENT ON COLUMN lsif_retention_configuration.max_age_for_non_stale_tags_seconds IS 'The nujmber of seconds since the commit date of a tagged commit until it is considered stale.';",
				"DownQuery": "DROP TABLE lsif_retention_configuration;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395846
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395848,
				"Name": "drop default repos",
				"UpQuery": "DROP TABLE IF EXISTS default_repos;",
				"DownQuery": "CREATE TABLE default_repos (\n    repo_id integer NOT NULL\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395847
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395849,
				"Name": "drop unused indexes",
				"UpQuery": "-- Covered by external_service_repos_idx (external_service_id, repo_id)\nDROP INDEX IF EXISTS external_service_repos_external_service_id;",
				"DownQuery": "CREATE INDEX external_service_repos_external_service_id ON external_service_repos USING btree (external_service_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395848
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395850,
				"Name": "add rand id to batch spec executions",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS rand_id text NOT NULL;\n\nCREATE INDEX batch_spec_executions_rand_id ON batch_spec_executions USING btree (rand_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_executions_rand_id;\n\nALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS rand_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395849
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395851,
				"Name": "workerutil last updated at",
				"UpQuery": "ALTER TABLE batch_spec_executions ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE changeset_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE changesets ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE cm_action_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE cm_trigger_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE external_service_sync_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE insights_query_runner_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE lsif_dependency_indexing_jobs ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE lsif_indexes ADD COLUMN last_heartbeat_at timestamp with time zone;\nALTER TABLE lsif_uploads ADD COLUMN last_heartbeat_at timestamp with time zone;",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE batch_spec_executions DROP COLUMN last_heartbeat_at;\nALTER TABLE changeset_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE changesets DROP COLUMN last_heartbeat_at;\nALTER TABLE cm_action_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE cm_trigger_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE external_service_sync_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE insights_query_runner_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE lsif_dependency_indexing_jobs DROP COLUMN last_heartbeat_at;\nALTER TABLE lsif_indexes DROP COLUMN last_heartbeat_at;\nALTER TABLE lsif_uploads DROP COLUMN last_heartbeat_at;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395850
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395852,
				"Name": "lsif add covering index",
				"UpQuery": "CREATE INDEX lsif_packages_scheme_name_version_dump_id ON lsif_packages(scheme, name, version, dump_id);\nDROP INDEX lsif_packages_scheme_name_version;\n\nCREATE INDEX lsif_references_scheme_name_version_dump_id ON lsif_references(scheme, name, version, dump_id);\nDROP INDEX lsif_references_package;",
				"DownQuery": "CREATE INDEX lsif_packages_scheme_name_version ON lsif_packages(scheme, name, version);\nDROP INDEX lsif_packages_scheme_name_version_dump_id;\n\nCREATE INDEX lsif_references_package ON lsif_references(scheme, name, version);\nDROP INDEX lsif_references_scheme_name_version_dump_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395851
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395853,
				"Name": "add deleting state",
				"UpQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\n\nCREATE VIEW lsif_dumps AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting';\n\nCREATE VIEW lsif_dumps_with_repository_name AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\n\nCREATE VIEW lsif_dumps AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.finished_at AS processed_at\nFROM lsif_uploads u WHERE u.state = 'completed'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS SELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u JOIN repo r ON r.id = u.repository_id WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395852
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395854,
				"Name": "add priority insights queryrunner",
				"UpQuery": "ALTER TABLE insights_query_runner_jobs\n    ADD COLUMN priority INT NOT NULL DEFAULT 1;\n\nALTER TABLE insights_query_runner_jobs\n    ADD COLUMN cost INT NOT NULL DEFAULT 500;\n\nCOMMENT ON COLUMN insights_query_runner_jobs.priority IS 'Integer representing a category of priority for this query. Priority in this context is ambiguously defined for consumers to decide an interpretation.';\nCOMMENT ON COLUMN insights_query_runner_jobs.cost IS 'Integer representing a cost approximation of executing this search query.';\n\nCREATE INDEX insights_query_runner_jobs_priority_idx on insights_query_runner_jobs(priority);\nCREATE INDEX insights_query_runner_jobs_cost_idx on insights_query_runner_jobs(cost);",
				"DownQuery": "ALTER TABLE insights_query_runner_jobs\n    DROP COLUMN priority;\n\nALTER TABLE insights_query_runner_jobs\n    DROP COLUMN cost;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395853
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395855,
				"Name": "add-missing-execution-logs-cols",
				"UpQuery": "ALTER TABLE IF EXISTS cm_trigger_jobs ADD COLUMN IF NOT EXISTS execution_logs JSON[];\nALTER TABLE IF EXISTS cm_action_jobs  ADD COLUMN IF NOT EXISTS execution_logs JSON[];",
				"DownQuery": "ALTER TABLE IF EXISTS cm_trigger_jobs DROP COLUMN IF EXISTS execution_logs;\nALTER TABLE IF EXISTS cm_action_jobs  DROP COLUMN IF EXISTS execution_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395854
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395856,
				"Name": "add missing execution logs cols for real",
				"UpQuery": "ALTER TABLE IF EXISTS lsif_uploads ADD COLUMN IF NOT EXISTS execution_logs JSON[];",
				"DownQuery": "ALTER TABLE IF EXISTS lsif_uploads DROP COLUMN IF EXISTS execution_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395855
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395857,
				"Name": "last fetched",
				"UpQuery": "ALTER TABLE gitserver_repos ADD COLUMN last_fetched TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now();",
				"DownQuery": "ALTER TABLE gitserver_repos DROP COLUMN last_fetched;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395856
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395858,
				"Name": "drop lsif indexable repositories",
				"UpQuery": "DROP TABLE IF EXISTS lsif_indexable_repositories;",
				"DownQuery": "CREATE TABLE lsif_indexable_repositories (\n    id SERIAL PRIMARY KEY NOT NULL,\n    repository_id integer NOT NULL,\n    search_count integer DEFAULT 0 NOT NULL,\n    precise_count integer DEFAULT 0 NOT NULL,\n    last_index_enqueued_at timestamp with time zone,\n    last_updated_at timestamp with time zone DEFAULT now() NOT NULL,\n    enabled boolean\n);\n\nCREATE UNIQUE INDEX lsif_indexable_repositories_repository_id_key ON lsif_indexable_repositories (repository_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395857
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395859,
				"Name": "make batch spec executions batch spec id deferrable",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ALTER CONSTRAINT batch_spec_executions_batch_spec_id_fkey DEFERRABLE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions ALTER CONSTRAINT batch_spec_executions_batch_spec_id_fkey NOT DEFERRABLE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395858
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395860,
				"Name": "remove repo table policy",
				"UpQuery": "-- This removes the row-level security policy (if present), and disables RLS on\n-- the repo table. Both operations are idempotent.\nDROP POLICY IF EXISTS sg_repo_access_policy ON repo;\nALTER TABLE repo DISABLE ROW LEVEL SECURITY;",
				"DownQuery": "-- We do not recreate the policy, as we've shifted our strategy away from row-\n-- level security to application-level code. Prior migrations that created the\n-- policy have also been removed.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395859
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395861,
				"Name": "remove sg service grants",
				"UpQuery": "DO $$\nBEGIN\n    REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public FROM sg_service;\n    REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA public FROM sg_service;\n    REVOKE USAGE ON SCHEMA public FROM sg_service;\nEXCEPTION WHEN undefined_object THEN\n    -- Roles are visible across databases within a server, and we use templated\n    -- databases for test parallelism, so it's possible in some cases for the\n    -- tests to hit a case where the role can't be dropped because one of the\n    -- test databases still has objects that depend on it.\nEND;\n$$;",
				"DownQuery": "-- We do not recreate the grants, as we've shifted our strategy away from row-\n-- level security to application-level code. Prior migrations that created the\n-- grants have also been removed.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395860
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395862,
				"Name": "remove sg service role",
				"UpQuery": "DO $$\nBEGIN\n    DROP ROLE IF EXISTS sg_service;\nEXCEPTION WHEN dependent_objects_still_exist THEN\n    -- Roles are visible across databases within a server, and we use templated\n    -- databases for test parallelism, so it's possible in some cases for the\n    -- tests to hit a case where the role can't be dropped because one of the\n    -- test databases still has objects that depend on it.\nEND;\n$$;",
				"DownQuery": "-- We do not recreate the role, as we've shifted our strategy away from row-\n-- level security to application-level code. Prior migrations that created the\n-- role have also been removed.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395861
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395863,
				"Name": "event logs public properties column",
				"UpQuery": "ALTER TABLE IF EXISTS event_logs ADD COLUMN IF NOT EXISTS public_argument JSONB DEFAULT '{}'::jsonb NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS event_logs DROP COLUMN IF EXISTS public_argument;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395862
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395864,
				"Name": "create temporary settings",
				"UpQuery": "CREATE TABLE IF NOT EXISTS temporary_settings (\n    id serial NOT NULL PRIMARY KEY,\n    user_id integer NOT NULL UNIQUE,\n    contents jsonb,\n    created_at timestamp with time zone DEFAULT now() NOT NULL,\n    updated_at timestamp with time zone DEFAULT now() NOT NULL,\n\n    FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n);\n\nCOMMENT ON TABLE temporary_settings IS 'Stores per-user temporary settings used in the UI, for example, which modals have been dimissed or what theme is preferred.';\nCOMMENT ON COLUMN temporary_settings.user_id IS 'The ID of the user the settings will be saved for.';\nCOMMENT ON COLUMN temporary_settings.contents IS 'JSON-encoded temporary settings.';",
				"DownQuery": "DROP TABLE IF EXISTS temporary_settings;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395863
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395865,
				"Name": "insights job dependencies",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TABLE insights_query_runner_jobs_dependencies\n(\n    id             SERIAL    NOT NULL,\n    job_id         INT       NOT NULL,\n    recording_time TIMESTAMP NOT NULL,\n    PRIMARY KEY (id),\n    --  The delete cascade is intentional, these records only have meaning in context of the related job row.\n    CONSTRAINT insights_query_runner_jobs_dependencies_fk_job_id FOREIGN KEY (job_id) REFERENCES insights_query_runner_jobs (id) ON DELETE CASCADE\n);\n\nCOMMENT ON TABLE insights_query_runner_jobs_dependencies IS 'Stores data points for a code insight that do not need to be queried directly, but depend on the result of a query at a different point';\n\nCOMMENT ON COLUMN insights_query_runner_jobs_dependencies.job_id IS 'Foreign key to the job that owns this record.';\nCOMMENT ON COLUMN insights_query_runner_jobs_dependencies.recording_time IS 'The time for which this dependency should be recorded at using the parents value.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP TABLE IF EXISTS insights_query_runner_jobs_dependencies;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395864
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395866,
				"Name": "insights queue reset",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\n-- This table is a queue of records that need processing for code insights. Historically this queue grows\n-- unbounded because the historical backfiller operated without state - every time it executed it would\n-- requeue all of the work again. Since then we have added enough state to the backfiller to remove this problem,\n-- but customer instances are going to be full of millions of records that will need processing before we can start\n-- fresh. To avoid this problem, we are going to ship a 'reset' in 3.31 that will clear this queue entirely.\n-- Note: This data is by design ephemeral, so there is no risk of permanent data loss here.\n\nTRUNCATE insights_query_runner_jobs CASCADE;",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395865
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395867,
				"Name": "batch-spec-executions-cancel",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_executions ADD COLUMN IF NOT EXISTS cancel BOOL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_executions DROP COLUMN IF EXISTS cancel;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395866
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395868,
				"Name": "insights queue dependencies index",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE INDEX insights_query_runner_jobs_dependencies_job_id_fk_idx ON insights_query_runner_jobs_dependencies(job_id);",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nDROP INDEX IF EXISTS insights_query_runner_jobs_dependencies_job_id_fk_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395867
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395869,
				"Name": "add lsif configuration policy",
				"UpQuery": "CREATE TABLE lsif_configuration_policies (\n    id SERIAL PRIMARY KEY,\n    repository_id int,\n    name text,\n    type text NOT NULL,\n    pattern text NOT NULL,\n    retention_enabled boolean NOT NULL,\n    retention_duration_hours int,\n    retain_intermediate_commits boolean NOT NULL,\n    indexing_enabled boolean NOT NULL,\n    index_commit_max_age_hours int,\n    index_intermediate_commits boolean NOT NULL\n);\n\nCREATE INDEX lsif_configuration_policies_repository_id ON lsif_configuration_policies(repository_id);\n\nCOMMENT ON COLUMN lsif_configuration_policies.repository_id IS 'The identifier of the repository to which this configuration policy applies. If absent, this policy is applied globally.';\nCOMMENT ON COLUMN lsif_configuration_policies.type IS 'The type of Git object (e.g., COMMIT, BRANCH, TAG).';\nCOMMENT ON COLUMN lsif_configuration_policies.pattern IS 'A pattern used to match` names of the associated Git object type.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_enabled IS 'Whether or not this configuration policy affects data retention rules.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_duration_hours IS 'The max age of data retained by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.retain_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also retain all data used to resolve queries for any commit on the matching branches. Setting this value to false will only consider the tip of the branch.';\nCOMMENT ON COLUMN lsif_configuration_policies.indexing_enabled IS 'Whether or not this configuration policy affects auto-indexing schedules.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_commit_max_age_hours IS 'The max age of commits indexed by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also index all commits on the matching branches. Setting this value to false will only consider the tip of the branch.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_configuration_policies;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395868
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395870,
				"Name": "codeintel dependency repos",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_dependency_repos (\n    id bigserial NOT NULL PRIMARY KEY,\n    name text NOT NULL,\n    version text NOT NULL,\n    scheme text NOT NULL,\n    CONSTRAINT lsif_dependency_repos_unique_triplet\n        UNIQUE (scheme, name, version)\n);",
				"DownQuery": "DROP TABLE IF EXISTS lsif_dependency_repos;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395869
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395871,
				"Name": "insights queue state index",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\nCREATE INDEX IF NOT EXISTS insights_query_runner_jobs_processable_priority_id ON insights_query_runner_jobs (priority, id) WHERE state = 'queued' OR state = 'errored';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\ndrop index if exists insights_query_runner_jobs_processable_priority_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395870
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395872,
				"Name": "lsif upload reference counts",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN num_references int;\nCOMMENT ON COLUMN lsif_uploads.num_references IS 'The number of references to this upload data from other upload records (via lsif_references).';",
				"DownQuery": "ALTER TABLE lsif_uploads DROP COLUMN num_references;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395871
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395873,
				"Name": "lsif upload reference counts oob migration",
				"UpQuery": "INSERT INTO out_of_band_migrations (id, team, component, description, introduced_version_major, introduced_version_minor, non_destructive)\nVALUES (11, 'code-intelligence', 'lsif_uploads.num_references', 'Backfill LSIF upload reference counts', 3, 22, true)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- Do not remove oob migration when downgrading",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395872
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395874,
				"Name": "lsif nearest uploads indexes",
				"UpQuery": "-- Allow for lookup from upload id to commits that the upload can resolve queries for.\nCREATE INDEX lsif_nearest_uploads_uploads ON lsif_nearest_uploads USING GIN(uploads);\n\n-- Allow for lookup from commit to the set of commits that have analogous nearest uploads.\nCREATE INDEX lsif_nearest_uploads_links_repository_id_ancestor_commit_bytea ON lsif_nearest_uploads_links(repository_id, ancestor_commit_bytea);",
				"DownQuery": "DROP INDEX lsif_nearest_uploads_uploads;\nDROP INDEX lsif_nearest_uploads_links_repository_id_ancestor_commit_bytea;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395873
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395875,
				"Name": "lsif upload expired flag",
				"UpQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Add new column\nALTER TABLE lsif_uploads ADD COLUMN expired boolean not null default false;\nCOMMENT ON COLUMN lsif_uploads.expired IS 'Whether or not this upload data is no longer protected by any data retention policy.';\n\n-- Update view definitions to include new fields\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Drop new column\nALTER TABLE lsif_uploads DROP COLUMN expired;\n\n-- Restore old views\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395874
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395876,
				"Name": "lsif last retention scan",
				"UpQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Create table to rate limit data retention scans of a repository\nCREATE TABLE lsif_last_retention_scan (\n    repository_id int NOT NULL,\n    last_retention_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY(repository_id)\n);\nCOMMENT ON TABLE lsif_last_retention_scan IS 'Tracks the last time uploads a repository were checked against data retention policies.';\nCOMMENT ON COLUMN lsif_last_retention_scan.last_retention_scan_at IS 'The last time uploads of this repository were checked against data retention policies.';\n\n-- Add column to rate limit scanning of individual upload records\nALTER TABLE lsif_uploads ADD COLUMN last_retention_scan_at timestamp with time zone;\nCOMMENT ON COLUMN lsif_uploads.last_retention_scan_at IS 'The last time this upload was checked against data retention policies.';\n\n-- Update view definitions to include new fields\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "-- Drop dependent views\nDROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\n-- Drop new column and table\nALTER TABLE lsif_uploads DROP COLUMN last_retention_scan_at;\nDROP TABLE lsif_last_retention_scan;\n\n-- Restore old views\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395875
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395877,
				"Name": "index-lsif-uploads-repo",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_uploads_repository_id ON lsif_uploads (repository_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_uploads_repository_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395876
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_uploads",
					"IndexName": "lsif_uploads_repository_id"
				}
			},
			{
				"ID": 1528395878,
				"Name": "index-lsif-indexes-repo",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_indexes_repository_id_commit ON lsif_indexes (repository_id, commit);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_indexes_repository_id_commit;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395877
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_indexes",
					"IndexName": "lsif_indexes_repository_id_commit"
				}
			},
			{
				"ID": 1528395879,
				"Name": "repair lsif configuration policies",
				"UpQuery": "DROP TABLE lsif_configuration_policies;\n\nCREATE TABLE lsif_configuration_policies (\n    id SERIAL PRIMARY KEY,\n    repository_id int,\n    name text,\n    type text NOT NULL,\n    pattern text NOT NULL,\n    retention_enabled boolean NOT NULL,\n    retention_duration_hours int,\n    retain_intermediate_commits boolean NOT NULL,\n    indexing_enabled boolean NOT NULL,\n    index_commit_max_age_hours int,\n    index_intermediate_commits boolean NOT NULL\n);\n\nCREATE INDEX lsif_configuration_policies_repository_id ON lsif_configuration_policies(repository_id);\n\nCOMMENT ON COLUMN lsif_configuration_policies.repository_id IS 'The identifier of the repository to which this configuration policy applies. If absent, this policy is applied globally.';\nCOMMENT ON COLUMN lsif_configuration_policies.type IS 'The type of Git object (e.g., COMMIT, BRANCH, TAG).';\nCOMMENT ON COLUMN lsif_configuration_policies.pattern IS 'A pattern used to match` names of the associated Git object type.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_enabled IS 'Whether or not this configuration policy affects data retention rules.';\nCOMMENT ON COLUMN lsif_configuration_policies.retention_duration_hours IS 'The max age of data retained by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.retain_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also retain all data used to resolve queries for any commit on the matching branches. Setting this value to false will only consider the tip of the branch.';\nCOMMENT ON COLUMN lsif_configuration_policies.indexing_enabled IS 'Whether or not this configuration policy affects auto-indexing schedules.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_commit_max_age_hours IS 'The max age of commits indexed by this configuration policy. If null, the age is unbounded.';\nCOMMENT ON COLUMN lsif_configuration_policies.index_intermediate_commits IS 'If the matching Git object is a branch, setting this value to true will also index all commits on the matching branches. Setting this value to false will only consider the tip of the branch.';",
				"DownQuery": "-- Nothing on down",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395878
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395880,
				"Name": "insights queue persist mode",
				"UpQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nCREATE TYPE PersistMode AS ENUM ('record', 'snapshot');\n\nALTER TABLE insights_query_runner_jobs\n    ADD persist_mode PersistMode DEFAULT 'record' NOT NULL;\n\nCOMMENT ON COLUMN insights_query_runner_jobs.persist_mode IS 'The persistence level for this query. This value will determine the lifecycle of the resulting value.';",
				"DownQuery": "-- Insert migration here. See README.md. Highlights:\n--  * Always use IF EXISTS. eg: DROP TABLE IF EXISTS global_dep_private;\n--  * All migrations must be backward-compatible. Old versions of Sourcegraph\n--    need to be able to read/write post migration.\n--  * Historically we advised against transactions since we thought the\n--    migrate library handled it. However, it does not! /facepalm\n\nALTER TABLE insights_query_runner_jobs\n    DROP COLUMN persist_mode;\n\nDROP TYPE PersistMode;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395879
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395881,
				"Name": "add batch spec workspaces",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_resolution_jobs (\n  id              BIGSERIAL PRIMARY KEY,\n\n  batch_spec_id     INTEGER REFERENCES batch_specs(id) ON DELETE CASCADE DEFERRABLE,\n  allow_unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  allow_ignored     BOOLEAN NOT NULL DEFAULT FALSE,\n\n  state             TEXT DEFAULT 'queued',\n  failure_message   TEXT,\n  started_at        TIMESTAMP WITH TIME ZONE,\n  finished_at       TIMESTAMP WITH TIME ZONE,\n  process_after     TIMESTAMP WITH TIME ZONE,\n  num_resets        INTEGER NOT NULL DEFAULT 0,\n  num_failures      INTEGER NOT NULL DEFAULT 0,\n  execution_logs    JSON[],\n  worker_hostname   TEXT NOT NULL DEFAULT '',\n  last_heartbeat_at TIMESTAMP WITH TIME ZONE,\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS batch_spec_workspaces (\n  id              BIGSERIAL PRIMARY KEY,\n\n  batch_spec_id      INTEGER REFERENCES batch_specs(id) ON DELETE CASCADE DEFERRABLE,\n  changeset_spec_ids JSONB DEFAULT '{}'::jsonb,\n\n  repo_id integer      REFERENCES repo(id) DEFERRABLE,\n  branch               TEXT NOT NULL,\n  commit               TEXT NOT NULL,\n  path                 TEXT NOT NULL,\n  file_matches         TEXT[] NOT NULL,\n  only_fetch_workspace BOOLEAN NOT NULL DEFAULT FALSE,\n  steps                JSONB DEFAULT '[]'::jsonb CHECK (jsonb_typeof(steps) = 'array'),\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS batch_spec_workspace_execution_jobs (\n  id              BIGSERIAL PRIMARY KEY,\n\n  batch_spec_workspace_id  INTEGER REFERENCES batch_spec_workspaces(id) ON DELETE CASCADE DEFERRABLE,\n\n  state             TEXT DEFAULT 'queued',\n  failure_message   TEXT,\n  started_at        TIMESTAMP WITH TIME ZONE,\n  finished_at       TIMESTAMP WITH TIME ZONE,\n  process_after     TIMESTAMP WITH TIME ZONE,\n  num_resets        INTEGER NOT NULL DEFAULT 0,\n  num_failures      INTEGER NOT NULL DEFAULT 0,\n  execution_logs    JSON[],\n  worker_hostname   TEXT NOT NULL DEFAULT '',\n  last_heartbeat_at TIMESTAMP WITH TIME ZONE,\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_workspace_execution_jobs;\nDROP TABLE IF EXISTS batch_spec_workspaces;\nDROP TABLE IF EXISTS batch_spec_resolution_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395880
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395882,
				"Name": "lsif configuration protected policies",
				"UpQuery": "ALTER TABLE lsif_configuration_policies ADD COLUMN protected boolean DEFAULT false;\nUPDATE lsif_configuration_policies SET protected = false;\nALTER TABLE lsif_configuration_policies ALTER COLUMN protected SET NOT NULL;\n\nCOMMENT ON COLUMN lsif_configuration_policies.protected IS 'Whether or not this configuration policy is protected from modification of its data retention behavior (except for duration).';",
				"DownQuery": "ALTER TABLE lsif_configuration_policies DROP COLUMN protected;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395881
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395883,
				"Name": "default lsif configuration policies",
				"UpQuery": "INSERT INTO lsif_configuration_policies\n    (\n        name,\n        protected, pattern, type,\n        retention_enabled, retain_intermediate_commits, retention_duration_hours,\n        indexing_enabled, index_intermediate_commits, index_commit_max_age_hours\n    )\nVALUES\n    (\n        'Default tip-of-branch retention policy',\n        true, '*', 'GIT_TREE',\n        true, false, 2016, -- 3 months ~= 2016 hours = 1 week (168 hours) * 4 * 3\n        false, false, 0\n    ), (\n        'Default tag retention policy',\n        true, '*', 'GIT_TAG',\n        true, false, 8064, -- 12 months ~= 8064 hours = 1 week (168 hours) * 4 * 12\n        false, false, 0\n    );",
				"DownQuery": "-- Nothing on down",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395882
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395884,
				"Name": "add cancel to batch spec workspace execution jobs",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  ADD COLUMN IF NOT EXISTS cancel boolean DEFAULT false NOT NULL;\n\nCREATE INDEX IF NOT EXISTS batch_spec_workspace_execution_jobs_cancel\n  ON batch_spec_workspace_execution_jobs (cancel);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_cancel;\n\nALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  DROP COLUMN IF EXISTS cancel;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395883
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395885,
				"Name": "lsif last retention scan views",
				"UpQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.last_retention_scan_at,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.last_retention_scan_at,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.last_retention_scan_at,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW lsif_dumps_with_repository_name;\nDROP VIEW lsif_dumps;\nDROP VIEW lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        r.name AS repository_name\n    FROM lsif_uploads u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.finished_at AS processed_at\n    FROM lsif_uploads u\n    WHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\n    SELECT u.id,\n        u.commit,\n        u.root,\n        u.uploaded_at,\n        u.state,\n        u.failure_message,\n        u.started_at,\n        u.finished_at,\n        u.repository_id,\n        u.indexer,\n        u.num_parts,\n        u.uploaded_parts,\n        u.process_after,\n        u.num_resets,\n        u.upload_size,\n        u.num_failures,\n        u.associated_index_id,\n        u.expired,\n        u.processed_at,\n        r.name AS repository_name\n    FROM lsif_dumps u\n    JOIN repo r ON r.id = u.repository_id\n    WHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395884
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395886,
				"Name": "add missing fk indexes1",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_dependency_indexing_jobs_upload_id ON lsif_dependency_indexing_jobs(upload_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_dependency_indexing_jobs_upload_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395885
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_dependency_indexing_jobs",
					"IndexName": "lsif_dependency_indexing_jobs_upload_id"
				}
			},
			{
				"ID": 1528395887,
				"Name": "add missing fk indexes2",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_packages_dump_id ON lsif_packages(dump_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_packages_dump_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395886
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_packages",
					"IndexName": "lsif_packages_dump_id"
				}
			},
			{
				"ID": 1528395888,
				"Name": "add missing fk indexes3",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_references_dump_id ON lsif_references(dump_id);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_references_dump_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395887
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_references",
					"IndexName": "lsif_references_dump_id"
				}
			},
			{
				"ID": 1528395889,
				"Name": "add metadata column to oobmigration",
				"UpQuery": "ALTER TABLE\n    out_of_band_migrations\nADD COLUMN IF NOT EXISTS\n    metadata jsonb NOT NULL DEFAULT '{}'::jsonb;",
				"DownQuery": "ALTER TABLE\n    out_of_band_migrations\nDROP COLUMN IF EXISTS metadata;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395888
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395890,
				"Name": "drop repo cloned",
				"UpQuery": "ALTER TABLE\n    repo\nDROP COLUMN IF EXISTS cloned;",
				"DownQuery": "-- This migration is destructive since the column has been\n-- deprecated since 3.26\nALTER TABLE\n    repo\nADD COLUMN IF NOT EXISTS\n    cloned bool NOT NULL DEFAULT false;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395889
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395891,
				"Name": "lsif dependency indexing queueing",
				"UpQuery": "ALTER TABLE lsif_dependency_indexing_jobs\nRENAME TO lsif_dependency_syncing_jobs;\n\nCREATE TABLE IF NOT EXISTS lsif_dependency_indexing_jobs (\n    id serial PRIMARY KEY,\n    state text DEFAULT 'queued' NOT NULL,\n    failure_message text,\n    queued_at timestamp with time zone DEFAULT NOW() NOT NULL,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    last_heartbeat_at timestamp with time zone,\n    worker_hostname text NOT NULL DEFAULT '',\n    upload_id integer REFERENCES lsif_uploads(id) ON DELETE CASCADE,\n    external_service_kind text NOT NULL DEFAULT '',\n    external_service_sync timestamp with time zone\n);\n\nCOMMENT ON COLUMN lsif_dependency_indexing_jobs.external_service_kind IS 'Filter the external services for this kind to wait to have synced. If empty, external_service_sync is ignored and no external services are polled for their last sync time.';\nCOMMENT ON COLUMN lsif_dependency_indexing_jobs.external_service_sync IS 'The sync time after which external services of the given kind will have synced/created any repositories referenced by the LSIF upload that are resolvable.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_dependency_indexing_jobs;\n\nALTER TABLE lsif_dependency_syncing_jobs\nRENAME TO lsif_dependency_indexing_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395890
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395892,
				"Name": "drop batch spec executions",
				"UpQuery": "DROP TABLE IF EXISTS batch_spec_executions;",
				"DownQuery": "CREATE TABLE IF NOT EXISTS batch_spec_executions (\n  id              BIGSERIAL PRIMARY KEY,\n  rand_id         TEXT NOT NULL,\n\n  state           TEXT DEFAULT 'queued',\n  failure_message TEXT,\n  process_after   TIMESTAMP WITH TIME ZONE,\n  started_at      TIMESTAMP WITH TIME ZONE,\n  finished_at     TIMESTAMP WITH TIME ZONE,\n  last_heartbeat_at TIMESTAMP WITH TIME ZONE,\n  num_resets      INTEGER NOT NULL DEFAULT 0,\n  num_failures    INTEGER NOT NULL DEFAULT 0,\n  execution_logs  JSON[],\n  worker_hostname TEXT NOT NULL DEFAULT '',\n  cancel          BOOL DEFAULT FALSE,\n\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n  batch_spec TEXT NOT NULL,\n  batch_spec_id integer REFERENCES batch_specs(id) DEFERRABLE,\n\n  user_id INTEGER REFERENCES users(id),\n  namespace_org_id INTEGER REFERENCES orgs(id),\n  namespace_user_id INTEGER REFERENCES users(id)\n);\n\nALTER TABLE IF EXISTS batch_spec_executions ADD CONSTRAINT batch_spec_executions_has_1_namespace CHECK ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL));\nCREATE INDEX IF NOT EXISTS batch_spec_executions_rand_id ON batch_spec_executions USING btree (rand_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395891
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395893,
				"Name": "fix repo index part one",
				"UpQuery": "-- We have a hand-created but non-codified index in our Cloud environment\n-- called repo_deleted_at_idx which is a partial btree index over deleted_at\n-- where deleted_at is null. This effectively creates a btree index whose only\n-- value is NULL.\n--\n-- Instead, we'll make a partial index on useful fields that can at least help\n-- cover queries that select only/filter by id and/or name.\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS repo_non_deleted_id_name_idx ON repo(id, name) WHERE deleted_at IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS repo_non_deleted_id_name_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395892
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_non_deleted_id_name_idx"
				}
			},
			{
				"ID": 1528395894,
				"Name": "gitserver repo shard id index",
				"UpQuery": "-- This speeds up IterateRepoGitserverStatus\nCREATE INDEX CONCURRENTLY IF NOT EXISTS gitserver_repos_shard_id ON gitserver_repos(shard_id, repo_id);",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_shard_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395893
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_repos",
					"IndexName": "gitserver_repos_shard_id"
				}
			},
			{
				"ID": 1528395895,
				"Name": "gitserver repos lasterror idx",
				"UpQuery": "DROP INDEX IF EXISTS gitserver_repos_last_error_idx;",
				"DownQuery": "CREATE INDEX gitserver_repos_last_error_idx ON gitserver_repos(last_error) WHERE last_error IS NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395894
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395896,
				"Name": "gitserver repos new lasterror idx",
				"UpQuery": "CREATE INDEX CONCURRENTLY gitserver_repos_last_error_idx ON gitserver_repos(repo_id) WHERE last_error IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS gitserver_repos_last_error_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395895
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "gitserver_repos",
					"IndexName": "gitserver_repos_last_error_idx"
				}
			},
			{
				"ID": 1528395897,
				"Name": "extensions list missing index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS registry_extension_releases_registry_extension_id_created_at ON registry_extension_releases(registry_extension_id, created_at) WHERE deleted_at IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS registry_extension_releases_registry_extension_id_created_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395896
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "registry_extension_releases",
					"IndexName": "registry_extension_releases_registry_extension_id_created_at"
				}
			},
			{
				"ID": 1528395898,
				"Name": "codehost connection owned by org",
				"UpQuery": "-- Adds support for organization owning a codehost connection\nBEGIN;\n\nALTER TABLE IF EXISTS external_services ADD COLUMN IF NOT EXISTS namespace_org_id integer REFERENCES orgs(id) ON DELETE CASCADE DEFERRABLE;\nALTER TABLE IF EXISTS external_services ADD CONSTRAINT external_services_max_1_namespace CHECK ((namespace_user_id IS NULL AND namespace_org_id IS NULL) OR ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL)));\nCREATE INDEX external_services_namespace_org_id_idx ON external_services USING btree (namespace_org_id);\n\nEND;",
				"DownQuery": "ALTER TABLE IF EXISTS external_services DROP COLUMN IF EXISTS namespace_org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395897
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395899,
				"Name": "add index for lsif indexes state",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_indexes_state ON lsif_indexes(state);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_indexes_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395898
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_indexes",
					"IndexName": "lsif_indexes_state"
				}
			},
			{
				"ID": 1528395900,
				"Name": "add commit to lsif uploads repository index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS lsif_uploads_repository_id_commit ON lsif_uploads(repository_id, commit);",
				"DownQuery": "DROP INDEX IF EXISTS lsif_uploads_repository_id_commit;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395899
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "lsif_uploads",
					"IndexName": "lsif_uploads_repository_id_commit"
				}
			},
			{
				"ID": 1528395901,
				"Name": "remove duplicate index",
				"UpQuery": "DROP INDEX IF EXISTS lsif_uploads_repository_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS lsif_uploads_repository_id ON lsif_uploads(repository_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395900
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395902,
				"Name": "drop unused security events index 0",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_anonymous_user_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_anonymous_user_id ON security_event_logs USING btree (anonymous_user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395901
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395903,
				"Name": "drop unused security events index 1",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_user_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_user_id ON security_event_logs USING btree (user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395902
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395904,
				"Name": "drop unused security events index 2",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_name;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_name ON security_event_logs USING btree (name);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395903
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395905,
				"Name": "drop unused security events index 3",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_source;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_source ON security_event_logs USING btree (source);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395904
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395906,
				"Name": "drop unused security events index 4",
				"UpQuery": "DROP INDEX IF EXISTS security_event_logs_timestamp_at_utc;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS security_event_logs_timestamp_at_utc ON security_event_logs USING btree (date(timezone('UTC'::text, \"timestamp\")));",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395905
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395907,
				"Name": "more default lsif configuration policies",
				"UpQuery": "INSERT INTO lsif_configuration_policies\n    (\n        name,\n        protected, pattern, type,\n        retention_enabled, retain_intermediate_commits, retention_duration_hours,\n        indexing_enabled, index_intermediate_commits, index_commit_max_age_hours\n    )\nVALUES\n    (\n        'Default commit retention policy',\n        true, '*', 'GIT_TREE',\n        true, true, 168, -- 1 week (168 hours) * 4 * 3\n        false, false, 0\n    );",
				"DownQuery": "-- Nothing on down",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395906
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395908,
				"Name": "reverted",
				"UpQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"DownQuery": "-- Empty migration, this migration was reverted: https://github.com/sourcegraph/sourcegraph/pull/25715",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395907
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395909,
				"Name": "undo apidocs oob migration",
				"UpQuery": "-- Undo the changes corresponding to https://github.com/sourcegraph/sourcegraph/pull/25715\nDELETE FROM out_of_band_migrations WHERE id=12 AND team='apidocs';",
				"DownQuery": "-- Nothing to do, the up migration undid changes previously made.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395908
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395910,
				"Name": "gitserver last changed",
				"UpQuery": "ALTER TABLE gitserver_repos ADD COLUMN IF NOT EXISTS last_changed TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT now();",
				"DownQuery": "ALTER TABLE gitserver_repos DROP COLUMN last_changed;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395909
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395911,
				"Name": "add access token id to batch spec workspace execution jobs",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  ADD COLUMN IF NOT EXISTS access_token_id bigint REFERENCES access_tokens(id) ON DELETE SET NULL DEFERRABLE DEFAULT NULL;\n\nALTER TABLE IF EXISTS access_tokens\n  ADD COLUMN IF NOT EXISTS internal boolean DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_workspace_execution_jobs\n  DROP COLUMN IF EXISTS access_token_id;\n\nALTER TABLE IF EXISTS access_tokens\n  DROP COLUMN IF EXISTS internal;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395910
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395912,
				"Name": "apidocs oob search indexing",
				"UpQuery": "-- Create the OOB migration according to doc/dev/background-information/oobmigrations.md\nINSERT INTO out_of_band_migrations (id, team, component, description, introduced_version_major, introduced_version_minor, non_destructive)\nVALUES (\n    12,                                             -- This must be consistent across all Sourcegraph instances\n    'apidocs',                                      -- Team owning migration\n    'codeintel-db.lsif_data_documentation_search',  -- Component being migrated\n    'Index API docs for search',                    -- Description\n    3,                                              -- The next minor release (major version)\n    32,                                             -- The next minor release (minor version)\n    true                                            -- Can be read with previous version without down migration\n)\nON CONFLICT DO NOTHING;",
				"DownQuery": "-- The OOB migration doesn't add any new tables or columns or anything, so we don't need to do\n-- anything on down migration. It migrates data from lsif_data_documentation_pages -\u003e the new\n-- lsif_data_documentation_search_* tables - but it's fine to just leave those.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395911
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395913,
				"Name": "add unique constraint on batch spec resolution jobs",
				"UpQuery": "ALTER TABLE IF EXISTS batch_spec_resolution_jobs\n  ADD CONSTRAINT batch_spec_resolution_jobs_batch_spec_id_unique UNIQUE (batch_spec_id);",
				"DownQuery": "ALTER TABLE IF EXISTS batch_spec_resolution_jobs\n  DROP CONSTRAINT IF EXISTS batch_spec_resolution_jobs_batch_spec_id_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395912
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395914,
				"Name": "add created from raw to batch specs",
				"UpQuery": "ALTER TABLE batch_specs\n  ADD COLUMN IF NOT EXISTS created_from_raw boolean DEFAULT FALSE NOT NULL;",
				"DownQuery": "ALTER TABLE batch_specs\n  DROP COLUMN IF EXISTS created_from_raw;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395913
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395915,
				"Name": "remove raw changeset spec",
				"UpQuery": "ALTER TABLE\n    changeset_specs\nDROP COLUMN IF EXISTS\n    raw_spec;",
				"DownQuery": "-- We don't need to reconstruct the contents of the raw_spec column (and,\n-- indeed, we can't), so we'll just leave it with empty strings.\n\nALTER TABLE\n    changeset_specs\nADD COLUMN IF NOT EXISTS\n    raw_spec TEXT NOT NULL DEFAULT '';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395914
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395916,
				"Name": "add external service repos org id",
				"UpQuery": "ALTER TABLE external_service_repos ADD COLUMN IF NOT EXISTS org_id INTEGER REFERENCES orgs(id) ON DELETE CASCADE;",
				"DownQuery": "ALTER TABLE external_service_repos DROP COLUMN IF EXISTS org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395915
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395917,
				"Name": "add index rate limit",
				"UpQuery": "-- Create table to rate limit indexing scans of a repository\nCREATE TABLE lsif_last_index_scan (\n    repository_id int NOT NULL,\n    last_index_scan_at timestamp with time zone NOT NULL,\n\n    PRIMARY KEY(repository_id)\n);\nCOMMENT ON TABLE lsif_last_index_scan IS 'Tracks the last time repository was checked for auto-indexing job scheduling.';\nCOMMENT ON COLUMN lsif_last_index_scan.last_index_scan_at IS 'The last time uploads of this repository were considered for auto-indexing job scheduling.';",
				"DownQuery": "DROP TABLE IF EXISTS lsif_last_index_scan;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395916
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395918,
				"Name": "update batch spec workspaces to persist all",
				"UpQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS ignored BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS skipped BOOLEAN NOT NULL DEFAULT FALSE;\n\nALTER TABLE batch_specs\n  ADD COLUMN IF NOT EXISTS allow_unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS allow_ignored BOOLEAN NOT NULL DEFAULT FALSE;\n\nALTER TABLE batch_spec_resolution_jobs\n  DROP COLUMN IF EXISTS allow_unsupported,\n  DROP COLUMN IF EXISTS allow_ignored;",
				"DownQuery": "ALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS ignored,\n  DROP COLUMN IF EXISTS unsupported,\n  DROP COLUMN IF EXISTS skipped;\n\nALTER TABLE batch_specs\n  DROP COLUMN IF EXISTS allow_unsupported,\n  DROP COLUMN IF EXISTS allow_ignored;\n\nALTER TABLE batch_spec_resolution_jobs\n  ADD COLUMN IF NOT EXISTS allow_unsupported BOOLEAN NOT NULL DEFAULT FALSE,\n  ADD COLUMN IF NOT EXISTS allow_ignored BOOLEAN NOT NULL DEFAULT FALSE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395917
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395919,
				"Name": "drop soft delete search contexts",
				"UpQuery": "DELETE FROM search_contexts WHERE deleted_at IS NOT NULL;\n\nCOMMENT ON COLUMN search_contexts.deleted_at IS 'This column is unused as of Sourcegraph 3.34. Do not refer to it anymore. It will be dropped in a future version.';\n\nALTER TABLE search_context_repos ADD CONSTRAINT search_context_repos_unique UNIQUE (repo_id, search_context_id, revision);\n\nALTER TABLE search_context_repos DROP CONSTRAINT IF EXISTS search_context_repos_search_context_id_repo_id_revision_unique;",
				"DownQuery": "ALTER TABLE search_context_repos ADD CONSTRAINT search_context_repos_search_context_id_repo_id_revision_unique UNIQUE (search_context_id, repo_id, revision);\n\nALTER TABLE search_context_repos DROP CONSTRAINT IF EXISTS search_context_repos_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395918
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395920,
				"Name": "create sub repo permissions table",
				"UpQuery": "create table sub_repo_permissions\n(\n    repo_id       integer       not null\n        constraint sub_repo_permissions_repo_id_fk\n            references repo\n            on delete cascade,\n    user_id       integer       not null\n        constraint sub_repo_permissions_users_id_fk\n            references users\n            on delete cascade,\n    version       int default 1 not null,\n    path_includes text[],\n    path_excludes text[],\n    updated_at timestamp with time zone default now() not null\n);\n\ncomment on table sub_repo_permissions is 'Responsible for storing permissions at a finer granularity than repo';\n\ncreate unique index sub_repo_permissions_repo_id_user_id_uindex\n    on sub_repo_permissions (repo_id, user_id);\n\ncreate index sub_repo_perms_user_id ON sub_repo_permissions (user_id);\ncreate index sub_repo_perms_repo_id ON sub_repo_permissions (repo_id);",
				"DownQuery": "DROP TABLE IF EXISTS sub_repo_permissions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395919
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395921,
				"Name": "add version index sub repo permissions",
				"UpQuery": "drop index if exists sub_repo_permissions_repo_id_user_id_uindex;\n\ncreate unique index sub_repo_permissions_repo_id_user_id_version_uindex\n    on sub_repo_permissions (repo_id, user_id, version);\n\ncreate index sub_repo_perms_version ON sub_repo_permissions (version);",
				"DownQuery": "drop index if exists sub_repo_permissions_repo_id_user_id_version_uindex;\ndrop index if exists sub_repo_perms_version;\n\ncreate unique index sub_repo_permissions_repo_id_user_id_uindex\n    on sub_repo_permissions (repo_id, user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395920
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395922,
				"Name": "add external service repos org id index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS external_service_repos_org_id_idx ON external_service_repos USING btree (org_id) WHERE org_id IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS external_service_repos_org_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395921
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395923,
				"Name": "add has webhooks",
				"UpQuery": "ALTER TABLE\n    external_services\nADD COLUMN IF NOT EXISTS\n    has_webhooks BOOLEAN NULL DEFAULT NULL;\n\nCREATE INDEX\n    external_services_has_webhooks_idx\nON\n    external_services (has_webhooks);\n\nINSERT INTO\n    out_of_band_migrations (\n        id,\n        team,\n        component,\n        description,\n        introduced_version_major,\n        introduced_version_minor,\n        non_destructive\n    )\nVALUES (\n    13,\n    'batch-changes',\n    'frontend-db.external_services',\n    'Calculate the webhook state of each external service',\n    3,\n    34,\n    true\n)\nON CONFLICT\n    DO NOTHING\n;",
				"DownQuery": "-- We don't remove the out of band migration when moving down.\n\nALTER TABLE\n    external_services\nDROP COLUMN IF EXISTS\n    has_webhooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395922
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395924,
				"Name": "lsif configuration policies repository pattern lookup",
				"UpQuery": "-- Create lookup table for repository pattern matching\nCREATE TABLE IF NOT EXISTS lsif_configuration_policies_repository_pattern_lookup (\n    policy_id INTEGER NOT NULL,\n    repo_id INTEGER NOT NULL,\n    PRIMARY KEY (policy_id, repo_id)\n);\n\nCOMMENT ON TABLE lsif_configuration_policies_repository_pattern_lookup IS 'A lookup table to get all the repository patterns by repository id that apply to a configuration policy.';\nCOMMENT ON COLUMN lsif_configuration_policies_repository_pattern_lookup.policy_id IS 'The policy identifier associated with the repository.';\nCOMMENT ON COLUMN lsif_configuration_policies_repository_pattern_lookup.repo_id IS 'The repository identifier associated with the policy.';\n\n-- Add glob pattern column\nALTER TABLE lsif_configuration_policies ADD COLUMN repository_patterns TEXT[];\nCOMMENT ON COLUMN lsif_configuration_policies.repository_patterns IS 'The name pattern matching repositories to which this configuration policy applies. If absent, all repositories are matched.';\n\n-- Add column to determine the last update of the associated records in lsif_configuration_policies_repository_pattern_lookup\nALTER TABLE lsif_configuration_policies ADD COLUMN last_resolved_at TIMESTAMP WITH TIME ZONE DEFAULT NULL;",
				"DownQuery": "-- Drop new table\nDROP TABLE IF EXISTS lsif_configuration_policies_repository_pattern_lookup;\n\n-- Drop new columns\nALTER TABLE lsif_configuration_policies DROP COLUMN last_resolved_at;\nALTER TABLE lsif_configuration_policies DROP COLUMN repository_patterns;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395923
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395925,
				"Name": "settings global index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS settings_global_id ON settings (id DESC) WHERE user_id IS NULL AND org_id IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS settings_global_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395924
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395926,
				"Name": "drop redundant sub repo perms index",
				"UpQuery": "DROP INDEX IF EXISTS sub_repo_perms_repo_id;\n\nDROP INDEX IF EXISTS sub_repo_perms_user_id;\n\nDROP INDEX IF EXISTS sub_repo_perms_version;",
				"DownQuery": "CREATE INDEX sub_repo_perms_repo_id ON sub_repo_permissions (repo_id);\n\nCREATE INDEX sub_repo_perms_user_id ON sub_repo_permissions (user_id);\n\nCREATE INDEX sub_repo_perms_version ON sub_repo_permissions (version);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395925
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395927,
				"Name": "webhook logs",
				"UpQuery": "CREATE TABLE IF NOT EXISTS webhook_logs (\n    id BIGSERIAL PRIMARY KEY,\n    received_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    external_service_id INTEGER NULL REFERENCES external_services (id) ON DELETE CASCADE ON UPDATE CASCADE,\n    status_code INTEGER NOT NULL,\n    request BYTEA NOT NULL,\n    response BYTEA NOT NULL,\n    encryption_key_id TEXT NOT NULL\n);\n\nCREATE INDEX IF NOT EXISTS\n    webhook_logs_received_at_idx\nON\n    webhook_logs (received_at);\n\nCREATE INDEX IF NOT EXISTS\n    webhook_logs_external_service_id_idx\nON\n    webhook_logs (external_service_id);\n\nCREATE INDEX IF NOT EXISTS\n    webhook_logs_status_code_idx\nON\n    webhook_logs (status_code);",
				"DownQuery": "DROP TABLE IF EXISTS webhook_logs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395926
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395928,
				"Name": "add batch spec execution cache entries",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_execution_cache_entries (\n  id           BIGSERIAL PRIMARY KEY,\n\n  key          TEXT NOT NULL,\n  value        TEXT NOT NULL,\n\n  version      INTEGER NOT NULL,\n\n  last_used_at TIMESTAMP WITH TIME ZONE,\n  created_at   TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);",
				"DownQuery": "DROP TABLE IF EXISTS batch_spec_execution_cache_entries;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395927
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395929,
				"Name": "external service repos clone url",
				"UpQuery": "CREATE INDEX IF NOT EXISTS external_service_repos_clone_url_idx ON external_service_repos (clone_url);",
				"DownQuery": "DROP INDEX IF EXISTS external_service_repos_clone_url_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395928
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395930,
				"Name": "drop unused column object ids from user permissions table",
				"UpQuery": "ALTER TABLE IF EXISTS user_permissions DROP COLUMN IF EXISTS object_ids;",
				"DownQuery": "ALTER TABLE IF EXISTS user_permissions ADD COLUMN object_ids bytea NOT NULL default '\\x';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395929
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395931,
				"Name": "drop unused column user ids from repo permissions table",
				"UpQuery": "ALTER TABLE IF EXISTS repo_permissions DROP COLUMN IF EXISTS user_ids;",
				"DownQuery": "ALTER TABLE IF EXISTS repo_permissions ADD COLUMN user_ids bytea NOT NULL default '\\x';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395930
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395932,
				"Name": "add cache entry id to batch spec workspaces",
				"UpQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS batch_spec_execution_cache_entry_id INTEGER REFERENCES batch_spec_execution_cache_entries(id) DEFERRABLE;",
				"DownQuery": "ALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS batch_spec_execution_cache_entry_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395931
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395933,
				"Name": "add cached result found to batch spec workspaces",
				"UpQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS cached_result_found BOOLEAN NOT NULL DEFAULT FALSE;\n\nUPDATE\n  batch_spec_workspaces\nSET\n  cached_result_found = true\nWHERE\n  batch_spec_execution_cache_entry_id IS NOT NULL;\n\nALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS batch_spec_execution_cache_entry_id;\n\nDELETE FROM\n  batch_spec_execution_cache_entries e1\nWHERE\n  EXISTS (SELECT 1 FROM batch_spec_execution_cache_entries e2 WHERE e1.key = e2.key AND e1.id != e2.id);\n\nALTER TABLE batch_spec_execution_cache_entries\n  ADD CONSTRAINT batch_spec_execution_cache_entries_key_unique UNIQUE (key);",
				"DownQuery": "ALTER TABLE batch_spec_workspaces\n  ADD COLUMN IF NOT EXISTS batch_spec_execution_cache_entry_id INTEGER REFERENCES batch_spec_execution_cache_entries(id) DEFERRABLE;\n\nALTER TABLE batch_spec_workspaces\n  DROP COLUMN IF EXISTS cached_result_found;\n\nALTER TABLE batch_spec_execution_cache_entries\n  DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_key_unique;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395932
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395934,
				"Name": "lsif upload reference counts",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN reference_count int;\nCOMMENT ON COLUMN lsif_uploads.reference_count IS 'The number of references to this upload data from other upload records (via lsif_references).';\nCOMMENT ON COLUMN lsif_uploads.num_references IS 'Deprecated in favor of reference_count.';",
				"DownQuery": "-- Drop new column\nALTER TABLE lsif_uploads DROP COLUMN reference_count;\n\n-- Restore old comment on deprecated column\nCOMMENT ON COLUMN lsif_uploads.num_references IS 'The number of references to this upload data from other upload records (via lsif_references).';",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395933
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395935,
				"Name": "repo stars desc id desc index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_stars_desc_id_desc_idx\n    ON repo USING btree (stars DESC NULLS LAST, id DESC) WHERE deleted_at IS NULL AND blocked IS NULL;",
				"DownQuery": "DROP INDEX IF EXISTS repo_stars_desc_id_desc_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395934
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_stars_desc_id_desc_idx"
				}
			},
			{
				"ID": 1528395936,
				"Name": "repo name case sensitive trgm idx",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_name_case_sensitive_trgm_idx ON repo USING gin ((name::text) gin_trgm_ops);",
				"DownQuery": "DROP INDEX IF EXISTS repo_name_case_sensitive_trgm_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395935
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_name_case_sensitive_trgm_idx"
				}
			},
			{
				"ID": 1528395937,
				"Name": "codemonitor webhooks",
				"UpQuery": "-- Begin cm_webhooks\nCREATE TABLE IF NOT EXISTS cm_webhooks (\n\tid BIGSERIAL PRIMARY KEY,\n\tmonitor BIGINT NOT NULL REFERENCES cm_monitors(id) ON DELETE CASCADE,\n\turl TEXT NOT NULL,\n\tenabled BOOLEAN NOT NULL,\n\tcreated_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tcreated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\tchanged_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tchanged_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX IF NOT EXISTS cm_webhooks_monitor ON cm_webhooks (monitor);\n\nCOMMENT ON TABLE cm_webhooks IS 'Webhook actions configured on code monitors';\nCOMMENT ON COLUMN cm_webhooks.monitor IS 'The code monitor that the action is defined on';\nCOMMENT ON COLUMN cm_webhooks.url IS 'The webhook URL we send the code monitor event to';\nCOMMENT ON COLUMN cm_webhooks.enabled IS 'Whether this webhook action is enabled. When not enabled, the action will not be run when its code monitor generates events';\n-- End cm_webhooks\n\n-- Begin cm_slack_webhooks\nCREATE TABLE IF NOT EXISTS cm_slack_webhooks (\n\tid BIGSERIAL PRIMARY KEY,\n\tmonitor BIGINT NOT NULL REFERENCES cm_monitors(id) ON DELETE CASCADE,\n\turl TEXT NOT NULL,\n\tenabled BOOLEAN NOT NULL,\n\tcreated_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tcreated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\tchanged_by INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n\tchanged_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX IF NOT EXISTS cm_slack_webhooks_monitor ON cm_slack_webhooks (monitor);\n\nCOMMENT ON TABLE cm_slack_webhooks IS 'Slack webhook actions configured on code monitors';\nCOMMENT ON COLUMN cm_slack_webhooks.monitor IS 'The code monitor that the action is defined on';\nCOMMENT ON COLUMN cm_slack_webhooks.url IS 'The Slack webhook URL we send the code monitor event to';\nCOMMENT ON COLUMN cm_webhooks.enabled IS 'Whether this Slack webhook action is enabled. When not enabled, the action will not be run when its code monitor generates events';\n-- End cm_slack_webhooks\n\n-- Begin add non-email actions to cm_triggers\nALTER TABLE cm_action_jobs\n\tALTER COLUMN email DROP NOT NULL, -- make email nullable (drop the not null constraint)\n\tADD COLUMN IF NOT EXISTS webhook BIGINT -- create a nullable webhook column\n\t\tREFERENCES cm_webhooks(id) ON DELETE CASCADE,\n\tADD COLUMN IF NOT EXISTS slack_webhook BIGINT  --create a nullable slack webhook column\n\t\tREFERENCES cm_slack_webhooks(id) ON DELETE CASCADE,\n\tADD CONSTRAINT cm_action_jobs_only_one_action_type CHECK ( -- constrain that only one of email, webhook, and slack_webhook is non-null\n\t\t( \n\t\t\tCASE WHEN email IS NULL THEN 0 ELSE 1 END\n\t\t\t+ CASE WHEN webhook IS NULL THEN 0 ELSE 1 END \n\t\t\t+ CASE WHEN slack_webhook IS NULL THEN 0 ELSE 1 END \n\t\t) = 1\n\t);\n\nCOMMENT ON COLUMN cm_action_jobs.email IS 'The ID of the cm_emails action to execute if this is an email job. Mutually exclusive with webhook and slack_webhook';\nCOMMENT ON COLUMN cm_action_jobs.webhook IS 'The ID of the cm_webhooks action to execute if this is a webhook job. Mutually exclusive with email and slack_webhook';\nCOMMENT ON COLUMN cm_action_jobs.slack_webhook IS 'The ID of the cm_slack_webhook action to execute if this is a slack webhook job. Mutually exclusive with email and webhook';\nCOMMENT ON CONSTRAINT cm_action_jobs_only_one_action_type ON cm_action_jobs IS 'Constrains that each queued code monitor action has exactly one action type';\n-- End add non-email actions to cm_triggers",
				"DownQuery": "ALTER TABLE cm_action_jobs\n\tDROP CONSTRAINT IF EXISTS cm_action_jobs_only_one_action_type,\n\tDROP COLUMN IF EXISTS slack_webhook,\n\tDROP COLUMN IF EXISTS webhook,\n\tALTER COLUMN email SET NOT NULL;\n\nDROP TABLE IF EXISTS cm_slack_webhooks;\nDROP TABLE IF EXISTS cm_webhooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395936
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395938,
				"Name": "batch spec no cache",
				"UpQuery": "ALTER TABLE batch_specs ADD COLUMN IF NOT EXISTS no_cache BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE batch_specs DROP COLUMN IF EXISTS no_cache;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395937
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395939,
				"Name": "batch specs changeset specs delete cascade",
				"UpQuery": "ALTER TABLE changeset_specs\n    DROP CONSTRAINT changeset_specs_batch_spec_id_fkey,\n    ADD CONSTRAINT changeset_specs_batch_spec_id_fkey FOREIGN KEY (batch_spec_id) REFERENCES batch_specs (id) ON DELETE CASCADE DEFERRABLE;",
				"DownQuery": "ALTER TABLE changeset_specs\n    DROP CONSTRAINT changeset_specs_batch_spec_id_fkey,\n    ADD CONSTRAINT changeset_specs_batch_spec_id_fkey FOREIGN KEY (batch_spec_id) REFERENCES batch_specs (id) DEFERRABLE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395938
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395940,
				"Name": "executor heartbeats",
				"UpQuery": "CREATE TABLE IF NOT EXISTS executor_heartbeats (\n    id SERIAL PRIMARY KEY,\n    hostname TEXT NOT NULL UNIQUE,\n    queue_name TEXT NOT NULL,\n    os TEXT NOT NULL,\n    architecture TEXT NOT NULL,\n    docker_version TEXT NOT NULL,\n    executor_version TEXT NOT NULL,\n    git_version TEXT NOT NULL,\n    ignite_version TEXT NOT NULL,\n    src_cli_version TEXT NOT NULL,\n    first_seen_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    last_seen_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCOMMENT ON TABLE executor_heartbeats IS 'Tracks the most recent activity of executors attached to this Sourcegraph instance.';\nCOMMENT ON COLUMN executor_heartbeats.hostname IS 'The uniquely identifying name of the executor.';\nCOMMENT ON COLUMN executor_heartbeats.queue_name IS 'The queue name that the executor polls for work.';\nCOMMENT ON COLUMN executor_heartbeats.os IS 'The operating system running the executor.';\nCOMMENT ON COLUMN executor_heartbeats.architecture IS 'The machine architure running the executor.';\nCOMMENT ON COLUMN executor_heartbeats.docker_version IS 'The version of Docker used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.executor_version IS 'The version of the executor.';\nCOMMENT ON COLUMN executor_heartbeats.git_version IS 'The version of Git used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.ignite_version IS 'The version of Ignite used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.src_cli_version IS 'The version of src-cli used by the executor.';\nCOMMENT ON COLUMN executor_heartbeats.first_seen_at IS 'The first time a heartbeat from the executor was received.';\nCOMMENT ON COLUMN executor_heartbeats.last_seen_at IS 'The last time a heartbeat from the executor was received.';",
				"DownQuery": "DROP TABLE IF EXISTS executor_heartbeats;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395939
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395941,
				"Name": "remove-org-monitors",
				"UpQuery": "DELETE FROM cm_monitors WHERE namespace_user_id IS NULL;\nCOMMENT ON COLUMN cm_monitors.namespace_org_id IS 'DEPRECATED: code monitors cannot be owned by an org';\n\nALTER TABLE cm_monitors \n\tALTER COLUMN namespace_user_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE cm_monitors\n\tALTER COLUMN namespace_user_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395940
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395942,
				"Name": "remove-org-saved-searches",
				"UpQuery": "-- NOTE: this migration deleted saved searches belonging to orgs when what we should have done\n-- was remove notifications from saved searches. Saved searches are still used (and useful) as\n-- a bookmarking feature, and are not deprecated. Saved search notifications, however, are\n-- deprecated, and will be removed in v3.34.0 by removing the query runner service. \n\n-- DELETE FROM saved_searches WHERE user_id IS NULL;\n\n-- ALTER TABLE saved_searches\n-- \tALTER COLUMN user_id SET NOT NULL;\n\n-- COMMENT ON COLUMN saved_searches.org_id IS 'DEPRECATED: saved searches must be owned by a user';",
				"DownQuery": "-- ALTER TABLE saved_searches\n-- \tALTER COLUMN user_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395941
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395943,
				"Name": "disable-saved-search-notifications",
				"UpQuery": "UPDATE saved_searches\nSET (notify_owner, notify_slack) = (false, false);\n\nALTER TABLE saved_searches\n\tADD CONSTRAINT saved_searches_notifications_disabled CHECK (\n\t\tnotify_owner = false\n\t\tAND notify_slack = false\n\t);\n\nALTER TABLE IF EXISTS saved_searches\n\tALTER COLUMN user_id DROP NOT NULL;",
				"DownQuery": "ALTER TABLE IF EXISTS saved_searches\n\tDROP CONSTRAINT IF EXISTS saved_searches_notifications_disabled;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395942
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395944,
				"Name": "reenable-code-monitors",
				"UpQuery": "-- If code monitors were disabled by a manual step, make\n\t-- it possible to re-enable them by removing the constraint.\n\t-- If an admin wants to restore the previous enabled state\n\t-- from the backup table, they can run something like the following:\n\t--     UPDATE cm_monitors\n\t--     SET enabled = cm_monitors_enabled_backup.enabled\n\t--     FROM cm_monitors_enabled_backup\n\t--     WHERE cm_monitors.id = cm_monitors_enabled_backup.id;\n\tALTER TABLE cm_monitors\n\tDROP CONSTRAINT IF EXISTS cm_monitors_cannot_be_enabled;",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395943
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395945,
				"Name": "make batch change last applied at nullable",
				"UpQuery": "-- NO-OP to fix out of sequence migrations",
				"DownQuery": "-- NO-OP to fix out of sequence migrations",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395944
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395946,
				"Name": "drop unused last external service column",
				"UpQuery": "-- NO-OP to fix out of sequence migrations",
				"DownQuery": "-- NO-OP to fix out of sequence migrations",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395945
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395947,
				"Name": "settings migration out of band",
				"UpQuery": "-- NO-OP to fix out of sequence migrations",
				"DownQuery": "-- NO-OP to fix out of sequence migrations",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395946
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395948,
				"Name": "cache entry persist",
				"UpQuery": "-- NO-OP to fix out of sequence migrations",
				"DownQuery": "-- NO-OP to fix out of sequence migrations",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395947
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395949,
				"Name": "repo stars null to zero",
				"UpQuery": "CREATE OR REPLACE PROCEDURE set_repo_stars_null_to_zero() AS\n$BODY$\nDECLARE\n  done boolean;\n  total integer = 0;\n  updated integer = 0;\n\nBEGIN\n  SELECT COUNT(*) INTO total FROM repo WHERE stars IS NULL;\n\n  RAISE NOTICE 'repo_stars_null_to_zero: updating % rows', total;\n\n  done := total = 0;\n\n  WHILE NOT done LOOP\n    UPDATE repo SET stars = 0\n    FROM (\n      SELECT id FROM repo\n      WHERE stars IS NULL\n      LIMIT 10000\n      FOR UPDATE SKIP LOCKED\n    ) s\n    WHERE repo.id = s.id;\n\n    COMMIT;\n\n    SELECT COUNT(*) = 0 INTO done FROM repo WHERE stars IS NULL LIMIT 1;\n\n    updated := updated + 10000;\n\n    RAISE NOTICE 'repo_stars_null_to_zero: updated % of % rows', updated, total;\n  END LOOP;\nEND\n$BODY$\nLANGUAGE plpgsql;",
				"DownQuery": "DROP PROCEDURE IF EXISTS set_repo_stars_null_to_zero;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395948
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395950,
				"Name": "repo stars call null to zero",
				"UpQuery": "CALL set_repo_stars_null_to_zero();",
				"DownQuery": "",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395949
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395951,
				"Name": "repo stars not null",
				"UpQuery": "ALTER TABLE repo\n  ALTER COLUMN stars SET NOT NULL,\n  ALTER COLUMN stars SET DEFAULT 0;",
				"DownQuery": "ALTER TABLE repo\n  ALTER COLUMN stars DROP NOT NULL,\n  ALTER COLUMN stars DROP DEFAULT;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395950
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395952,
				"Name": "notebooks",
				"UpQuery": "CREATE TABLE IF NOT EXISTS notebooks (\n    id BIGSERIAL PRIMARY KEY,\n    title CITEXT NOT NULL,\n    blocks JSONB DEFAULT '[]'::JSONB NOT NULL,\n    public BOOLEAN NOT NULL,\n    creator_user_id INTEGER REFERENCES users(id) ON DELETE SET NULL DEFERRABLE,\n    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n    CONSTRAINT blocks_is_array CHECK (jsonb_typeof(blocks) = 'array')\n);",
				"DownQuery": "DROP TABLE IF EXISTS notebooks;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395951
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395953,
				"Name": "enable pgcrypto",
				"UpQuery": "CREATE EXTENSION IF NOT EXISTS pgcrypto;",
				"DownQuery": "DROP EXTENSION IF EXISTS pgcrypto;",
				"Privileged": true,
				"NonIdempotent": false,
				"Parents": [
					1528395952
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395954,
				"Name": "add repo hashed name index",
				"UpQuery": "-- Should run as single non-transaction block\nCREATE INDEX CONCURRENTLY IF NOT EXISTS repo_hashed_name_idx ON repo USING BTREE (sha256(lower(name)::bytea)) WHERE deleted_at IS NULL;",
				"DownQuery": "-- Should run as single non-transaction block\nDROP INDEX CONCURRENTLY IF EXISTS repo_hashed_name_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395953
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_hashed_name_idx"
				}
			},
			{
				"ID": 1528395955,
				"Name": "add user id to batch spec execution cache entries",
				"UpQuery": "-- Bust the cache, since we can't recreate the user_id for existing cache entries.\nDELETE FROM batch_spec_execution_cache_entries;\n\nALTER TABLE batch_spec_execution_cache_entries\n  ADD COLUMN IF NOT EXISTS user_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n  DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_key_unique,\n    DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_user_id_key_unique,\n  ADD CONSTRAINT batch_spec_execution_cache_entries_user_id_key_unique UNIQUE (user_id, key);",
				"DownQuery": "-- Bust the cache, since we might run into unique key constraint errors.\nDELETE FROM batch_spec_execution_cache_entries;\n\nALTER TABLE batch_spec_execution_cache_entries\n  DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_user_id_key_unique,\n  DROP COLUMN IF EXISTS user_id,\n  DROP CONSTRAINT IF EXISTS batch_spec_execution_cache_entries_key_unique,\n  ADD CONSTRAINT batch_spec_execution_cache_entries_key_unique UNIQUE (key);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395954
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395956,
				"Name": "add org stats table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS org_stats\n(\n    org_id INTEGER\n        REFERENCES orgs(id) ON DELETE CASCADE DEFERRABLE\n            PRIMARY KEY,\n    code_host_repo_count INTEGER DEFAULT 0,\n    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\nCOMMENT ON TABLE org_stats IS 'Business statistics for organizations';\nCOMMENT ON COLUMN org_stats.org_id IS 'Org ID that the stats relate to.';\nCOMMENT ON COLUMN org_stats.code_host_repo_count IS 'Count of repositories accessible on all code hosts for this organization.';",
				"DownQuery": "DROP TABLE IF EXISTS org_stats;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395955
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395957,
				"Name": "notebooks text search indices",
				"UpQuery": "-- We add a generated column that will contain a tsvector representation of strings contained in the blocks array (extracted with the jsonb_to_tsvector expression).\nALTER TABLE notebooks ADD COLUMN IF NOT EXISTS blocks_tsvector TSVECTOR GENERATED ALWAYS AS (jsonb_to_tsvector('english', blocks, '[\"string\"]')) STORED;\n\n-- Postgres does not support trigram indices on a CITEXT column. We have to revert it back to a regular TEXT column to apply a trigram index.\nALTER TABLE notebooks ALTER COLUMN title TYPE TEXT;\n\nCREATE INDEX IF NOT EXISTS notebooks_title_trgm_idx ON notebooks USING GIN (title gin_trgm_ops);\n\n-- TSVECTOR columns do not support a gin_trgm_ops index, so we omit it here.\nCREATE INDEX IF NOT EXISTS notebooks_blocks_tsvector_idx ON notebooks USING GIN (blocks_tsvector);",
				"DownQuery": "ALTER TABLE notebooks DROP COLUMN IF EXISTS blocks_tsvector;\n\nALTER TABLE notebooks ALTER COLUMN title TYPE CITEXT;\n\nDROP INDEX IF EXISTS notebooks_title_trgm_idx;\n\nDROP INDEX IF EXISTS notebooks_blocks_tsvector_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395956
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395958,
				"Name": "tos accepted",
				"UpQuery": "ALTER TABLE IF EXISTS users ADD COLUMN IF NOT EXISTS tos_accepted BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE IF EXISTS users DROP COLUMN IF EXISTS tos_accepted;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395957
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395959,
				"Name": "batch change creator id",
				"UpQuery": "DO $$\nBEGIN\n    IF EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'batch_changes' AND column_name = 'initial_applier_id')\n    THEN\n        ALTER TABLE batch_changes RENAME COLUMN initial_applier_id TO creator_id;\n    END IF;\nEND $$;",
				"DownQuery": "DO $$\nBEGIN\n    IF EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name = 'batch_changes' AND column_name = 'creator_id')\n    THEN\n        ALTER TABLE batch_changes RENAME COLUMN creator_id TO initial_applier_id;\n    END IF;\nEND $$;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395958
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395960,
				"Name": "batch spec workspace skipped steps",
				"UpQuery": "ALTER TABLE batch_spec_workspaces ADD COLUMN IF NOT EXISTS skipped_steps integer[] NOT NULL DEFAULT '{}';",
				"DownQuery": "ALTER TABLE batch_spec_workspaces DROP COLUMN IF EXISTS skipped_steps;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395959
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395961,
				"Name": "make batch change last applied at nullable",
				"UpQuery": "ALTER TABLE IF EXISTS batch_changes\n    ALTER COLUMN last_applied_at DROP NOT NULL,\n    ALTER COLUMN last_applied_at DROP DEFAULT;",
				"DownQuery": "UPDATE batch_changes SET last_applied_at = TO_TIMESTAMP(0) WHERE last_applied_at IS NULL;\n\nALTER TABLE IF EXISTS batch_changes\n    ALTER COLUMN last_applied_at SET DEFAULT NOW(),\n    ALTER COLUMN last_applied_at SET NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395960
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395962,
				"Name": "drop unused last external service column",
				"UpQuery": "ALTER TABLE IF EXISTS gitserver_repos DROP COLUMN IF EXISTS last_external_service;",
				"DownQuery": "ALTER TABLE IF EXISTS gitserver_repos ADD COLUMN IF NOT EXISTS last_external_service bigint;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395961
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395963,
				"Name": "settings migration out of band",
				"UpQuery": "CREATE TABLE IF NOT EXISTS insights_settings_migration_jobs\n(\n    id SERIAL NOT NULL,\n    user_id int,\n    org_id int,\n    global boolean,\n    settings_id int NOT NULL, -- non-constrained foreign key to settings object that should be migrated\n    total_insights int NOT NULL DEFAULT 0,\n    migrated_insights int NOT NULL DEFAULT 0,\n    total_dashboards int NOT NULL DEFAULT 0,\n    migrated_dashboards int NOT NULL DEFAULT 0,\n    runs int NOT NULL DEFAULT 0,\n    completed_at timestamp\n);\n\nTRUNCATE insights_settings_migration_jobs;\n\n-- We go in this order (global, org, user) such that we migrate any higher level shared insights first. This way\n-- we can just go in the order of id rather than have a secondary index.\n\n-- global\nINSERT INTO insights_settings_migration_jobs (settings_id, global)\nSELECT id, TRUE\nFROM settings\nWHERE user_id IS NULL AND org_id IS NULL\nORDER BY id DESC\nLIMIT 1;\n\n-- org\nINSERT INTO insights_settings_migration_jobs (settings_id, org_id)\nSELECT DISTINCT ON (org_id) id, org_id\nFROM settings\nWHERE org_id IS NOT NULL\nORDER BY org_id, id DESC;\n\n--  user\nINSERT INTO insights_settings_migration_jobs (settings_id, user_id)\nSELECT DISTINCT ON (user_id) id, user_id\nFROM settings\nWHERE user_id IS NOT NULL\nORDER BY user_id, id DESC;\n\n\nINSERT INTO out_of_band_migrations(id, team, component, description, non_destructive,\n                                   apply_reverse, is_enterprise, introduced_version_major, introduced_version_minor)\nVALUES (14, 'code-insights', 'db.insights_settings_migration_jobs',\n        'Migrating insight definitions from settings files to database tables as a last stage to use the GraphQL API.',\n        TRUE, FALSE, TRUE, 3, 35)\nON CONFLICT DO NOTHING;",
				"DownQuery": "DROP TABLE IF EXISTS insights_settings_migration_jobs;\n\nDELETE\nFROM out_of_band_migrations\nWHERE id = 14;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395962
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395964,
				"Name": "cache entry persist",
				"UpQuery": "ALTER TABLE batch_spec_workspaces ADD COLUMN IF NOT EXISTS step_cache_results JSONB NOT NULL DEFAULT '{}';",
				"DownQuery": "ALTER TABLE batch_spec_workspaces DROP COLUMN IF EXISTS step_cache_results;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395963
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395965,
				"Name": "add search contexts query",
				"UpQuery": "ALTER TABLE search_contexts ADD COLUMN IF NOT EXISTS query TEXT;\n\nCREATE INDEX IF NOT EXISTS search_contexts_query_idx ON search_contexts USING BTREE (query);",
				"DownQuery": "ALTER TABLE search_contexts DROP COLUMN IF EXISTS query;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395964
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395966,
				"Name": "add changeset external fork namespace",
				"UpQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n  changesets\nADD COLUMN IF NOT EXISTS\n  external_fork_namespace CITEXT NULL;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"DownQuery": "-- Note that we have to regenerate the reconciler_changesets view, as the SELECT\n-- c.* in the view definition isn't refreshed when the fields change within the\n-- changesets table.\nDROP VIEW IF EXISTS\n    reconciler_changesets;\n\nALTER TABLE\n  changesets\nDROP COLUMN IF EXISTS\n  external_fork_namespace;\n\nCREATE VIEW reconciler_changesets AS\n    SELECT c.* FROM changesets c\n    INNER JOIN repo r on r.id = c.repo_id\n    WHERE\n        r.deleted_at IS NULL AND\n        EXISTS (\n            SELECT 1 FROM batch_changes\n            LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n            LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n            WHERE\n                c.batch_change_ids ? batch_changes.id::text AND\n                namespace_user.deleted_at IS NULL AND\n                namespace_org.deleted_at IS NULL\n        )\n;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395965
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395967,
				"Name": "notebook stars",
				"UpQuery": "CREATE TABLE IF NOT EXISTS notebook_stars (\n    notebook_id INTEGER NOT NULL REFERENCES notebooks(id) ON DELETE CASCADE DEFERRABLE,\n    user_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE DEFERRABLE,\n    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n\n    PRIMARY KEY (notebook_id, user_id)\n);\n\nCREATE INDEX IF NOT EXISTS notebook_stars_user_id_idx ON notebook_stars USING btree (user_id);",
				"DownQuery": "DROP INDEX IF EXISTS notebook_stars_user_id_idx;\n\nDROP TABLE IF EXISTS notebook_stars;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395966
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395968,
				"Name": "track fork namespace on spec",
				"UpQuery": "ALTER TABLE\n  changeset_specs\nADD COLUMN IF NOT EXISTS\n  fork_namespace CITEXT NULL;",
				"DownQuery": "ALTER TABLE\n  changeset_specs\nDROP COLUMN IF EXISTS\n  fork_namespace;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395967
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395969,
				"Name": "add org invitation fields",
				"UpQuery": "ALTER TABLE IF EXISTS org_invitations\n  ADD COLUMN IF NOT EXISTS recipient_email CITEXT,\n  ADD COLUMN IF NOT EXISTS expires_at timestamp with time zone;",
				"DownQuery": "ALTER TABLE IF EXISTS org_invitations\n  DROP COLUMN IF EXISTS recipient_email,\n  DROP COLUMN IF EXISTS expires_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395968
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395970,
				"Name": "save code monitor payload",
				"UpQuery": "ALTER TABLE cm_trigger_jobs\n    DROP CONSTRAINT IF EXISTS search_results_is_array,\n    ADD COLUMN IF NOT EXISTS search_results JSONB,\n    ADD CONSTRAINT search_results_is_array CHECK (jsonb_typeof(search_results) = 'array');\n\nCOMMENT ON COLUMN cm_trigger_jobs.results IS 'DEPRECATED: replaced by len(search_results) \u003e 0. Can be removed after version 3.37 release cut';\nCOMMENT ON COLUMN cm_trigger_jobs.num_results IS 'DEPRECATED: replaced by len(search_results). Can be removed after version 3.37 release cut';",
				"DownQuery": "ALTER TABLE cm_trigger_jobs\n    DROP COLUMN IF EXISTS search_results;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395969
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395971,
				"Name": "add notebook namespaces",
				"UpQuery": "ALTER TABLE IF EXISTS notebooks\n    ADD COLUMN IF NOT EXISTS namespace_user_id integer REFERENCES users(id) ON DELETE SET NULL DEFERRABLE,\n    ADD COLUMN IF NOT EXISTS namespace_org_id integer REFERENCES orgs(id) ON DELETE SET NULL DEFERRABLE,\n    ADD COLUMN IF NOT EXISTS updater_user_id integer REFERENCES users(id) ON DELETE SET NULL DEFERRABLE,\n    DROP CONSTRAINT IF EXISTS notebooks_has_max_1_namespace,\n    ADD CONSTRAINT notebooks_has_max_1_namespace CHECK ((namespace_user_id IS NULL AND namespace_org_id IS NULL) OR ((namespace_user_id IS NULL) \u003c\u003e (namespace_org_id IS NULL)));\n\nCREATE INDEX IF NOT EXISTS notebooks_namespace_user_id_idx ON notebooks USING btree (namespace_user_id);\n\nCREATE INDEX IF NOT EXISTS notebooks_namespace_org_id_idx ON notebooks USING btree (namespace_org_id);\n\nUPDATE notebooks SET namespace_user_id = creator_user_id;",
				"DownQuery": "ALTER TABLE IF EXISTS notebooks\n    DROP COLUMN IF EXISTS namespace_user_id,\n    DROP COLUMN IF EXISTS namespace_org_id,\n    DROP COLUMN IF EXISTS updater_user_id,\n    DROP CONSTRAINT IF EXISTS notebooks_has_max_1_namespace;\n\nDROP INDEX IF EXISTS notebooks_namespace_user_id_idx;\n\nDROP INDEX IF EXISTS notebooks_namespace_org_id_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395970
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395972,
				"Name": "no steps persisted",
				"UpQuery": "ALTER TABLE batch_spec_workspaces DROP COLUMN IF EXISTS steps;\nALTER TABLE batch_spec_workspaces DROP COLUMN IF EXISTS skipped_steps;",
				"DownQuery": "ALTER TABLE batch_spec_workspaces ADD COLUMN IF NOT EXISTS steps JSONB DEFAULT '[]'::JSONB CHECK (jsonb_typeof(steps) = 'array'::TEXT);\nALTER TABLE batch_spec_workspaces ADD COLUMN IF NOT EXISTS skipped_steps INTEGER[] NOT NULL DEFAULT '{}'::INTEGER[];",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395971
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1528395973,
				"Name": "return user_id index to sub_repo_permissions table",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS sub_repo_perms_user_id ON sub_repo_permissions (user_id);",
				"DownQuery": "DROP INDEX IF EXISTS sub_repo_perms_user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395972
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "sub_repo_permissions",
					"IndexName": "sub_repo_perms_user_id"
				}
			},
			{
				"ID": 1644471839,
				"Name": "codemonitor results in notifications",
				"UpQuery": "ALTER TABLE cm_emails\n    ADD COLUMN IF NOT EXISTS include_results BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE cm_webhooks\n    ADD COLUMN IF NOT EXISTS include_results BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE cm_slack_webhooks\n    ADD COLUMN IF NOT EXISTS include_results BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE cm_emails\n    DROP COLUMN IF EXISTS include_results;\nALTER TABLE cm_webhooks\n    DROP COLUMN IF EXISTS include_results;\nALTER TABLE cm_slack_webhooks\n    DROP COLUMN IF EXISTS include_results;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395973
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1644515056,
				"Name": "allow org invitation user id to be nullable",
				"UpQuery": "ALTER TABLE IF EXISTS org_invitations ALTER COLUMN recipient_user_id DROP NOT NULL;\nALTER TABLE IF EXISTS org_invitations\n    DROP CONSTRAINT IF EXISTS either_user_id_or_email_defined,\n  ADD CONSTRAINT either_user_id_or_email_defined CHECK ((recipient_user_id IS NULL) != (recipient_email IS NULL));",
				"DownQuery": "-- Undo the changes made in the up migration\nALTER TABLE IF EXISTS org_invitations ALTER COLUMN recipient_user_id SET NOT NULL;\nALTER TABLE IF EXISTS org_invitations DROP CONSTRAINT IF EXISTS either_user_id_or_email_defined;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1528395973
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1644583379,
				"Name": "set_expiry_date_for_existing_invitations",
				"UpQuery": "-- If we have invitations that are not deleted, not revoked, not responded to and with no expiry time\n-- set the default expiry time to 7 days from now\nUPDATE\n    org_invitations\nSET\n    expires_at = now() + interval '7 days'\nWHERE\n    deleted_at IS NULL\n    AND revoked_at IS NULL\n    AND responded_at IS NULL\n    AND expires_at IS NULL;",
				"DownQuery": "-- Undo the changes made in the up migration\nUPDATE org_invitations SET expires_at = NULL WHERE expires_at IS NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1644515056
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1644868458,
				"Name": "unqiue batch changes",
				"UpQuery": "CREATE UNIQUE INDEX IF NOT EXISTS batch_changes_unique_user_id ON batch_changes (name, namespace_user_id) WHERE namespace_user_id IS NOT NULL;\nCREATE UNIQUE INDEX IF NOT EXISTS batch_changes_unique_org_id ON batch_changes (name, namespace_org_id) WHERE namespace_org_id IS NOT NULL;",
				"DownQuery": "DROP INDEX IF EXISTS batch_changes_unique_user_id;\nDROP INDEX IF EXISTS batch_changes_unique_org_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1644471839,
					1644583379
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1645106226,
				"Name": "user opt in or out from org invite search",
				"UpQuery": "ALTER TABLE IF EXISTS users ADD COLUMN IF NOT EXISTS searchable BOOLEAN NOT NULL DEFAULT TRUE;",
				"DownQuery": "ALTER TABLE IF EXISTS users DROP COLUMN IF EXISTS searchable;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1644868458
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1645554732,
				"Name": "default-settings-value",
				"UpQuery": "ALTER TABLE settings\n    ALTER COLUMN contents SET DEFAULT '{}';\n\nUPDATE settings\nSET contents = '{}'\nWHERE contents = NULL\n    OR contents = '';\n\nALTER TABLE settings\n    ALTER COLUMN contents SET NOT NULL,\n    DROP CONSTRAINT IF EXISTS settings_no_empty_contents,\n    ADD CONSTRAINT settings_no_empty_contents CHECK ( contents \u003c\u003e '' );",
				"DownQuery": "ALTER TABLE settings\n    ALTER COLUMN contents DROP NOT NULL;\n\nALTER TABLE settings\n    ALTER COLUMN contents DROP DEFAULT,\n    DROP CONSTRAINT IF EXISTS settings_no_empty_contents;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645106226
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1645635177,
				"Name": "allow_another_invitation_after_previous_expired",
				"UpQuery": "DROP INDEX IF EXISTS org_invitations_singleflight;",
				"DownQuery": "CREATE UNIQUE INDEX IF NOT EXISTS org_invitations_singleflight ON org_invitations USING btree (org_id, recipient_user_id) WHERE ((responded_at IS NULL) AND (revoked_at IS NULL) AND (deleted_at IS NULL));",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645554732
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646027072,
				"Name": "add external_services.token_expires_at column",
				"UpQuery": "ALTER TABLE external_services ADD COLUMN IF NOT EXISTS token_expires_at TIMESTAMP WITH TIME ZONE;",
				"DownQuery": "ALTER TABLE external_services DROP COLUMN IF EXISTS token_expires_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645554732
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646153853,
				"Name": "add-created-at-to-external-service-repos",
				"UpQuery": "ALTER TABLE IF EXISTS external_service_repos\n    ADD COLUMN IF NOT EXISTS created_at timestamp with time zone DEFAULT transaction_timestamp();",
				"DownQuery": "ALTER TABLE IF EXISTS external_service_repos\n    DROP COLUMN IF EXISTS created_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645554732
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646239940,
				"Name": "non-nullable-created-at-external-service-repos",
				"UpQuery": "ALTER TABLE IF EXISTS external_service_repos\n    ALTER COLUMN created_at SET NOT NULL ;",
				"DownQuery": "ALTER TABLE IF EXISTS external_service_repos\n    ALTER COLUMN created_at DROP NOT NULL ;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1645635177,
					1646153853
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646306565,
				"Name": "drop-binary-permissions-columns",
				"UpQuery": "ALTER TABLE repo_pending_permissions DROP COLUMN IF EXISTS user_ids;\nALTER TABLE user_pending_permissions DROP COLUMN IF EXISTS object_ids;",
				"DownQuery": "ALTER TABLE repo_pending_permissions ADD COLUMN IF NOT EXISTS user_ids bytea NOT NULL DEFAULT '\\x'::bytea;\nALTER TABLE user_pending_permissions ADD COLUMN IF NOT EXISTS object_ids bytea NOT NULL DEFAULT '\\x'::bytea;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646027072,
					1646239940
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646652951,
				"Name": "store_org_open_beta_metadata",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\nCREATE TABLE IF NOT EXISTS orgs_open_beta_stats (\n    id uuid PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id integer,\n    org_id integer,\n    created_at timestamptz DEFAULT now(),\n    data jsonb NOT NULL DEFAULT '{}'\n);",
				"DownQuery": "-- Undo the changes made in the up migration\nDROP TABLE IF EXISTS orgs_open_beta_stats;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646306565
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646741362,
				"Name": "add_gitserver_repos_repo_size_bytes_column",
				"UpQuery": "ALTER TABLE IF EXISTS gitserver_repos\n    ADD COLUMN IF NOT EXISTS repo_size_bytes BIGINT;",
				"DownQuery": "ALTER TABLE IF EXISTS gitserver_repos\n    DROP COLUMN IF EXISTS repo_size_bytes;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646306565
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646848295,
				"Name": "indexer version",
				"UpQuery": "ALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS indexer_version text;\nCOMMENT ON COLUMN lsif_uploads.indexer_version IS 'The version of the indexer that produced the index file. If not supplied by the user it will be pulled from the index metadata.';\n\nDROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps;\n\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS indexer_version;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_dumps AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nDROP VIEW IF EXISTS lsif_indexes_with_repository_name;\nALTER TABLE lsif_indexes DROP COLUMN IF EXISTS indexer_version;\n\nCREATE VIEW lsif_indexes_with_repository_name AS\nSELECT\n    u.id,\n    u.commit,\n    u.queued_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.process_after,\n    u.num_resets,\n    u.num_failures,\n    u.docker_steps,\n    u.root,\n    u.indexer,\n    u.indexer_args,\n    u.outfile,\n    u.log_contents,\n    u.execution_logs,\n    u.local_steps,\n    r.name AS repository_name\nFROM lsif_indexes u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646741362
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1646847163,
				"Name": "code monitor last searched",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\n--  * If you are modifying Postgres extensions, you must also declare \"privileged: true\"\n--    in the associated metadata.yaml file.\n\nCREATE TABLE IF NOT EXISTS cm_last_searched (\n    monitor_id BIGINT NOT NULL REFERENCES cm_monitors(id) ON DELETE CASCADE,\n    args_hash BIGINT NOT NULL,\n    commit_oids text[] NOT NULL,\n    PRIMARY KEY (monitor_id, args_hash)\n);\n\nCOMMENT ON TABLE cm_last_searched\n    IS 'The last searched commit hashes for the given code monitor and unique set of search arguments';\nCOMMENT ON COLUMN cm_last_searched.args_hash\n    IS 'A unique hash of the gitserver search arguments to identify this search job';\nCOMMENT ON COLUMN cm_last_searched.commit_oids\n    IS 'The set of commit OIDs that was previously successfully searched and should be excluded on the next run';",
				"DownQuery": "-- Undo the changes made in the up migration\n\nDROP TABLE IF EXISTS cm_last_searched;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646306565
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1647282553,
				"Name": "Add queued_at to workerutil tables",
				"UpQuery": "ALTER TABLE batch_spec_resolution_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE batch_spec_workspace_execution_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE changeset_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE cm_action_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE cm_trigger_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE external_service_sync_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\nALTER TABLE insights_query_runner_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\n\n-- LSIF upload records are not queued when created; they begin in an extra state called \"uploading\" and only\n-- after the payload has been received in full do we mark the record ready for processing. We update this field\n--- manually at that point.\nALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS queued_at timestamptz;\n\n--\n-- Drop views that require new column\n\nDROP VIEW IF EXISTS external_service_sync_jobs_with_next_sync_at;\nDROP VIEW IF EXISTS lsif_dumps_with_repository_name;\nDROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps;\nDROP VIEW IF EXISTS reconciler_changesets;\n\n--\n-- Recreate views with new column\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS\nSELECT j.id,\n    j.state,\n    j.failure_message,\n    j.queued_at,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.execution_logs,\n    j.external_service_id,\n    e.next_sync_at\nFROM external_services e\nJOIN external_service_sync_jobs j ON e.id = j.external_service_id;\n\nCREATE VIEW lsif_dumps AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u JOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n    c.batch_change_ids,\n    c.repo_id,\n    c.queued_at,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_changed,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_batch_change_id,\n    c.reconciler_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error,\n    c.external_title,\n    c.worker_hostname,\n    c.ui_publication_state,\n    c.last_heartbeat_at,\n    c.external_fork_namespace\nFROM changesets c\nJOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n    LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n    LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n);",
				"DownQuery": "--\n-- Drop views that added new column\n\nDROP VIEW IF EXISTS external_service_sync_jobs_with_next_sync_at;\nDROP VIEW IF EXISTS lsif_dumps_with_repository_name;\nDROP VIEW IF EXISTS lsif_uploads_with_repository_name;\nDROP VIEW IF EXISTS lsif_dumps;\nDROP VIEW IF EXISTS reconciler_changesets;\n\n--\n-- Recreate old views\n\nCREATE VIEW external_service_sync_jobs_with_next_sync_at AS\nSELECT j.id,\n    j.state,\n    j.failure_message,\n    j.started_at,\n    j.finished_at,\n    j.process_after,\n    j.num_resets,\n    j.num_failures,\n    j.execution_logs,\n    j.external_service_id,\n    e.next_sync_at\nFROM external_services e\nJOIN external_service_sync_jobs j ON e.id = j.external_service_id;\n\nCREATE VIEW lsif_dumps AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.finished_at AS processed_at\nFROM lsif_uploads u\nWHERE u.state = 'completed'::text OR u.state = 'deleting'::text;\n\nCREATE VIEW lsif_dumps_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    u.processed_at,\n    r.name AS repository_name\nFROM lsif_dumps u JOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n    c.batch_change_ids,\n    c.repo_id,\n    c.created_at,\n    c.updated_at,\n    c.metadata,\n    c.external_id,\n    c.external_service_type,\n    c.external_deleted_at,\n    c.external_branch,\n    c.external_updated_at,\n    c.external_state,\n    c.external_review_state,\n    c.external_check_state,\n    c.diff_stat_added,\n    c.diff_stat_changed,\n    c.diff_stat_deleted,\n    c.sync_state,\n    c.current_spec_id,\n    c.previous_spec_id,\n    c.publication_state,\n    c.owned_by_batch_change_id,\n    c.reconciler_state,\n    c.failure_message,\n    c.started_at,\n    c.finished_at,\n    c.process_after,\n    c.num_resets,\n    c.closing,\n    c.num_failures,\n    c.log_contents,\n    c.execution_logs,\n    c.syncer_error,\n    c.external_title,\n    c.worker_hostname,\n    c.ui_publication_state,\n    c.last_heartbeat_at,\n    c.external_fork_namespace\nFROM changesets c\nJOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n    LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n    LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n);\n\n--\n-- Drop new columns\n\nALTER TABLE batch_spec_resolution_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE batch_spec_workspace_execution_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE changeset_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE changesets DROP COLUMN IF EXISTS queued_at;\nALTER TABLE cm_action_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE cm_trigger_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE external_service_sync_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE insights_query_runner_jobs DROP COLUMN IF EXISTS queued_at;\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS queued_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646847163,
					1646848295
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1647849753,
				"Name": "drop backup tables",
				"UpQuery": "DROP TABLE IF EXISTS org_members_bkup_1514536731;\nDROP TABLE IF EXISTS settings_bkup_1514702776;",
				"DownQuery": "-- Nothing to do, actually. We have not been using these backup tables since 2018.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646652951,
					1647282553
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1647860082,
				"Name": "add_localclone_worker_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS gitserver_localclone_jobs (\n    id                  SERIAL PRIMARY KEY,\n    state               text DEFAULT 'queued',\n    failure_message     text,\n    started_at          timestamp with time zone,\n    finished_at         timestamp with time zone,\n    process_after       timestamp with time zone,\n    num_resets          integer not null default 0,\n    num_failures        integer not null default 0,\n    last_heartbeat_at   timestamp with time zone,\n    execution_logs      json[],\n    worker_hostname     text not null default '',\n\n    repo_id             integer not null,\n    source_hostname     text not null,\n    dest_hostname       text not null,\n    delete_source       boolean not null default false\n);",
				"DownQuery": "DROP TABLE IF EXISTS gitserver_localclone_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1646652951,
					1647282553
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648051770,
				"Name": "cascade feature flag updates",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\n--  * If you are modifying Postgres extensions, you must also declare \"privileged: true\"\n--    in the associated metadata.yaml file.\n\nALTER TABLE feature_flag_overrides\n    DROP CONSTRAINT feature_flag_overrides_flag_name_fkey;\n\nALTER TABLE feature_flag_overrides\n    ADD CONSTRAINT feature_flag_overrides_flag_name_fkey\n    FOREIGN KEY (flag_name)\n    REFERENCES feature_flags(flag_name)\n    ON DELETE CASCADE\n    ON UPDATE CASCADE;",
				"DownQuery": "-- Undo the changes made in the up migration\n\nALTER TABLE feature_flag_overrides\n    DROP CONSTRAINT feature_flag_overrides_flag_name_fkey;\n\nALTER TABLE feature_flag_overrides\n    ADD CONSTRAINT feature_flag_overrides_flag_name_fkey\n    FOREIGN KEY (flag_name)\n    REFERENCES feature_flags(flag_name)\n    ON DELETE CASCADE;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1647849753,
					1647860082
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648115472,
				"Name": "add_localclone_worker_view",
				"UpQuery": "CREATE OR REPLACE VIEW gitserver_localclone_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_localclone_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"DownQuery": "DROP VIEW IF EXISTS gitserver_localclone_jobs_with_repo_name;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1647849753,
					1647860082
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648195639,
				"Name": "add_localclone_worker_queued_at",
				"UpQuery": "ALTER TABLE gitserver_localclone_jobs ADD COLUMN IF NOT EXISTS queued_at timestamptz DEFAULT NOW();\n\n-- drop view and recreate it with the new column\n\nDROP VIEW IF EXISTS gitserver_localclone_jobs_with_repo_name;\n\nCREATE OR REPLACE VIEW gitserver_localclone_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_localclone_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"DownQuery": "-- drop view\nDROP VIEW IF EXISTS gitserver_localclone_jobs_with_repo_name;\n\n-- drop the column\nALTER TABLE gitserver_localclone_jobs DROP COLUMN IF EXISTS queued_at;\n\n-- recreate the view without the column\nCREATE OR REPLACE VIEW gitserver_localclone_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_localclone_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648051770,
					1648115472
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648524019,
				"Name": "int64-ids-user-pending-permissions",
				"UpQuery": "TRUNCATE TABLE user_pending_permissions;\nTRUNCATE TABLE repo_pending_permissions;\n\nALTER TABLE IF EXISTS user_pending_permissions ALTER COLUMN id TYPE BIGINT;\nALTER TABLE IF EXISTS repo_pending_permissions ALTER COLUMN user_ids_ints TYPE BIGINT[];\n\nALTER SEQUENCE IF EXISTS user_pending_permissions_id_seq RESTART;",
				"DownQuery": "TRUNCATE TABLE user_pending_permissions;\nTRUNCATE TABLE repo_pending_permissions;\n\nALTER TABLE IF EXISTS user_pending_permissions ALTER COLUMN id TYPE int;\nALTER TABLE IF EXISTS repo_pending_permissions ALTER COLUMN user_ids_ints TYPE int[];\n\nALTER SEQUENCE IF EXISTS user_pending_permissions_id_seq RESTART;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648195639
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1648628900,
				"Name": "rename_localclone_worker_table",
				"UpQuery": "-- drop view\nDROP VIEW IF EXISTS gitserver_localclone_jobs_with_repo_name;\n\n-- drop the table\nDROP TABLE IF EXISTS gitserver_localclone_jobs;\n\n-- create the new table\nCREATE TABLE IF NOT EXISTS gitserver_relocator_jobs (\n    id                  SERIAL PRIMARY KEY,\n    state               text DEFAULT 'queued',\n    queued_at           timestamptz DEFAULT NOW(),\n    failure_message     text,\n    started_at          timestamp with time zone,\n    finished_at         timestamp with time zone,\n    process_after       timestamp with time zone,\n    num_resets          integer not null DEFAULT 0,\n    num_failures        integer not null DEFAULT 0,\n    last_heartbeat_at   timestamp with time zone,\n    execution_logs      json[],\n    worker_hostname     text not null DEFAULT '',\n\n    repo_id             integer not null,\n    source_hostname     text not null,\n    dest_hostname       text not null,\n    delete_source       boolean not null DEFAULT false\n);\n\n-- create the view\nCREATE OR REPLACE VIEW gitserver_relocator_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_relocator_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"DownQuery": "-- drop view\nDROP VIEW IF EXISTS gitserver_relocator_jobs_with_repo_name;\n\n-- drop the table\nDROP TABLE IF EXISTS gitserver_relocator_jobs;\n\n-- create the old table\nCREATE TABLE IF NOT EXISTS gitserver_localclone_jobs (\n    id                  SERIAL PRIMARY KEY,\n    state               text DEFAULT 'queued',\n    queued_at           timestamptz DEFAULT NOW(),\n    failure_message     text,\n    started_at          timestamp with time zone,\n    finished_at         timestamp with time zone,\n    process_after       timestamp with time zone,\n    num_resets          integer not null DEFAULT 0,\n    num_failures        integer not null DEFAULT 0,\n    last_heartbeat_at   timestamp with time zone,\n    execution_logs      json[],\n    worker_hostname     text not null DEFAULT '',\n\n    repo_id             integer not null,\n    source_hostname     text not null,\n    dest_hostname       text not null,\n    delete_source       boolean not null DEFAULT false\n);\n\n-- create the old view\nCREATE OR REPLACE VIEW gitserver_localclone_jobs_with_repo_name AS\n  SELECT glj.*, r.name AS repo_name\n  FROM gitserver_localclone_jobs glj\n  JOIN repo r ON r.id = glj.repo_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648195639
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649159359,
				"Name": "batch_spec_resolution_user_id",
				"UpQuery": "ALTER TABLE batch_spec_resolution_jobs\n    ADD COLUMN IF NOT EXISTS initiator_id integer,\n    ADD FOREIGN KEY (initiator_id) REFERENCES users(id) ON UPDATE CASCADE ON DELETE NO ACTION DEFERRABLE;\n\nUPDATE batch_spec_resolution_jobs SET initiator_id = (SELECT bs.user_id FROM batch_specs bs WHERE bs.id = batch_spec_id);",
				"DownQuery": "ALTER TABLE batch_spec_resolution_jobs\n    DROP COLUMN IF EXISTS initiator_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648524019,
					1648628900
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649269601,
				"Name": "remove unused code monitor columns",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\n--  * If you are modifying Postgres extensions, you must also declare \"privileged: true\"\n--    in the associated metadata.yaml file.\n\nALTER TABLE cm_trigger_jobs\n    DROP COLUMN IF EXISTS results;\nALTER TABLE cm_trigger_jobs\n    DROP COLUMN IF EXISTS num_results;",
				"DownQuery": "-- Undo the changes made in the up migration\n\nALTER TABLE cm_trigger_jobs\n    ADD COLUMN IF NOT EXISTS results BOOLEAN;\nALTER TABLE cm_trigger_jobs\n    ADD COLUMN IF NOT EXISTS num_results INTEGER;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648524019,
					1648628900
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649441222,
				"Name": "lsif_uploads_audit_logging",
				"UpQuery": "CREATE TABLE IF NOT EXISTS lsif_uploads_audit_logs (\n    -- log entry columns\n    log_timestamp       timestamptz DEFAULT NOW(),\n    record_deleted_at   timestamptz,\n    -- associated object columns\n    upload_id           integer not null,\n    commit              text not null,\n    root                text not null,\n    repository_id       integer not null,\n    uploaded_at         timestamptz not null,\n    indexer             text not null,\n    indexer_version     text,\n    upload_size         integer,\n    associated_index_id integer,\n    committed_at        timestamptz,\n    transition_columns  hstore[]\n);\n\nCOMMENT ON COLUMN lsif_uploads_audit_logs.log_timestamp IS 'Timestamp for this log entry.';\nCOMMENT ON COLUMN lsif_uploads_audit_logs.record_deleted_at IS 'Set once the upload this entry is associated with is deleted. Once NOW() - record_deleted_at is above a certain threshold, this log entry will be deleted.';\nCOMMENT ON COLUMN lsif_uploads_audit_logs.transition_columns IS 'Array of changes that occurred to the upload for this entry, in the form of {\"column\"=\u003e\"\u003ccolumn name\u003e\", \"old\"=\u003e\"\u003cprevious value\u003e\", \"new\"=\u003e\"\u003cnew value\u003e\"}.';\n\nCREATE INDEX IF NOT EXISTS lsif_uploads_audit_logs_upload_id ON lsif_uploads_audit_logs USING btree (upload_id);\nCREATE INDEX IF NOT EXISTS lsif_uploads_audit_logs_timestamp ON lsif_uploads_audit_logs USING brin (log_timestamp);\n\n-- CREATE TYPE IF NOT EXISTS is not a thing, so we must drop it here,\n-- but also all the functions that reference the type...\nDROP FUNCTION IF EXISTS func_row_to_lsif_uploads_transition_columns;\nDROP FUNCTION IF EXISTS func_lsif_uploads_transition_columns_diff;\nDROP TYPE IF EXISTS lsif_uploads_transition_columns;\n\nCREATE TYPE lsif_uploads_transition_columns AS (\n    state           text,\n    expired         boolean,\n    num_resets      integer,\n    num_failures    integer,\n    worker_hostname text,\n    committed_at    timestamptz\n);\n\nCOMMENT ON TYPE lsif_uploads_transition_columns IS 'A type containing the columns that make-up the set of tracked transition columns. Primarily used to create a nulled record due to `OLD` being unset in INSERT queries, and creating a nulled record with a subquery is not allowed.';\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        committed_at, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            NEW.committed_at, func_lsif_uploads_transition_columns_diff(\n                func_row_to_lsif_uploads_transition_columns(OLD),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_delete() RETURNS TRIGGER AS $$\n    BEGIN\n        UPDATE lsif_uploads_audit_logs\n        SET record_deleted_at = NOW()\n        WHERE upload_id IN (\n            SELECT id FROM OLD\n        );\n\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        committed_at, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            NEW.committed_at, func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_row_to_lsif_uploads_transition_columns(\n    rec record\n) RETURNS lsif_uploads_transition_columns AS $$\n    BEGIN\n        RETURN (rec.state, rec.expired, rec.num_resets, rec.num_failures, rec.worker_hostname, rec.committed_at);\n    END;\n$$ LANGUAGE plpgsql;\n\nCOMMENT ON FUNCTION func_lsif_uploads_insert IS 'Transforms a record from the lsif_uploads table into an `lsif_uploads_transition_columns` type variable.';\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_transition_columns_diff(\n    old lsif_uploads_transition_columns, new lsif_uploads_transition_columns\n) RETURNS hstore[] AS $$\n    BEGIN\n        -- array || NULL should be a noop, but that doesn't seem to be happening\n        -- hence array_remove here\n        RETURN array_remove(\n            ARRAY[]::hstore[] ||\n            CASE WHEN old.state IS DISTINCT FROM new.state THEN\n                hstore(ARRAY['column', 'state', 'old', old.state, 'new', new.state])\n                ELSE NULL\n            END ||\n            CASE WHEN old.expired IS DISTINCT FROM new.expired THEN\n                hstore(ARRAY['column', 'expired', 'old', old.expired::text, 'new', new.expired::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.num_resets IS DISTINCT FROM new.num_resets THEN\n                hstore(ARRAY['column', 'num_resets', 'old', old.num_resets::text, 'new', new.num_resets::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.num_failures IS DISTINCT FROM new.num_failures THEN\n                hstore(ARRAY['column', 'num_failures', 'old', old.num_failures::text, 'new', new.num_failures::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.worker_hostname IS DISTINCT FROM new.worker_hostname THEN\n                hstore(ARRAY['column', 'worker_hostname', 'old', old.worker_hostname, 'new', new.worker_hostname])\n                ELSE NULL\n            END ||\n            CASE WHEN old.committed_at IS DISTINCT FROM new.committed_at THEN\n                hstore(ARRAY['column', 'committed_at', 'old', old.committed_at::text, 'new', new.committed_at::text])\n                ELSE NULL\n            END,\n        NULL);\n    END;\n$$ LANGUAGE plpgsql;\n\nCOMMENT ON FUNCTION func_lsif_uploads_transition_columns_diff IS 'Diffs two `lsif_uploads_transition_columns` values into an array of hstores, where each hstore is in the format {\"column\"=\u003e\"\u003ccolumn name\u003e\", \"old\"=\u003e\"\u003cprevious value\u003e\", \"new\"=\u003e\"\u003cnew value\u003e\"}.';\n\n-- CREATE OR REPLACE only supported in Postgres 14+\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_update ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_delete ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_insert ON lsif_uploads;\n\nCREATE TRIGGER trigger_lsif_uploads_update\nBEFORE UPDATE OF state, num_resets, num_failures, worker_hostname, expired, committed_at\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_update();\n\nCREATE TRIGGER trigger_lsif_uploads_delete\nAFTER DELETE\nON lsif_uploads\nREFERENCING OLD TABLE AS OLD\nFOR EACH STATEMENT\nEXECUTE FUNCTION func_lsif_uploads_delete();\n\nCREATE TRIGGER trigger_lsif_uploads_insert\nAFTER INSERT\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_insert();",
				"DownQuery": "DROP TRIGGER IF EXISTS trigger_lsif_uploads_update ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_delete ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_insert ON lsif_uploads;\n\nDROP FUNCTION IF EXISTS func_lsif_uploads_update;\nDROP FUNCTION IF EXISTS func_lsif_uploads_delete;\nDROP FUNCTION IF EXISTS func_lsif_uploads_insert;\nDROP FUNCTION IF EXISTS func_lsif_uploads_transition_columns_diff;\nDROP FUNCTION IF EXISTS func_row_to_lsif_uploads_transition_columns;\n\nDROP TABLE IF EXISTS lsif_uploads_audit_logs;\n\nDROP INDEX IF EXISTS lsif_uploads_audit_logs_upload_id;\nDROP INDEX IF EXISTS lsif_uploads_audit_logs_timestamp;\n\nDROP TYPE IF EXISTS lsif_uploads_transition_columns;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649269601
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649759318,
				"Name": "change_default_invite_quota",
				"UpQuery": "ALTER TABLE IF EXISTS users ALTER COLUMN invite_quota SET DEFAULT 100;",
				"DownQuery": "-- Undo the changes made in the up migration\nALTER TABLE IF EXISTS users ALTER COLUMN invite_quota SET DEFAULT 15;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649269601
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649432863,
				"Name": "no hash for code monitor last searched",
				"UpQuery": "-- Perform migration here.\n--\n-- See /migrations/README.md. Highlights:\n--  * Make migrations idempotent (use IF EXISTS)\n--  * Make migrations backwards-compatible (old readers/writers must continue to work)\n--  * If you are using CREATE INDEX CONCURRENTLY, then make sure that only one statement\n--    is defined per file, and that each such statement is NOT wrapped in a transaction.\n--    Each such migration must also declare \"createIndexConcurrently: true\" in their\n--    associated metadata.yaml file.\n--  * If you are modifying Postgres extensions, you must also declare \"privileged: true\"\n--    in the associated metadata.yaml file.\n\nDELETE FROM cm_last_searched;\nALTER TABLE cm_last_searched\n    DROP CONSTRAINT IF EXISTS cm_last_searched_pkey,\n    DROP COLUMN IF EXISTS args_hash,\n    ADD COLUMN IF NOT EXISTS repo_id INTEGER NOT NULL REFERENCES repo(id) ON DELETE CASCADE,\n    ADD PRIMARY KEY (monitor_id, repo_id);",
				"DownQuery": "-- Undo the changes made in the up migration\n\nALTER TABLE cm_last_searched\n    DROP CONSTRAINT IF EXISTS cm_last_searched_pkey,\n    DROP COLUMN IF EXISTS repo_id,\n    ADD COLUMN IF NOT EXISTS args_hash bigint NOT NULL,\n    ADD PRIMARY KEY (monitor_id, args_hash);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1648524019,
					1648628900
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1650456734,
				"Name": "configuration_policies_audit_logging",
				"UpQuery": "CREATE TABLE IF NOT EXISTS configuration_policies_audit_logs (\n    -- log entry columns\n    log_timestamp      timestamptz DEFAULT clock_timestamp(),\n    record_deleted_at  timestamptz,\n    -- associated object columns\n    policy_id          integer not null,\n    transition_columns hstore[]\n);\n\nCOMMENT ON COLUMN configuration_policies_audit_logs.log_timestamp IS 'Timestamp for this log entry.';\nCOMMENT ON COLUMN configuration_policies_audit_logs.record_deleted_at IS 'Set once the upload this entry is associated with is deleted. Once NOW() - record_deleted_at is above a certain threshold, this log entry will be deleted.';\nCOMMENT ON COLUMN configuration_policies_audit_logs.transition_columns IS 'Array of changes that occurred to the upload for this entry, in the form of {\"column\"=\u003e\"\u003ccolumn name\u003e\", \"old\"=\u003e\"\u003cprevious value\u003e\", \"new\"=\u003e\"\u003cnew value\u003e\"}.';\n\nCREATE INDEX IF NOT EXISTS configuration_policies_audit_logs_policy_id ON configuration_policies_audit_logs USING btree (policy_id);\nCREATE INDEX IF NOT EXISTS configuration_policies_audit_logs_timestamp ON configuration_policies_audit_logs USING brin (log_timestamp);\n\n-- CREATE TYPE IF NOT EXISTS is not a thing, so we must drop it here,\n-- but also all the functions that reference the type...\nDROP FUNCTION IF EXISTS func_row_to_configuration_policies_transition_columns;\nDROP FUNCTION IF EXISTS func_configuration_policies_transition_columns_diff;\nDROP TYPE IF EXISTS configuration_policies_transition_columns;\n\nCREATE TYPE configuration_policies_transition_columns AS (\n    name                        text,\n    type                        text,\n    pattern                     text,\n    retention_enabled           boolean,\n    retention_duration_hours    integer,\n    retain_intermediate_commits boolean,\n    indexing_enabled            boolean,\n    index_commit_max_age_hours  integer,\n    index_intermediate_commits  boolean,\n    protected                   boolean,\n    repository_patterns         text[]\n);\n\nCOMMENT ON TYPE configuration_policies_transition_columns IS 'A type containing the columns that make-up the set of tracked transition columns. Primarily used to create a nulled record due to `OLD` being unset in INSERT queries, and creating a nulled record with a subquery is not allowed.';\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_configuration_policies_transition_columns_diff(\n            func_row_to_configuration_policies_transition_columns(OLD),\n            func_row_to_configuration_policies_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO configuration_policies_audit_logs\n            (policy_id, transition_columns)\n            VALUES (\n                NEW.id,\n                diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_delete() RETURNS TRIGGER AS $$\n    BEGIN\n        UPDATE configuration_policies_audit_logs\n        SET record_deleted_at = NOW()\n        WHERE policy_id IN (\n            SELECT id FROM OLD\n        );\n\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO configuration_policies_audit_logs\n        (policy_id, transition_columns)\n        VALUES (\n            NEW.id,\n            func_configuration_policies_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_configuration_policies_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\n\nCREATE OR REPLACE FUNCTION func_row_to_configuration_policies_transition_columns(\n    rec record\n) RETURNS configuration_policies_transition_columns AS $$\n    BEGIN\n        RETURN (\n            rec.name, rec.type, rec.pattern,\n            rec.retention_enabled, rec.retention_duration_hours, rec.retain_intermediate_commits,\n            rec.indexing_enabled, rec.index_commit_max_age_hours, rec.index_intermediate_commits,\n            rec.protected, rec.repository_patterns);\n    END;\n$$ LANGUAGE plpgsql;\n\nCOMMENT ON FUNCTION func_configuration_policies_insert IS 'Transforms a record from the configuration_policies table into an `configuration_policies_transition_columns` type variable.';\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_transition_columns_diff(\n    old configuration_policies_transition_columns, new configuration_policies_transition_columns\n) RETURNS hstore[] AS $$\n    BEGIN\n        -- array || NULL should be a noop, but that doesn't seem to be happening\n        -- hence array_remove here\n        RETURN array_remove(\n            ARRAY[]::hstore[] ||\n            CASE WHEN old.name IS DISTINCT FROM new.name THEN\n                hstore(ARRAY['column', 'name', 'old', old.name, 'new', new.name])\n                ELSE NULL\n            END ||\n            CASE WHEN old.type IS DISTINCT FROM new.type THEN\n                hstore(ARRAY['column', 'type', 'old', old.type, 'new', new.type])\n                ELSE NULL\n            END ||\n            CASE WHEN old.pattern IS DISTINCT FROM new.pattern THEN\n                hstore(ARRAY['column', 'pattern', 'old', old.pattern, 'new', new.pattern])\n                ELSE NULL\n            END ||\n            CASE WHEN old.retention_enabled IS DISTINCT FROM new.retention_enabled THEN\n                hstore(ARRAY['column', 'retention_enabled', 'old', old.retention_enabled::text, 'new', new.retention_enabled::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.retention_duration_hours IS DISTINCT FROM new.retention_duration_hours THEN\n                hstore(ARRAY['column', 'retention_duration_hours', 'old', old.retention_duration_hours::text, 'new', new.retention_duration_hours::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.indexing_enabled IS DISTINCT FROM new.indexing_enabled THEN\n                hstore(ARRAY['column', 'indexing_enabled', 'old', old.indexing_enabled::text, 'new', new.indexing_enabled::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.index_commit_max_age_hours IS DISTINCT FROM new.index_commit_max_age_hours THEN\n                hstore(ARRAY['column', 'index_commit_max_age_hours', 'old', old.index_commit_max_age_hours::text, 'new', new.index_commit_max_age_hours::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.index_intermediate_commits IS DISTINCT FROM new.index_intermediate_commits THEN\n                hstore(ARRAY['column', 'index_intermediate_commits', 'old', old.index_intermediate_commits::text, 'new', new.index_intermediate_commits::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.protected IS DISTINCT FROM new.protected THEN\n                hstore(ARRAY['column', 'protected', 'old', old.protected::text, 'new', new.protected::text])\n                ELSE NULL\n            END ||\n            CASE WHEN old.repository_patterns IS DISTINCT FROM new.repository_patterns THEN\n                hstore(ARRAY['column', 'repository_patterns', 'old', old.repository_patterns::text, 'new', new.repository_patterns::text])\n                ELSE NULL\n            END,\n        NULL);\n    END;\n$$ LANGUAGE plpgsql;\n\nCOMMENT ON FUNCTION func_configuration_policies_transition_columns_diff IS 'Diffs two `configuration_policies_transition_columns` values into an array of hstores, where each hstore is in the format {\"column\"=\u003e\"\u003ccolumn name\u003e\", \"old\"=\u003e\"\u003cprevious value\u003e\", \"new\"=\u003e\"\u003cnew value\u003e\"}.';\n\n-- CREATE OR REPLACE only supported in Postgres 14+\nDROP TRIGGER IF EXISTS trigger_configuration_policies_update ON lsif_configuration_policies;\nDROP TRIGGER IF EXISTS trigger_configuration_policies_delete ON lsif_configuration_policies;\nDROP TRIGGER IF EXISTS trigger_configuration_policies_insert ON lsif_configuration_policies;\n\nCREATE TRIGGER trigger_configuration_policies_update\nBEFORE UPDATE OF name, pattern, retention_enabled, retention_duration_hours, type, retain_intermediate_commits\nON lsif_configuration_policies\nFOR EACH ROW\nEXECUTE FUNCTION func_configuration_policies_update();\n\nCREATE TRIGGER trigger_configuration_policies_delete\nAFTER DELETE\nON lsif_configuration_policies\nREFERENCING OLD TABLE AS OLD\nFOR EACH STATEMENT\nEXECUTE FUNCTION func_configuration_policies_delete();\n\nCREATE TRIGGER trigger_configuration_policies_insert\nAFTER INSERT\nON lsif_configuration_policies\nFOR EACH ROW\nEXECUTE FUNCTION func_configuration_policies_insert();",
				"DownQuery": "DROP TRIGGER IF EXISTS trigger_configuration_policies_update ON lsif_configuration_policies;\nDROP TRIGGER IF EXISTS trigger_configuration_policies_delete ON lsif_configuration_policies;\nDROP TRIGGER IF EXISTS trigger_configuration_policies_insert ON lsif_configuration_policies;\n\nDROP FUNCTION IF EXISTS func_configuration_policies_update;\nDROP FUNCTION IF EXISTS func_configuration_policies_delete;\nDROP FUNCTION IF EXISTS func_configuration_policies_insert;\nDROP FUNCTION IF EXISTS func_configuration_policies_transition_columns_diff;\nDROP FUNCTION IF EXISTS func_row_to_configuration_policies_transition_columns;\n\nDROP TABLE IF EXISTS configuration_policies_audit_logs;\n\nDROP INDEX IF EXISTS configuration_policies_audit_logs_upload_id;\nDROP INDEX IF EXISTS configuration_policies_audit_logs_timestamp;\n\nDROP TYPE IF EXISTS configuration_policies_transition_columns;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649432863,
					1649441222,
					1649759318
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1650637472,
				"Name": "Add codeintel_langugage_support_requests table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_langugage_support_requests (\n    id SERIAL,\n    user_id integer NOT NULL,\n    language_id text NOT NULL\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_langugage_support_requests_user_id_language ON codeintel_langugage_support_requests(user_id, language_id);",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_langugage_support_requests;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649159359,
					1649432863,
					1649441222,
					1649759318
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1651061363,
				"Name": "lsif_uploads_audit_logging_reason",
				"UpQuery": "ALTER TABLE lsif_uploads_audit_logs\nADD COLUMN IF NOT EXISTS reason text DEFAULT '',\nDROP COLUMN IF EXISTS committed_at;\n\nCOMMENT ON COLUMN lsif_uploads_audit_logs.reason IS 'The reason/source for this entry.';\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_lsif_uploads_transition_columns_diff(\n            func_row_to_lsif_uploads_transition_columns(OLD),\n            func_row_to_lsif_uploads_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO lsif_uploads_audit_logs\n            (reason, upload_id, commit, root, repository_id, uploaded_at,\n            indexer, indexer_version, upload_size, associated_index_id,\n            transition_columns)\n            VALUES (\n                COALESCE(current_setting('codeintel.lsif_uploads_audit.reason', true), ''),\n                NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n                NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n                diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\n\n-- CREATE OR REPLACE only supported in Postgres 14+\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_update ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_insert ON lsif_uploads;\n\nCREATE TRIGGER trigger_lsif_uploads_update\nBEFORE UPDATE OF state, num_resets, num_failures, worker_hostname, expired, committed_at\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_update();\n\nCREATE TRIGGER trigger_lsif_uploads_insert\nAFTER INSERT\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_insert();",
				"DownQuery": "ALTER TABLE\n    IF EXISTS lsif_uploads_audit_logs\n    DROP COLUMN IF EXISTS reason,\n    ADD COLUMN IF NOT EXISTS committed_at timestamptz;\n\n-- Revert functions to previous version\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        committed_at, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            NEW.committed_at, func_lsif_uploads_transition_columns_diff(\n                func_row_to_lsif_uploads_transition_columns(OLD),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        committed_at, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            NEW.committed_at, func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\n-- CREATE OR REPLACE only supported in Postgres 14+\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_update ON lsif_uploads;\nDROP TRIGGER IF EXISTS trigger_lsif_uploads_insert ON lsif_uploads;\n\nCREATE TRIGGER trigger_lsif_uploads_update\nBEFORE UPDATE OF state, num_resets, num_failures, worker_hostname, expired, committed_at\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_update();\n\nCREATE TRIGGER trigger_lsif_uploads_insert\nAFTER INSERT\nON lsif_uploads\nFOR EACH ROW\nEXECUTE FUNCTION func_lsif_uploads_insert();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650637472
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1651077257,
				"Name": "lsif_dirty_repo_timestamp",
				"UpQuery": "ALTER TABLE\n    lsif_dirty_repositories\nADD\n    COLUMN IF NOT EXISTS set_dirty_at timestamptz NOT NULL DEFAULT NOW();",
				"DownQuery": "ALTER TABLE\n    IF EXISTS lsif_dirty_repositories DROP COLUMN IF EXISTS set_dirty_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650637472
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1651159431,
				"Name": "fix-maven-dependency-repos-name",
				"UpQuery": "UPDATE lsif_dependency_repos\nSET name = replace(regexp_replace(name, '^maven/', ''), '/', ':')\nWHERE scheme = 'semanticdb'\nAND name LIKE 'maven/%';\n\nDELETE FROM lsif_dependency_repos\nWHERE scheme = 'semanticdb'\nAND (name LIKE '%:%:%' OR name LIKE 'jdk:%' OR name LIKE 'jdk/%');",
				"DownQuery": "-- Undo the changes made in the up migration",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1651077257
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652143849,
				"Name": "drop_constraint_from_filter_column_in_lsif_references_table",
				"UpQuery": "ALTER TABLE IF EXISTS lsif_references\n    ALTER COLUMN filter DROP NOT NULL;",
				"DownQuery": "-- Undo the changes made in the up migration\nALTER TABLE IF EXISTS lsif_references\n    ALTER COLUMN filter SET NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650456734,
					1651061363,
					1651159431
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652175864,
				"Name": "add-unrestricted-to-repo-permissions",
				"UpQuery": "ALTER TABLE\n    repo_permissions\nADD\n    COLUMN IF NOT EXISTS unrestricted boolean NOT NULL DEFAULT false;\n\nCREATE INDEX IF NOT EXISTS repo_permissions_unrestricted_true_idx ON repo_permissions\n    USING btree (unrestricted) WHERE unrestricted;",
				"DownQuery": "ALTER TABLE\n    repo_permissions\n    DROP\n        COLUMN IF EXISTS unrestricted;\n\nDROP INDEX IF EXISTS repo_permissions_unrestricted_true_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650456734,
					1651061363,
					1651159431
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652228814,
				"Name": "index_bitbucket_cloud_commit",
				"UpQuery": "CREATE INDEX IF NOT EXISTS\n    changesets_bitbucket_cloud_metadata_source_commit_idx\nON\n    changesets ((metadata-\u003e'source'-\u003e'commit'-\u003e\u003e'hash'))",
				"DownQuery": "DROP INDEX IF EXISTS\n    changesets_bitbucket_cloud_metadata_source_commit_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652175864
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652189866,
				"Name": "Add lockfiles tables",
				"UpQuery": "CREATE TABLE IF NOT EXISTS codeintel_lockfiles (\n    id SERIAL PRIMARY KEY,\n    repository_id integer NOT NULL,\n    commit_bytea bytea NOT NULL,\n    codeintel_lockfile_reference_ids integer [] NOT NULL\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfiles_repository_id_commit_bytea ON codeintel_lockfiles USING btree (repository_id, commit_bytea);\n\nCREATE INDEX IF NOT EXISTS codeintel_lockfiles_codeintel_lockfile_reference_ids ON codeintel_lockfiles USING GIN (\n    codeintel_lockfile_reference_ids gin__int_ops\n);\n\nCOMMENT ON TABLE codeintel_lockfiles IS 'Associates a repository-commit pair with the set of repository-level dependencies parsed from lockfiles.';\n\nCOMMENT ON COLUMN codeintel_lockfiles.commit_bytea IS 'A 40-char revhash. Note that this commit may not be resolvable in the future.';\n\nCOMMENT ON COLUMN codeintel_lockfiles.codeintel_lockfile_reference_ids IS 'A key to a resolved repository name-revspec pair. Not all repository names and revspecs are resolvable.';\n\nCREATE TABLE IF NOT EXISTS codeintel_lockfile_references (\n    id SERIAL PRIMARY KEY,\n    repository_name text NOT NULL,\n    revspec text NOT NULL,\n    package_scheme text NOT NULL,\n    package_name text NOT NULL,\n    package_version text NOT NULL,\n    repository_id integer,\n    commit_bytea bytea\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_name_revspec_package ON codeintel_lockfile_references USING btree (\n    repository_name,\n    revspec,\n    package_scheme,\n    package_name,\n    package_version\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_id_commit_bytea ON codeintel_lockfile_references USING btree (repository_id, commit_bytea)\nWHERE\n    repository_id IS NOT NULL\n    AND commit_bytea IS NOT NULL;\n\nCOMMENT ON TABLE codeintel_lockfile_references IS 'Tracks a lockfile dependency that might be resolvable to a specific repository-commit pair.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.repository_name IS 'Encodes `reposource.PackageDependency.RepoName`. A name that is \"globally unique\" for a Sourcegraph instance. Used in `repo:...` queries.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.revspec IS 'Encodes `reposource.PackageDependency.GitTagFromVersion`. Returns the git tag associated with the given dependency version, used in `rev:` or `repo:foo@rev` queries.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.package_scheme IS 'Encodes `reposource.PackageDependency.Scheme`. The scheme of the dependency (e.g., semanticdb, npm).';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.package_name IS 'Encodes `reposource.PackageDependency.PackageSyntax`. The name of the dependency as used by the package manager, excluding version information.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.package_version IS 'Encodes `reposource.PackageDependency.PackageVersion`. The version of the package.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.repository_id IS 'The identifier of the repo that resolves the associated name, if it is resolvable on this instance.';\n\nCOMMENT ON COLUMN codeintel_lockfile_references.commit_bytea IS 'The resolved 40-char revhash of the associated revspec, if it is resolvable on this instance.';",
				"DownQuery": "DROP TABLE IF EXISTS codeintel_lockfile_references;\n\nDROP TABLE IF EXISTS codeintel_lockfiles;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1650456734,
					1651061363,
					1651159431
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652707934,
				"Name": "add last_check_at to codeintel_lockfile_references",
				"UpQuery": "DROP INDEX IF EXISTS codeintel_lockfile_references_repository_id_commit_bytea;\n\nCREATE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_id_commit_bytea ON codeintel_lockfile_references USING btree (repository_id, commit_bytea)\nWHERE\n    repository_id IS NOT NULL\n    AND commit_bytea IS NOT NULL;\n\nALTER TABLE\n    codeintel_lockfile_references\nADD\n    COLUMN IF NOT EXISTS last_check_at timestamptz;\n\nCOMMENT ON COLUMN codeintel_lockfile_references.last_check_at IS 'Timestamp when background job last checked this row for repository resolution';\n\nCREATE INDEX IF NOT EXISTS codeintel_lockfile_references_last_check_at ON codeintel_lockfile_references USING btree (last_check_at);",
				"DownQuery": "ALTER TABLE\n    codeintel_lockfile_references\nDROP\n    COLUMN IF EXISTS last_check_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652143849,
					1652175864,
					1652189866
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652946496,
				"Name": "add_trigger_to_insert_gitserver_repo",
				"UpQuery": "-- batch insert repos which don't have a corresponding row in gitserver_repos table\nINSERT INTO gitserver_repos(repo_id, shard_id)\nSELECT repo.id, ''\nFROM repo\nLEFT JOIN gitserver_repos gr\nON repo.id = gr.repo_id\nWHERE gr.repo_id IS NULL\nON CONFLICT (repo_id) DO NOTHING;\n\nCREATE OR REPLACE FUNCTION func_insert_gitserver_repo() RETURNS TRIGGER AS $$\nBEGIN\nINSERT INTO gitserver_repos\n(repo_id, shard_id)\nVALUES (NEW.id, '');\nRETURN NULL;\nEND;\n$$ LANGUAGE plpgsql;\n\nDROP TRIGGER IF EXISTS trigger_gitserver_repo_insert on repo;\n\nCREATE TRIGGER trigger_gitserver_repo_insert\n    AFTER INSERT\n    ON repo\n    FOR EACH ROW\n    EXECUTE FUNCTION func_insert_gitserver_repo();",
				"DownQuery": "DROP TRIGGER IF EXISTS trigger_gitserver_repo_insert ON repo;\nDROP FUNCTION IF EXISTS func_insert_gitserver_repo;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652228814,
					1652707934
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1652964210,
				"Name": "add last_lockfile_scan table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS last_lockfile_scan (\n    repository_id integer NOT NULL PRIMARY KEY,\n    last_lockfile_scan_at timestamp with time zone NOT NULL\n);\n\nCOMMENT ON TABLE last_lockfile_scan IS 'Tracks the last time repository was checked for lockfile indexing.';\n\nCOMMENT ON COLUMN last_lockfile_scan.last_lockfile_scan_at IS 'The last time this repository was considered for lockfile indexing.';",
				"DownQuery": "DROP TABLE IF EXISTS last_lockfile_scan;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652228814,
					1652707934
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653334014,
				"Name": "Remove default from out_of_band_migrations created timestamp",
				"UpQuery": "ALTER TABLE\n    out_of_band_migrations\nALTER COLUMN\n    created DROP DEFAULT;",
				"DownQuery": "ALTER TABLE\n    out_of_band_migrations\nALTER COLUMN\n    created\nSET\n    DEFAULT NOW();",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652964210
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653472246,
				"Name": "add_nps_survey_fields",
				"UpQuery": "ALTER TABLE survey_responses\n  ADD COLUMN IF NOT EXISTS use_cases text[],\n  ADD COLUMN IF NOT EXISTS other_use_case text;",
				"DownQuery": "ALTER TABLE survey_responses\n  DROP COLUMN IF EXISTS use_cases,\n  DROP COLUMN IF EXISTS other_use_case;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652946496,
					1653334014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653479179,
				"Name": "audit_log_op_and_seq",
				"UpQuery": "DO $$\nBEGIN\n    IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'audit_log_operation') THEN\n        -- delete is known by record_deleted_at\n        CREATE TYPE audit_log_operation AS ENUM('create', 'modify', 'delete');\n    END IF;\nEND\n$$;\n\nCREATE SEQUENCE IF NOT EXISTS lsif_uploads_audit_logs_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\nCREATE SEQUENCE IF NOT EXISTS configuration_policies_audit_logs_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\n-- table not been used yet\nTRUNCATE TABLE lsif_uploads_audit_logs;\nTRUNCATE TABLE configuration_policies_audit_logs;\n\nALTER TABLE lsif_uploads_audit_logs\nADD COLUMN IF NOT EXISTS sequence BIGINT NOT NULL DEFAULT nextval('lsif_uploads_audit_logs_seq'::regclass),\nADD COLUMN IF NOT EXISTS operation audit_log_operation NOT NULL;\n\nALTER TABLE configuration_policies_audit_logs\nADD COLUMN IF NOT EXISTS sequence BIGINT NOT NULL DEFAULT nextval('configuration_policies_audit_logs_seq'::regclass),\nADD COLUMN IF NOT EXISTS operation audit_log_operation NOT NULL;\n\nALTER SEQUENCE lsif_uploads_audit_logs_seq OWNED BY lsif_uploads_audit_logs.sequence;\nALTER SEQUENCE configuration_policies_audit_logs_seq OWNED BY configuration_policies_audit_logs.sequence;\n\n-- Start replace triggers\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_lsif_uploads_transition_columns_diff(\n            func_row_to_lsif_uploads_transition_columns(OLD),\n            func_row_to_lsif_uploads_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO lsif_uploads_audit_logs\n            (reason, upload_id, commit, root, repository_id, uploaded_at,\n            indexer, indexer_version, upload_size, associated_index_id,\n            operation, transition_columns)\n            VALUES (\n                COALESCE(current_setting('codeintel.lsif_uploads_audit.reason', true), ''),\n                NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n                NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n                'modify', diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        operation, transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            'create', func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_configuration_policies_transition_columns_diff(\n            func_row_to_configuration_policies_transition_columns(OLD),\n            func_row_to_configuration_policies_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO configuration_policies_audit_logs\n            (policy_id, operation, transition_columns)\n            VALUES (NEW.id, 'modify', diff);\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO configuration_policies_audit_logs\n        (policy_id, operation, transition_columns)\n        VALUES (\n            NEW.id, 'create',\n            func_configuration_policies_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_configuration_policies_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\n-- End replace triggers",
				"DownQuery": "ALTER TABLE lsif_uploads_audit_logs\nDROP COLUMN IF EXISTS sequence,\nDROP COLUMN IF EXISTS operation;\n\nDROP SEQUENCE IF EXISTS lsif_uploads_audit_logs_seq;\n\nALTER TABLE configuration_policies_audit_logs\nDROP COLUMN IF EXISTS sequence,\nDROP COLUMN IF EXISTS operation;\n\nDROP SEQUENCE IF EXISTS configuration_policies_audit_logs_seq;\n\nDROP TYPE IF EXISTS audit_log_operation;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_configuration_policies_transition_columns_diff(\n            func_row_to_configuration_policies_transition_columns(OLD),\n            func_row_to_configuration_policies_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO configuration_policies_audit_logs\n            (policy_id, transition_columns)\n            VALUES (\n                NEW.id,\n                diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_configuration_policies_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO configuration_policies_audit_logs\n        (policy_id, transition_columns)\n        VALUES (\n            NEW.id,\n            func_configuration_policies_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_configuration_policies_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_update() RETURNS TRIGGER AS $$\n    DECLARE\n        diff hstore[];\n    BEGIN\n        diff = func_lsif_uploads_transition_columns_diff(\n            func_row_to_lsif_uploads_transition_columns(OLD),\n            func_row_to_lsif_uploads_transition_columns(NEW)\n        );\n\n        IF (array_length(diff, 1) \u003e 0) THEN\n            INSERT INTO lsif_uploads_audit_logs\n            (reason, upload_id, commit, root, repository_id, uploaded_at,\n            indexer, indexer_version, upload_size, associated_index_id,\n            transition_columns)\n            VALUES (\n                COALESCE(current_setting('codeintel.lsif_uploads_audit.reason', true), ''),\n                NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n                NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n                diff\n            );\n        END IF;\n\n        RETURN NEW;\n    END;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION func_lsif_uploads_insert() RETURNS TRIGGER AS $$\n    BEGIN\n        INSERT INTO lsif_uploads_audit_logs\n        (upload_id, commit, root, repository_id, uploaded_at,\n        indexer, indexer_version, upload_size, associated_index_id,\n        transition_columns)\n        VALUES (\n            NEW.id, NEW.commit, NEW.root, NEW.repository_id, NEW.uploaded_at,\n            NEW.indexer, NEW.indexer_version, NEW.upload_size, NEW.associated_index_id,\n            func_lsif_uploads_transition_columns_diff(\n                (NULL, NULL, NULL, NULL, NULL, NULL),\n                func_row_to_lsif_uploads_transition_columns(NEW)\n            )\n        );\n        RETURN NULL;\n    END;\n$$ LANGUAGE plpgsql;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652946496,
					1653334014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1649253538,
				"Name": "batch_spec_resolution_user_id_non_null",
				"UpQuery": "UPDATE batch_spec_resolution_jobs SET initiator_id = (SELECT bs.user_id FROM batch_specs bs WHERE bs.id = batch_spec_id);\n\nALTER TABLE batch_spec_resolution_jobs ALTER COLUMN initiator_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE batch_spec_resolution_jobs ALTER COLUMN initiator_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653479179
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654116265,
				"Name": "add_unique_index_to_external_services",
				"UpQuery": "CREATE UNIQUE INDEX IF NOT EXISTS external_services_unique_kind_org_id ON external_services (kind, namespace_org_id) WHERE (deleted_at IS NULL AND namespace_user_id IS NULL AND namespace_org_id IS NOT NULL);\nCREATE UNIQUE INDEX IF NOT EXISTS external_services_unique_kind_user_id ON external_services (kind, namespace_user_id) WHERE (deleted_at IS NULL AND namespace_org_id IS NULL AND namespace_user_id IS NOT NULL);",
				"DownQuery": "DROP INDEX IF EXISTS external_services_unique_kind_org_id;\nDROP INDEX IF EXISTS external_services_unique_kind_user_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653479179
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654168174,
				"Name": "add_explicit_permissions_bitbucket_projects_jobs_table",
				"UpQuery": "CREATE TABLE IF NOT EXISTS explicit_permissions_bitbucket_projects_jobs (\n    id SERIAL PRIMARY KEY,\n    state text DEFAULT 'queued',\n    failure_message text,\n    queued_at timestamp with time zone DEFAULT NOW(),\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer not null default 0,\n    num_failures integer not null default 0,\n    last_heartbeat_at timestamp with time zone,\n    execution_logs json [],\n    worker_hostname text not null default '',\n    -- additional columns\n    project_key text not null,\n    external_service_id integer not null,\n    permissions json [],\n    unrestricted boolean not null default false,\n    CHECK (\n        (\n            permissions IS NOT NULL\n            AND unrestricted IS false\n        )\n        OR (\n            permissions IS NULL\n            AND unrestricted IS true\n        )\n    )\n);",
				"DownQuery": "DROP TABLE IF EXISTS explicit_permissions_bitbucket_projects_jobs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653479179
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655226733,
				"Name": "hstore_aggregate_func",
				"UpQuery": "CREATE OR REPLACE FUNCTION merge_audit_log_transitions(internal hstore, arrayhstore hstore[]) RETURNS hstore AS $$\n    DECLARE\n        trans hstore;\n    BEGIN\n      FOREACH trans IN ARRAY arrayhstore\n      LOOP\n          internal := internal || hstore(trans-\u003e'column', trans-\u003e'new');\n      END LOOP;\n\n      RETURN internal;\n    END;\n$$ LANGUAGE plpgsql IMMUTABLE;\n\nCREATE OR REPLACE AGGREGATE snapshot_transition_columns(HSTORE[]) (\n    SFUNC = merge_audit_log_transitions,\n    STYPE = HSTORE,\n    INITCOND = ''\n);",
				"DownQuery": "DROP AGGREGATE IF EXISTS snapshot_transition_columns(HSTORE[]);\n\nDROP FUNCTION IF EXISTS merge_audit_log_transitions;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654116265,
					1654168174
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653524883,
				"Name": "Create view for batch spec workspace execution worker",
				"UpQuery": "ALTER TABLE batch_spec_workspace_execution_jobs ADD COLUMN IF NOT EXISTS user_id INTEGER;\n\nUPDATE batch_spec_workspace_execution_jobs exec SET user_id = (\n    SELECT spec.user_id\n    FROM batch_spec_workspaces AS workspace\n    JOIN batch_specs spec ON spec.id = workspace.batch_spec_id\n    WHERE workspace.id = exec.batch_spec_workspace_id\n);\n\nCREATE INDEX IF NOT EXISTS batch_spec_workspace_execution_jobs_user_id ON batch_spec_workspace_execution_jobs (user_id);\n\nCREATE INDEX IF NOT EXISTS batch_spec_workspace_execution_jobs_state ON batch_spec_workspace_execution_jobs (state);\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH user_queues AS (\n    SELECT\n        exec.user_id,\n        MAX(exec.started_at) AS latest_dequeue\n    FROM batch_spec_workspace_execution_jobs AS exec\n    GROUP BY exec.user_id\n),\n-- We are creating this materialized CTE because PostgreSQL doesn't allow `FOR UPDATE` with window functions.\n-- Materializing it makes sure that the view query is not inlined into the FOR UPDATE select the Dequeue method\n-- performs.\nmaterialized_queue_candidates AS MATERIALIZED (\n    SELECT\n        exec.*,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN user_queues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    ROW_NUMBER() OVER () AS place_in_global_queue, materialized_queue_candidates.*\nFROM materialized_queue_candidates;",
				"DownQuery": "DROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nALTER TABLE batch_spec_workspace_execution_jobs DROP COLUMN IF EXISTS user_id;\n\nDROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_user_id;\n\nDROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653334014,
					1653479179
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654770608,
				"Name": "workspace_user_id_non_nullable",
				"UpQuery": "UPDATE batch_spec_workspace_execution_jobs exec SET user_id = (\n    SELECT spec.user_id\n    FROM batch_spec_workspaces AS workspace\n    JOIN batch_specs spec ON spec.id = workspace.batch_spec_id\n    WHERE workspace.id = exec.batch_spec_workspace_id\n);\n\nALTER TABLE batch_spec_workspace_execution_jobs ALTER COLUMN user_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE batch_spec_workspace_execution_jobs ALTER COLUMN user_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653524883,
					1654116265,
					1654168174
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654848945,
				"Name": "add_explicit_permissions_bitbucket_projects_jobs_index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS explicit_permissions_bitbucket_projects_jobs_project_key_external_service_id_state_idx ON explicit_permissions_bitbucket_projects_jobs (project_key, external_service_id, state);",
				"DownQuery": "DROP INDEX IF EXISTS explicit_permissions_bitbucket_projects_jobs_project_key_external_service_id_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653524883,
					1654116265,
					1654168174
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1654872407,
				"Name": "fast_cascade_delete_batch_specs_1",
				"UpQuery": "-- Create index for foreign key reverse lookups. This is required for cascading deletes.\nCREATE INDEX CONCURRENTLY IF NOT EXISTS changeset_specs_batch_spec_id ON changeset_specs (batch_spec_id);",
				"DownQuery": "DROP INDEX IF EXISTS changeset_specs_batch_spec_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654848945
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changeset_specs",
					"IndexName": "changeset_specs_batch_spec_id"
				}
			},
			{
				"ID": 1654874148,
				"Name": "fast_cascade_delete_batch_specs_2",
				"UpQuery": "-- Create index for foreign key reverse lookups. This is required for cascading deletes.\nCREATE INDEX CONCURRENTLY IF NOT EXISTS batch_spec_workspaces_batch_spec_id ON batch_spec_workspaces (batch_spec_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspaces_batch_spec_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654872407
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "batch_spec_workspaces",
					"IndexName": "batch_spec_workspaces_batch_spec_id"
				}
			},
			{
				"ID": 1654874153,
				"Name": "fast_cascade_delete_batch_specs_3",
				"UpQuery": "-- Create index for foreign key reverse lookups. This is required for cascading deletes.\nCREATE INDEX CONCURRENTLY IF NOT EXISTS batch_spec_workspace_execution_jobs_batch_spec_workspace_id ON batch_spec_workspace_execution_jobs (batch_spec_workspace_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_batch_spec_workspace_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654874148
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "batch_spec_workspace_execution_jobs",
					"IndexName": "batch_spec_workspace_execution_jobs_batch_spec_workspace_id"
				}
			},
			{
				"ID": 1655037388,
				"Name": "faster_changeset_spec_cleanup_1",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS changeset_specs_created_at ON changeset_specs (created_at);",
				"DownQuery": "DROP INDEX IF EXISTS changeset_specs_created_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654874153
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changeset_specs",
					"IndexName": "changeset_specs_created_at"
				}
			},
			{
				"ID": 1655037391,
				"Name": "faster_changeset_spec_cleanup_2",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS changesets_changeset_specs ON changesets (current_spec_id, previous_spec_id);",
				"DownQuery": "DROP INDEX IF EXISTS changesets_changeset_specs;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655037388
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changesets",
					"IndexName": "changesets_changeset_specs"
				}
			},
			{
				"ID": 1655067139,
				"Name": "fixup_worker_fairness_view",
				"UpQuery": "DROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH user_queues AS (\n    SELECT\n        exec.user_id,\n        MAX(exec.started_at) AS latest_dequeue\n    FROM batch_spec_workspace_execution_jobs AS exec\n    GROUP BY exec.user_id\n),\nqueue_candidates AS (\n    SELECT\n        exec.id,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN user_queues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    queue_candidates.id, ROW_NUMBER() OVER () AS place_in_global_queue, queue_candidates.place_in_user_queue\nFROM queue_candidates;\n\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.*,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);",
				"DownQuery": "DROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH user_queues AS (\n    SELECT\n        exec.user_id,\n        MAX(exec.started_at) AS latest_dequeue\n    FROM batch_spec_workspace_execution_jobs AS exec\n    GROUP BY exec.user_id\n),\n-- We are creating this materialized CTE because PostgreSQL doesn't allow `FOR UPDATE` with window functions.\n-- Materializing it makes sure that the view query is not inlined into the FOR UPDATE select the Dequeue method\n-- performs.\nmaterialized_queue_candidates AS MATERIALIZED (\n    SELECT\n        exec.*,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN user_queues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    ROW_NUMBER() OVER () AS place_in_global_queue, materialized_queue_candidates.*\nFROM materialized_queue_candidates;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654874153
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655128668,
				"Name": "add indices to explicit_permissions_bitbucket_projects_jobs table",
				"UpQuery": "CREATE INDEX IF NOT EXISTS explicit_permissions_bitbucket_projects_jobs_queued_at_idx ON explicit_permissions_bitbucket_projects_jobs (queued_at);\nCREATE INDEX IF NOT EXISTS explicit_permissions_bitbucket_projects_jobs_state_idx ON explicit_permissions_bitbucket_projects_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS explicit_permissions_bitbucket_projects_jobs_queued_at_idx;\nDROP INDEX IF EXISTS explicit_permissions_bitbucket_projects_jobs_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654874153
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655328928,
				"Name": "fix_code_insights_failed_tcp_error",
				"UpQuery": "-- In 3.40 one transient error was accidentally flagged as non-retryable and would terminally fail. This simply\n-- resets these jobs in the queue to try again after 3.41 ships.\nupdate insights_query_runner_jobs set state = 'queued', failure_message = null, num_failures = 0\nwhere state = 'failed' and failure_message like '%dial tcp%';",
				"DownQuery": "-- Nothing to do in this down migration.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649253538,
					1655037391,
					1655067139,
					1655128668
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655412173,
				"Name": "code_insights_queue_missing_index",
				"UpQuery": "CREATE INDEX IF NOT EXISTS process_after_insights_query_runner_jobs_idx\n    ON insights_query_runner_jobs (process_after);\n\nCREATE INDEX IF NOT EXISTS finished_at_insights_query_runner_jobs_idx\n    ON insights_query_runner_jobs (finished_at);",
				"DownQuery": "DROP INDEX IF EXISTS process_after_insights_query_runner_jobs_idx;\nDROP INDEX IF EXISTS finished_at_insights_query_runner_jobs_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655328928
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655481894,
				"Name": "faster_ssbc_dequeue",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS batch_spec_workspace_execution_jobs_last_dequeue ON batch_spec_workspace_execution_jobs (user_id, started_at DESC);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_last_dequeue;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655412173
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "batch_spec_workspace_execution_jobs",
					"IndexName": "batch_spec_workspace_execution_jobs_last_dequeue"
				}
			},
			{
				"ID": 1655737737,
				"Name": "drop_unused_idx_batch_spec_workspace_execution_jobs_user_id",
				"UpQuery": "DROP INDEX IF EXISTS batch_spec_workspace_execution_jobs_user_id;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS batch_spec_workspace_execution_jobs_user_id ON batch_spec_workspace_execution_jobs (user_id);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655481894
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655763641,
				"Name": "faster_workspace_batch_spec_lookup",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS batch_spec_workspaces_id_batch_spec_id ON batch_spec_workspaces(id, batch_spec_id);",
				"DownQuery": "DROP INDEX IF EXISTS batch_spec_workspaces_id_batch_spec_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655481894
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "batch_spec_workspaces",
					"IndexName": "batch_spec_workspaces_id_batch_spec_id"
				}
			},
			{
				"ID": 1655843069,
				"Name": "insights_faster_job_status",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS insights_query_runner_jobs_series_id_state ON insights_query_runner_jobs (series_id, state);",
				"DownQuery": "DROP INDEX IF EXISTS insights_query_runner_jobs_series_id_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655737737,
					1655763641
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "insights_query_runner_jobs",
					"IndexName": "insights_query_runner_jobs_series_id_state"
				}
			},
			{
				"ID": 1655157509,
				"Name": "no_more_ssbc_access_tokens",
				"UpQuery": "DELETE FROM access_tokens WHERE internal and note = 'batch-spec-execution';\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.id,\n        j.batch_spec_workspace_id,\n        j.state,\n        j.failure_message,\n        j.started_at,\n        j.finished_at,\n        j.process_after,\n        j.num_resets,\n        j.num_failures,\n        j.execution_logs,\n        j.worker_hostname,\n        j.last_heartbeat_at,\n        j.created_at,\n        j.updated_at,\n        j.cancel,\n        j.queued_at,\n        j.user_id,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);\n\nALTER TABLE batch_spec_workspace_execution_jobs DROP COLUMN IF EXISTS access_token_id;",
				"DownQuery": "ALTER TABLE batch_spec_workspace_execution_jobs ADD COLUMN IF NOT EXISTS access_token_id integer REFERENCES access_tokens(id);\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.*,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1649253538,
					1654874153
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655105391,
				"Name": "lockfile_dependency_graph",
				"UpQuery": "DELETE FROM codeintel_lockfiles;\nDELETE FROM codeintel_lockfile_references;\n\nALTER TABLE codeintel_lockfiles\n  ADD COLUMN IF NOT EXISTS lockfile text;\n\n-- This is a backwards incompatible change. See dev/ci/go-backcompat/flakefiles/v3.41.0.json for details.\nDROP INDEX IF EXISTS codeintel_lockfiles_repository_id_commit_bytea;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfiles_repository_id_commit_bytea_lockfile ON codeintel_lockfiles USING btree (repository_id, commit_bytea, lockfile);\n\nCOMMENT ON COLUMN codeintel_lockfiles.lockfile IS 'Relative path of a lockfile in the given repository and the given commit.';\n\nALTER TABLE codeintel_lockfile_references\n  -- We can't make them non-nullable to stay backwards compatible\n  ADD COLUMN IF NOT EXISTS depends_on integer[] DEFAULT '{}',\n  ADD COLUMN IF NOT EXISTS resolution_lockfile text,\n  ADD COLUMN IF NOT EXISTS resolution_repository_id integer,\n  ADD COLUMN IF NOT EXISTS resolution_commit_bytea bytea;\n\nCOMMENT ON COLUMN codeintel_lockfile_references.depends_on IS 'IDs of other `codeintel_lockfile_references` this package depends on in the context of this `codeintel_lockfile_references.resolution_id`.';\nCOMMENT ON COLUMN codeintel_lockfile_references.resolution_lockfile IS 'Relative path of lockfile in which this package was referenced. Corresponds to `codeintel_lockfiles.lockfile`.';\nCOMMENT ON COLUMN codeintel_lockfile_references.resolution_repository_id IS 'ID of the repository in which lockfile was resolved. Corresponds to `codeintel_lockfiles.repository_id`.';\nCOMMENT ON COLUMN codeintel_lockfile_references.resolution_commit_bytea IS 'Commit at which lockfile was resolved. Corresponds to `codeintel_lockfiles.commit_bytea`.';\n\nCREATE INDEX IF NOT EXISTS codeintel_lockfiles_references_depends_on\nON codeintel_lockfile_references USING GIN (depends_on gin__int_ops);\n\n-- This is a backwards incompatible change. See dev/ci/go-backcompat/flakefiles/v3.41.0.json for details.\nDROP INDEX IF EXISTS codeintel_lockfile_references_repository_name_revspec_package;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_name_revspec_package_resolution ON codeintel_lockfile_references USING btree (\n    repository_name,\n    revspec,\n    package_scheme,\n    package_name,\n    package_version,\n    resolution_lockfile,\n    resolution_repository_id,\n    resolution_commit_bytea\n);",
				"DownQuery": "ALTER TABLE codeintel_lockfiles\n  DROP COLUMN IF EXISTS lockfile;\n\nDROP INDEX IF EXISTS codeintel_lockfiles_repository_id_commit_bytea_lockfile;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfiles_repository_id_commit_bytea ON codeintel_lockfiles USING btree (repository_id, commit_bytea);\n\nALTER TABLE codeintel_lockfile_references\n  DROP COLUMN IF EXISTS depends_on,\n  DROP COLUMN IF EXISTS resolution_lockfile,\n  DROP COLUMN IF EXISTS resolution_repository_id,\n  DROP COLUMN IF EXISTS resolution_commit_bytea;\n\nDROP INDEX IF EXISTS codeintel_lockfile_references_repository_name_revspec_package_resolution;\nCREATE UNIQUE INDEX IF NOT EXISTS codeintel_lockfile_references_repository_name_revspec_package ON codeintel_lockfile_references USING btree (\n    repository_name,\n    revspec,\n    package_scheme,\n    package_name,\n    package_version\n);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654848945
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1655454264,
				"Name": "add_lockfile_indexing_enabled_to_policy",
				"UpQuery": "ALTER TABLE lsif_configuration_policies\n  ADD COLUMN IF NOT EXISTS lockfile_indexing_enabled boolean NOT NULL DEFAULT false;\n\nCOMMENT ON COLUMN lsif_configuration_policies.lockfile_indexing_enabled IS 'Whether to index the lockfiles in the repositories matched by this policy';",
				"DownQuery": "ALTER TABLE lsif_configuration_policies\n  DROP COLUMN IF EXISTS lockfile_indexing_enabled;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655105391
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1656447205,
				"Name": "create_repo_description_trgm_idx",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS repo_description_trgm_idx ON repo USING GIN (lower(description) gin_trgm_ops);",
				"DownQuery": "DROP INDEX IF EXISTS repo_description_trgm_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1655454264,
					1655843069
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "repo",
					"IndexName": "repo_description_trgm_idx"
				}
			},
			{
				"ID": 1657106983,
				"Name": "faster_failure_msg_query",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS external_service_sync_jobs_state_external_service_id ON external_service_sync_jobs (state, external_service_id) INCLUDE (finished_at);",
				"DownQuery": "DROP INDEX IF EXISTS external_service_sync_jobs_state_external_service_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653472246,
					1655157509,
					1655226733,
					1655454264,
					1655843069
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "external_service_sync_jobs",
					"IndexName": "external_service_sync_jobs_state_external_service_id"
				}
			},
			{
				"ID": 1657107627,
				"Name": "drop_duplicate_index_sync_jobs_state",
				"UpQuery": "DROP INDEX IF EXISTS external_service_sync_jobs_state_idx;",
				"DownQuery": "CREATE INDEX IF NOT EXISTS external_service_sync_jobs_state_idx ON external_service_sync_jobs (state);",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657106983
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1657279116,
				"Name": "faster_dequeues_cm_action_jobs",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS cm_action_jobs_state_idx ON cm_action_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS cm_action_jobs_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1656447205,
					1657107627
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "cm_action_jobs",
					"IndexName": "cm_action_jobs_state_idx"
				}
			},
			{
				"ID": 1657279170,
				"Name": "faster_dequeues_cm_trigger_jobs",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS cm_trigger_jobs_state_idx ON cm_trigger_jobs (state);",
				"DownQuery": "DROP INDEX IF EXISTS cm_trigger_jobs_state_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657279116
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "cm_trigger_jobs",
					"IndexName": "cm_trigger_jobs_state_idx"
				}
			},
			{
				"ID": 1657635365,
				"Name": "add_fidelity_to_lockfiles",
				"UpQuery": "ALTER TABLE codeintel_lockfiles\n  ADD COLUMN IF NOT EXISTS fidelity text NOT NULL DEFAULT 'flat';\n\nCOMMENT ON COLUMN codeintel_lockfiles.fidelity IS 'Fidelity of the dependency graph thats persisted, whether it is a flat list, a whole graph, circular graph, ...';",
				"DownQuery": "ALTER TABLE codeintel_lockfiles DROP COLUMN IF EXISTS fidelity;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657279170
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658122170,
				"Name": "add_batch_change_id_to_batch_spec",
				"UpQuery": "ALTER TABLE batch_specs\n    ADD COLUMN IF NOT EXISTS batch_change_id bigint,\n    ADD FOREIGN KEY (batch_change_id) REFERENCES batch_changes(id) ON DELETE SET NULL DEFERRABLE;\n\nUPDATE batch_specs SET batch_change_id = (\n    -- In the event, the database is in a not-so-optimal state (usually in dev environment)\n    -- we want the subquery to never return more than one row.\n    -- This will never happen in production.\n    SELECT\n        bc.id\n    FROM batch_changes bc\n    WHERE bc.batch_spec_id = batch_specs.id\n    LIMIT 1\n);",
				"DownQuery": "ALTER TABLE batch_specs\n    DROP COLUMN IF EXISTS batch_change_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657635365
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658174103,
				"Name": "workspace_execution_user_queues",
				"UpQuery": "CREATE TABLE IF NOT EXISTS batch_spec_workspace_execution_last_dequeues (\n    user_id integer PRIMARY KEY REFERENCES users(id) ON DELETE CASCADE ON UPDATE CASCADE DEFERRABLE INITIALLY DEFERRED,\n    latest_dequeue timestamp with time zone\n);\n\nCREATE OR REPLACE FUNCTION batch_spec_workspace_execution_last_dequeues_upsert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n    INSERT INTO\n        batch_spec_workspace_execution_last_dequeues\n    SELECT\n        user_id,\n        MAX(started_at) as latest_dequeue\n    FROM\n        newtab\n    GROUP BY\n        user_id\n    ON CONFLICT (user_id) DO UPDATE SET\n        latest_dequeue = GREATEST(batch_spec_workspace_execution_last_dequeues.latest_dequeue, EXCLUDED.latest_dequeue);\n\n    RETURN NULL;\nEND $$;\n\nDROP TRIGGER IF EXISTS batch_spec_workspace_execution_last_dequeues_insert ON batch_spec_workspace_execution_jobs;\nCREATE TRIGGER batch_spec_workspace_execution_last_dequeues_insert AFTER INSERT ON batch_spec_workspace_execution_jobs REFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION batch_spec_workspace_execution_last_dequeues_upsert();\n\nDROP TRIGGER IF EXISTS batch_spec_workspace_execution_last_dequeues_update ON batch_spec_workspace_execution_jobs;\nCREATE TRIGGER batch_spec_workspace_execution_last_dequeues_update AFTER UPDATE ON batch_spec_workspace_execution_jobs REFERENCING NEW TABLE AS newtab FOR EACH STATEMENT EXECUTE FUNCTION batch_spec_workspace_execution_last_dequeues_upsert();\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH queue_candidates AS (\n    SELECT\n        exec.id,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN batch_spec_workspace_execution_last_dequeues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    queue_candidates.id, ROW_NUMBER() OVER () AS place_in_global_queue, queue_candidates.place_in_user_queue\nFROM queue_candidates;\n\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.*,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);\n\nINSERT INTO batch_spec_workspace_execution_last_dequeues\nSELECT\n    exec.user_id as user_id,\n    MAX(exec.started_at) AS latest_dequeue\nFROM batch_spec_workspace_execution_jobs exec\nGROUP BY exec.user_id\nON CONFLICT (user_id) DO UPDATE\n    SET latest_dequeue = GREATEST(batch_spec_workspace_execution_last_dequeues.latest_dequeue, EXCLUDED.latest_dequeue);",
				"DownQuery": "DROP TRIGGER IF EXISTS batch_spec_workspace_execution_last_dequeues_insert ON batch_spec_workspace_execution_jobs;\nDROP TRIGGER IF EXISTS batch_spec_workspace_execution_last_dequeues_update ON batch_spec_workspace_execution_jobs;\nDROP FUNCTION IF EXISTS batch_spec_workspace_execution_last_dequeues_upsert();\n\nDROP VIEW IF EXISTS batch_spec_workspace_execution_jobs_with_rank;\nDROP VIEW IF EXISTS batch_spec_workspace_execution_queue;\n\nCREATE VIEW batch_spec_workspace_execution_queue AS\nWITH user_queues AS (\n    SELECT\n        exec.user_id,\n        MAX(exec.started_at) AS latest_dequeue\n    FROM batch_spec_workspace_execution_jobs AS exec\n    GROUP BY exec.user_id\n),\nqueue_candidates AS (\n    SELECT\n        exec.id,\n        RANK() OVER (\n            PARTITION BY queue.user_id\n            -- Make sure the jobs are still fulfilled in timely order, and that the ordering is stable.\n            ORDER BY exec.created_at ASC, exec.id ASC\n        ) AS place_in_user_queue\n    FROM batch_spec_workspace_execution_jobs exec\n    JOIN user_queues queue ON queue.user_id = exec.user_id\n    WHERE\n    \t-- Only queued records should get a rank.\n        exec.state = 'queued'\n    ORDER BY\n        -- Round-robin let users dequeue jobs.\n        place_in_user_queue,\n        -- And ensure the user who dequeued the longest ago is next.\n        queue.latest_dequeue ASC NULLS FIRST\n)\nSELECT\n    queue_candidates.id, ROW_NUMBER() OVER () AS place_in_global_queue, queue_candidates.place_in_user_queue\nFROM queue_candidates;\n\nCREATE VIEW batch_spec_workspace_execution_jobs_with_rank AS (\n    SELECT\n        j.*,\n        q.place_in_global_queue,\n        q.place_in_user_queue\n    FROM\n        batch_spec_workspace_execution_jobs j\n    LEFT JOIN batch_spec_workspace_execution_queue q ON j.id = q.id\n);\n\nDROP TABLE IF EXISTS batch_spec_workspace_execution_last_dequeues;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657635365
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658225452,
				"Name": "fast_cm_trigger_jobs_delete",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS cm_trigger_jobs_finished_at ON cm_trigger_jobs (finished_at ASC);",
				"DownQuery": "DROP INDEX IF EXISTS cm_trigger_jobs_finished_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657635365
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "cm_trigger_jobs",
					"IndexName": "cm_trigger_jobs_finished_at"
				}
			},
			{
				"ID": 1657663493,
				"Name": "cancel_worker_feature",
				"UpQuery": "ALTER TABLE explicit_permissions_bitbucket_projects_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE external_service_sync_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE gitserver_relocator_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE insights_query_runner_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE lsif_dependency_indexing_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE lsif_dependency_syncing_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE lsif_indexes ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE lsif_uploads ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE batch_spec_resolution_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE changeset_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE changesets ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE cm_action_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;\nALTER TABLE cm_trigger_jobs ADD COLUMN IF NOT EXISTS cancel BOOLEAN NOT NULL DEFAULT FALSE;",
				"DownQuery": "ALTER TABLE explicit_permissions_bitbucket_projects_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE external_service_sync_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE gitserver_relocator_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE insights_query_runner_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE lsif_dependency_indexing_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE lsif_dependency_syncing_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE lsif_indexes DROP COLUMN IF EXISTS cancel;\nALTER TABLE lsif_uploads DROP COLUMN IF EXISTS cancel;\nALTER TABLE batch_spec_resolution_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE changeset_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE changesets DROP COLUMN IF EXISTS cancel;\nALTER TABLE cm_action_jobs DROP COLUMN IF EXISTS cancel;\nALTER TABLE cm_trigger_jobs DROP COLUMN IF EXISTS cancel;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1657279170
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658255432,
				"Name": "add_missing_constraints",
				"UpQuery": "DELETE FROM batch_spec_resolution_jobs WHERE batch_spec_id IS NULL OR state IS NULL;\n\nALTER TABLE batch_spec_resolution_jobs\n    ALTER COLUMN batch_spec_id SET NOT NULL,\n    ALTER COLUMN state SET NOT NULL;\n\nDELETE FROM batch_spec_workspace_execution_jobs WHERE batch_spec_workspace_id IS NULL OR state IS NULL;\n\nALTER TABLE batch_spec_workspace_execution_jobs\n    ALTER COLUMN batch_spec_workspace_id SET NOT NULL,\n    ALTER COLUMN state SET NOT NULL;\n\nDELETE FROM batch_spec_workspaces WHERE batch_spec_id IS NULL OR changeset_spec_ids IS NULL OR repo_id IS NULL;\n\nALTER TABLE batch_spec_workspaces\n    ALTER COLUMN batch_spec_id SET NOT NULL,\n    ALTER COLUMN changeset_spec_ids SET NOT NULL,\n    ALTER COLUMN repo_id SET NOT NULL;\n\nDELETE FROM changeset_jobs WHERE state IS NULL;\nALTER TABLE changeset_jobs\n    ALTER COLUMN state SET NOT NULL;",
				"DownQuery": "ALTER TABLE batch_spec_resolution_jobs\n    ALTER COLUMN batch_spec_id DROP NOT NULL,\n    ALTER COLUMN state DROP NOT NULL;\n\nALTER TABLE batch_spec_workspace_execution_jobs\n    ALTER COLUMN batch_spec_workspace_id DROP NOT NULL,\n    ALTER COLUMN state DROP NOT NULL;\n\nALTER TABLE batch_spec_workspaces\n    ALTER COLUMN batch_spec_id DROP NOT NULL,\n    ALTER COLUMN changeset_spec_ids DROP NOT NULL,\n    ALTER COLUMN repo_id DROP NOT NULL;\n\nALTER TABLE changeset_jobs\n    ALTER COLUMN state DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1654770608,
					1657663493,
					1658174103,
					1658225452
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658384388,
				"Name": "normalize product_licenses.license_key fields",
				"UpQuery": "ALTER TABLE product_licenses ADD COLUMN IF NOT EXISTS license_version INT;\nALTER TABLE product_licenses ADD COLUMN IF NOT EXISTS license_tags TEXT[];\nALTER TABLE product_licenses ADD COLUMN IF NOT EXISTS license_user_count INT;\nALTER TABLE product_licenses ADD COLUMN IF NOT EXISTS license_expires_at TIMESTAMP WITH TIME ZONE;\nALTER TABLE product_subscriptions ADD COLUMN IF NOT EXISTS account_number TEXT;",
				"DownQuery": "ALTER TABLE product_licenses DROP COLUMN IF EXISTS license_version;\nALTER TABLE product_licenses DROP COLUMN IF EXISTS license_tags;\nALTER TABLE product_licenses DROP COLUMN IF EXISTS license_user_count;\nALTER TABLE product_licenses DROP COLUMN IF EXISTS license_expires_at;\nALTER TABLE product_subscriptions DROP COLUMN IF EXISTS account_number;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658255432
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1653596521,
				"Name": "Add column detached_at to changesets table",
				"UpQuery": "ALTER TABLE changesets\n    ADD COLUMN IF NOT EXISTS detached_at timestamp with time zone;\n\nCREATE INDEX IF NOT EXISTS\n    changesets_detached_at\n    ON\n        changesets (detached_at);\n\nDROP VIEW IF EXISTS reconciler_changesets;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n       c.batch_change_ids,\n       c.repo_id,\n       c.queued_at,\n       c.created_at,\n       c.updated_at,\n       c.metadata,\n       c.external_id,\n       c.external_service_type,\n       c.external_deleted_at,\n       c.external_branch,\n       c.external_updated_at,\n       c.external_state,\n       c.external_review_state,\n       c.external_check_state,\n       c.diff_stat_added,\n       c.diff_stat_changed,\n       c.diff_stat_deleted,\n       c.sync_state,\n       c.current_spec_id,\n       c.previous_spec_id,\n       c.publication_state,\n       c.owned_by_batch_change_id,\n       c.reconciler_state,\n       c.failure_message,\n       c.started_at,\n       c.finished_at,\n       c.process_after,\n       c.num_resets,\n       c.closing,\n       c.num_failures,\n       c.log_contents,\n       c.execution_logs,\n       c.syncer_error,\n       c.external_title,\n       c.worker_hostname,\n       c.ui_publication_state,\n       c.last_heartbeat_at,\n       c.external_fork_namespace,\n       c.detached_at\nFROM changesets c\n         JOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n             LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n             LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );",
				"DownQuery": "DROP VIEW IF EXISTS reconciler_changesets;\n\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n       c.batch_change_ids,\n       c.repo_id,\n       c.queued_at,\n       c.created_at,\n       c.updated_at,\n       c.metadata,\n       c.external_id,\n       c.external_service_type,\n       c.external_deleted_at,\n       c.external_branch,\n       c.external_updated_at,\n       c.external_state,\n       c.external_review_state,\n       c.external_check_state,\n       c.diff_stat_added,\n       c.diff_stat_changed,\n       c.diff_stat_deleted,\n       c.sync_state,\n       c.current_spec_id,\n       c.previous_spec_id,\n       c.publication_state,\n       c.owned_by_batch_change_id,\n       c.reconciler_state,\n       c.failure_message,\n       c.started_at,\n       c.finished_at,\n       c.process_after,\n       c.num_resets,\n       c.closing,\n       c.num_failures,\n       c.log_contents,\n       c.execution_logs,\n       c.syncer_error,\n       c.external_title,\n       c.worker_hostname,\n       c.ui_publication_state,\n       c.last_heartbeat_at,\n       c.external_fork_namespace\nFROM changesets c\n         JOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n             LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n             LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );\n\nDROP INDEX IF EXISTS changesets_detached_at;\n\nALTER TABLE changesets DROP COLUMN IF EXISTS detached_at;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1652946496,
					1653334014
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658484997,
				"Name": "add webhook_build_jobs table",
				"UpQuery": "CREATE SEQUENCE IF NOT EXISTS webhook_build_jobs_id_seq\n    START WITH 1\n    INCREMENT BY 1\n    NO MINVALUE\n    NO MAXVALUE\n    CACHE 1;\n\n CREATE TABLE IF NOT EXISTS webhook_build_jobs (\n    repo_id integer,\n    repo_name text,\n    extsvc_kind text,\n    queued_at timestamp with time zone DEFAULT now(),\n    id integer DEFAULT nextval('webhook_build_jobs_id_seq'::regclass) NOT NULL,\n    state text DEFAULT 'queued'::text NOT NULL,\n    failure_message text,\n    started_at timestamp with time zone,\n    finished_at timestamp with time zone,\n    process_after timestamp with time zone,\n    num_resets integer DEFAULT 0 NOT NULL,\n    num_failures integer DEFAULT 0 NOT NULL,\n    execution_logs json[],\n    last_heartbeat_at timestamp with time zone,\n    worker_hostname text DEFAULT ''::text NOT NULL\n );\n\n CREATE INDEX IF NOT EXISTS webhook_build_jobs_queued_at_idx ON webhook_build_jobs USING btree (queued_at);",
				"DownQuery": "DROP TABLE IF EXISTS webhook_build_jobs;\nDROP INDEX IF EXISTS webhook_build_jobs_queued_at_idx;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653596521,
					1658384388
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658503913,
				"Name": "batches_changeset_state_computed",
				"UpQuery": "ALTER TABLE changesets ADD COLUMN IF NOT EXISTS computed_state TEXT;\n\nDROP TRIGGER IF EXISTS changesets_update_computed_state ON changesets;\n\nUPDATE\n    changesets\nSET\n    computed_state = CASE\n        WHEN reconciler_state = 'errored' THEN 'RETRYING'\n        WHEN reconciler_state = 'failed' THEN 'FAILED'\n        WHEN reconciler_state = 'scheduled' THEN 'SCHEDULED'\n        WHEN reconciler_state != 'completed' THEN 'PROCESSING'\n        WHEN publication_state = 'UNPUBLISHED' THEN 'UNPUBLISHED'\n        ELSE external_state\n    END;\n\nALTER TABLE changesets ALTER COLUMN computed_state SET NOT NULL;\n\nCREATE OR REPLACE FUNCTION changesets_computed_state_ensure() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n\n    NEW.computed_state = CASE\n        WHEN NEW.reconciler_state = 'errored' THEN 'RETRYING'\n        WHEN NEW.reconciler_state = 'failed' THEN 'FAILED'\n        WHEN NEW.reconciler_state = 'scheduled' THEN 'SCHEDULED'\n        WHEN NEW.reconciler_state != 'completed' THEN 'PROCESSING'\n        WHEN NEW.publication_state = 'UNPUBLISHED' THEN 'UNPUBLISHED'\n        ELSE NEW.external_state\n    END AS computed_state;\n\n    RETURN NEW;\nEND $$;\n\nCREATE TRIGGER changesets_update_computed_state BEFORE INSERT OR UPDATE ON changesets FOR EACH ROW EXECUTE FUNCTION changesets_computed_state_ensure();\n\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nCREATE VIEW branch_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    changesets.owned_by_batch_change_id AS owner_batch_change_id,\n    repo.name AS repo_name,\n    changeset_specs.title AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state,\n    changesets.computed_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.current_spec_id IS NOT NULL) AND (EXISTS ( SELECT 1\n           FROM changeset_specs changeset_specs_1\n          WHERE ((changeset_specs_1.id = changesets.current_spec_id) AND (changeset_specs_1.head_ref = changeset_specs.head_ref)))))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NULL) AND (repo.deleted_at IS NULL));\n\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\nCREATE VIEW tracking_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    repo.name AS repo_name,\n    COALESCE((changesets.metadata -\u003e\u003e 'Title'::text), (changesets.metadata -\u003e\u003e 'title'::text)) AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state,\n    changesets.computed_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.external_id = changeset_specs.external_id))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NOT NULL) AND (repo.deleted_at IS NULL));\n\nDROP VIEW IF EXISTS reconciler_changesets;\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n       c.batch_change_ids,\n       c.repo_id,\n       c.queued_at,\n       c.created_at,\n       c.updated_at,\n       c.metadata,\n       c.external_id,\n       c.external_service_type,\n       c.external_deleted_at,\n       c.external_branch,\n       c.external_updated_at,\n       c.external_state,\n       c.external_review_state,\n       c.external_check_state,\n       c.diff_stat_added,\n       c.diff_stat_changed,\n       c.diff_stat_deleted,\n       c.sync_state,\n       c.current_spec_id,\n       c.previous_spec_id,\n       c.publication_state,\n       c.owned_by_batch_change_id,\n       c.reconciler_state,\n       c.computed_state,\n       c.failure_message,\n       c.started_at,\n       c.finished_at,\n       c.process_after,\n       c.num_resets,\n       c.closing,\n       c.num_failures,\n       c.log_contents,\n       c.execution_logs,\n       c.syncer_error,\n       c.external_title,\n       c.worker_hostname,\n       c.ui_publication_state,\n       c.last_heartbeat_at,\n       c.external_fork_namespace,\n       c.detached_at\nFROM changesets c\n         JOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n             LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n             LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );",
				"DownQuery": "DROP TRIGGER IF EXISTS changesets_update_computed_state ON changesets;\nDROP FUNCTION IF EXISTS changesets_computed_state_ensure();\n\nDROP VIEW IF EXISTS branch_changeset_specs_and_changesets;\nCREATE VIEW branch_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    changesets.owned_by_batch_change_id AS owner_batch_change_id,\n    repo.name AS repo_name,\n    changeset_specs.title AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.current_spec_id IS NOT NULL) AND (EXISTS ( SELECT 1\n           FROM changeset_specs changeset_specs_1\n          WHERE ((changeset_specs_1.id = changesets.current_spec_id) AND (changeset_specs_1.head_ref = changeset_specs.head_ref)))))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NULL) AND (repo.deleted_at IS NULL));\n\nDROP VIEW IF EXISTS tracking_changeset_specs_and_changesets;\nCREATE VIEW tracking_changeset_specs_and_changesets AS\n SELECT changeset_specs.id AS changeset_spec_id,\n    COALESCE(changesets.id, (0)::bigint) AS changeset_id,\n    changeset_specs.repo_id,\n    changeset_specs.batch_spec_id,\n    repo.name AS repo_name,\n    COALESCE((changesets.metadata -\u003e\u003e 'Title'::text), (changesets.metadata -\u003e\u003e 'title'::text)) AS changeset_name,\n    changesets.external_state,\n    changesets.publication_state,\n    changesets.reconciler_state\n   FROM ((changeset_specs\n     LEFT JOIN changesets ON (((changesets.repo_id = changeset_specs.repo_id) AND (changesets.external_id = changeset_specs.external_id))))\n     JOIN repo ON ((changeset_specs.repo_id = repo.id)))\n  WHERE ((changeset_specs.external_id IS NOT NULL) AND (repo.deleted_at IS NULL));\n\nDROP VIEW IF EXISTS reconciler_changesets;\nCREATE VIEW reconciler_changesets AS\nSELECT c.id,\n       c.batch_change_ids,\n       c.repo_id,\n       c.queued_at,\n       c.created_at,\n       c.updated_at,\n       c.metadata,\n       c.external_id,\n       c.external_service_type,\n       c.external_deleted_at,\n       c.external_branch,\n       c.external_updated_at,\n       c.external_state,\n       c.external_review_state,\n       c.external_check_state,\n       c.diff_stat_added,\n       c.diff_stat_changed,\n       c.diff_stat_deleted,\n       c.sync_state,\n       c.current_spec_id,\n       c.previous_spec_id,\n       c.publication_state,\n       c.owned_by_batch_change_id,\n       c.reconciler_state,\n       c.failure_message,\n       c.started_at,\n       c.finished_at,\n       c.process_after,\n       c.num_resets,\n       c.closing,\n       c.num_failures,\n       c.log_contents,\n       c.execution_logs,\n       c.syncer_error,\n       c.external_title,\n       c.worker_hostname,\n       c.ui_publication_state,\n       c.last_heartbeat_at,\n       c.external_fork_namespace,\n       c.detached_at\nFROM changesets c\n         JOIN repo r ON r.id = c.repo_id\nWHERE r.deleted_at IS NULL AND EXISTS (\n    SELECT 1\n    FROM batch_changes\n             LEFT JOIN users namespace_user ON batch_changes.namespace_user_id = namespace_user.id\n             LEFT JOIN orgs namespace_org ON batch_changes.namespace_org_id = namespace_org.id\n    WHERE c.batch_change_ids ? batch_changes.id::text AND namespace_user.deleted_at IS NULL AND namespace_org.deleted_at IS NULL\n    );\n\n\nALTER TABLE changesets DROP COLUMN IF EXISTS computed_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1653596521,
					1658384388
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658512336,
				"Name": "batches_changeset_state_index",
				"UpQuery": "CREATE INDEX CONCURRENTLY IF NOT EXISTS changesets_computed_state ON changesets (computed_state);",
				"DownQuery": "DROP INDEX IF EXISTS changesets_computed_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658503913
				],
				"IsCreateIndexConcurrently": true,
				"IndexMetadata": {
					"TableName": "changesets",
					"IndexName": "changesets_computed_state"
				}
			},
			{
				"ID": 1658748822,
				"Name": "add_timestamps_to_lockfiles",
				"UpQuery": "ALTER TABLE codeintel_lockfiles\n  ADD COLUMN IF NOT EXISTS created_at timestamptz NOT NULL DEFAULT NOW(),\n  ADD COLUMN IF NOT EXISTS updated_at timestamptz NOT NULL DEFAULT NOW()\n  ;\n\nCOMMENT ON COLUMN codeintel_lockfiles.created_at IS 'Time when lockfile was indexed';\nCOMMENT ON COLUMN codeintel_lockfiles.updated_at IS 'Time when lockfile index was updated';",
				"DownQuery": "ALTER TABLE codeintel_lockfiles\n  DROP COLUMN IF EXISTS created_at,\n  DROP COLUMN IF EXISTS updated_at\n  ;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658512336
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658837440,
				"Name": "sync_jobs_missing_index",
				"UpQuery": "DELETE FROM external_service_sync_jobs WHERE external_service_id IS NULL;\nALTER TABLE external_service_sync_jobs ALTER COLUMN external_service_id SET NOT NULL;",
				"DownQuery": "ALTER TABLE external_service_sync_jobs ALTER COLUMN external_service_id DROP NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658748822
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658856572,
				"Name": "event_log_scrape_state",
				"UpQuery": "CREATE TABLE IF NOT EXISTS event_logs_scrape_state\n(\n    id                     SERIAL\n        CONSTRAINT event_logs_scrape_state_pk\n            PRIMARY KEY,\n    bookmark_id INT NOT NULL\n);\n\nCOMMENT ON TABLE event_logs_scrape_state IS 'Contains state for the periodic telemetry job that scrapes events if enabled.';\nCOMMENT ON COLUMN event_logs_scrape_state.bookmark_id IS 'Bookmarks the maximum most recent successful event_logs.id that was scraped';",
				"DownQuery": "DROP TABLE IF EXISTS event_logs_scrape_state;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658748822
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658950366,
				"Name": "event_log_scrape_allow_list",
				"UpQuery": "CREATE TABLE IF NOT EXISTS event_logs_export_allowlist\n(\n    id         SERIAL PRIMARY KEY,\n    event_name TEXT NOT NULL\n);\n\nCREATE UNIQUE INDEX IF NOT EXISTS event_logs_export_allowlist_event_name_idx ON event_logs_export_allowlist (event_name);\n\nCOMMENT ON TABLE event_logs_export_allowlist IS 'An allowlist of events that are approved for export if the scraping job is enabled';\nCOMMENT ON COLUMN event_logs_export_allowlist.event_name IS 'Name of the event that corresponds to event_logs.name';",
				"DownQuery": "DROP TABLE IF EXISTS event_logs_export_allowlist;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658122170,
					1658484997,
					1658856572
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659085788,
				"Name": "add_repo_stats_table",
				"UpQuery": "--------------------------------------------------------------------------------\n--                              repos table                                   --\n--------------------------------------------------------------------------------\n\n-- repo_statistics holds statistics for the repo table (hence the singular\n-- \"repo\" in the name)\nCREATE TABLE IF NOT EXISTS repo_statistics (\n  total         BIGINT NOT NULL DEFAULT 0,\n  soft_deleted  BIGINT NOT NULL DEFAULT 0,\n  not_cloned    BIGINT NOT NULL DEFAULT 0,\n  cloning       BIGINT NOT NULL DEFAULT 0,\n  cloned        BIGINT NOT NULL DEFAULT 0,\n  failed_fetch  BIGINT NOT NULL DEFAULT 0\n);\n\nCOMMENT ON COLUMN repo_statistics.total IS 'Number of repositories that are not soft-deleted and not blocked';\nCOMMENT ON COLUMN repo_statistics.soft_deleted IS 'Number of repositories that are soft-deleted and not blocked';\nCOMMENT ON COLUMN repo_statistics.not_cloned IS 'Number of repositories that are NOT soft-deleted and not blocked and not cloned by gitserver';\nCOMMENT ON COLUMN repo_statistics.cloning IS 'Number of repositories that are NOT soft-deleted and not blocked and currently being cloned by gitserver';\nCOMMENT ON COLUMN repo_statistics.cloned IS 'Number of repositories that are NOT soft-deleted and not blocked and cloned by gitserver';\nCOMMENT ON COLUMN repo_statistics.failed_fetch IS 'Number of repositories that are NOT soft-deleted and not blocked and have last_error set in gitserver_repos table';\n\n-- Insert initial values into repo_statistics table\nINSERT INTO repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\nVALUES (\n  (SELECT COUNT(*) FROM repo WHERE deleted_at is NULL     AND blocked IS NULL),\n  (SELECT COUNT(*) FROM repo WHERE deleted_at is NOT NULL AND blocked IS NULL),\n  (\n    SELECT COUNT(*)\n    FROM repo\n    JOIN gitserver_repos gr ON gr.repo_id = repo.id\n    WHERE\n      repo.deleted_at is NULL\n    AND\n      repo.blocked IS NULL\n    AND\n      gr.clone_status = 'not_cloned'\n  ),\n  (\n    SELECT COUNT(*)\n    FROM repo\n    JOIN gitserver_repos gr ON gr.repo_id = repo.id\n    WHERE\n      repo.deleted_at is NULL\n    AND\n      repo.blocked IS NULL\n    AND\n      gr.clone_status = 'cloning'\n  ),\n  (\n    SELECT COUNT(*)\n    FROM repo\n    JOIN gitserver_repos gr ON gr.repo_id = repo.id\n    WHERE\n      repo.deleted_at is NULL\n    AND\n      repo.blocked IS NULL\n    AND\n      gr.clone_status = 'cloned'\n  ),\n  (\n    SELECT COUNT(*)\n    FROM repo\n    JOIN gitserver_repos gr ON gr.repo_id = repo.id\n    WHERE\n      repo.deleted_at is NULL\n    AND\n      repo.blocked IS NULL\n    AND\n      gr.last_error IS NOT NULL\n  )\n);\n\n-- UPDATE\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      -- Insert diff of changes\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\n      VALUES (\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NOT NULL AND blocked IS NULL) - (SELECT COUNT(*) FROM oldtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'not_cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloning')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloning')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.clone_status = 'cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN gitserver_repos gr ON gr.repo_id = newtab.id WHERE newtab.deleted_at is NULL AND newtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n        )\n      )\n      ;\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_update ON repo;\nCREATE TRIGGER trig_recalc_repo_statistics_on_repo_update\nAFTER UPDATE ON repo\nREFERENCING OLD TABLE AS oldtab NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_repo_statistics_on_repo_update();\n\n-- INSERT\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned)\n      VALUES (\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n        -- New repositories are always not_cloned by default, so we can count them as not cloned here\n        (SELECT COUNT(*) FROM newtab WHERE deleted_at IS NULL     AND blocked IS NULL)\n        -- New repositories never have last_error set, so we can also ignore those here\n      );\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_insert ON repo;\nCREATE TRIGGER trig_recalc_repo_statistics_on_repo_insert\nAFTER INSERT ON repo\nREFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_repo_statistics_on_repo_insert();\n\n-- DELETE\nCREATE OR REPLACE FUNCTION recalc_repo_statistics_on_repo_delete() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO\n        repo_statistics (total, soft_deleted, not_cloned, cloning, cloned, failed_fetch)\n      VALUES (\n        -- Insert negative counts\n        (SELECT -COUNT(*) FROM oldtab WHERE deleted_at IS NULL     AND blocked IS NULL),\n        (SELECT -COUNT(*) FROM oldtab WHERE deleted_at IS NOT NULL AND blocked IS NULL),\n        (SELECT -COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'not_cloned'),\n        (SELECT -COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloning'),\n        (SELECT -COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.clone_status = 'cloned'),\n        (SELECT -COUNT(*) FROM oldtab JOIN gitserver_repos gr ON gr.repo_id = oldtab.id WHERE oldtab.deleted_at is NULL AND oldtab.blocked IS NULL AND gr.last_error IS NOT NULL)\n      );\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_delete ON repo;\nCREATE TRIGGER trig_recalc_repo_statistics_on_repo_delete\nAFTER DELETE ON repo\nREFERENCING OLD TABLE AS oldtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_repo_statistics_on_repo_delete();\n\n--------------------------------------------------------------------------------\n--                       gitserver_repos table                                --\n--------------------------------------------------------------------------------\n\n-- gitserver_repos_statistics holds statistics for the gitserver_repos table\nCREATE TABLE IF NOT EXISTS gitserver_repos_statistics (\n  -- In this table we have one row per shard_id\n  shard_id text PRIMARY KEY,\n\n  total        BIGINT NOT NULL DEFAULT 0,\n  not_cloned   BIGINT NOT NULL DEFAULT 0,\n  cloning      BIGINT NOT NULL DEFAULT 0,\n  cloned       BIGINT NOT NULL DEFAULT 0,\n  failed_fetch BIGINT NOT NULL DEFAULT 0\n);\n\nCOMMENT ON COLUMN gitserver_repos_statistics.shard_id IS 'ID of this gitserver shard. If an empty string then the repositories havent been assigned a shard.';\nCOMMENT ON COLUMN gitserver_repos_statistics.total IS 'Number of repositories in gitserver_repos table on this shard';\nCOMMENT ON COLUMN gitserver_repos_statistics.not_cloned IS 'Number of repositories in gitserver_repos table on this shard that are not cloned yet';\nCOMMENT ON COLUMN gitserver_repos_statistics.cloning IS 'Number of repositories in gitserver_repos table on this shard that cloning';\nCOMMENT ON COLUMN gitserver_repos_statistics.cloned IS 'Number of repositories in gitserver_repos table on this shard that are cloned';\nCOMMENT ON COLUMN gitserver_repos_statistics.failed_fetch IS 'Number of repositories in gitserver_repos table on this shard where last_error is set';\n\n-- Insert initial values into gitserver_repos_statistics\nINSERT INTO\n  gitserver_repos_statistics (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\nSELECT\n  shard_id,\n  COUNT(*) AS total,\n  COUNT(*) FILTER(WHERE clone_status = 'not_cloned') AS not_cloned,\n  COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n  COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n  COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\nFROM\n  gitserver_repos\nGROUP BY shard_id\nON CONFLICT(shard_id)\nDO UPDATE\nSET\n  total        = gitserver_repos_statistics.total        + excluded.total,\n  not_cloned   = gitserver_repos_statistics.not_cloned   + excluded.not_cloned,\n  cloning      = gitserver_repos_statistics.cloning      + excluded.cloning,\n  cloned       = gitserver_repos_statistics.cloned       + excluded.cloned,\n  failed_fetch = gitserver_repos_statistics.failed_fetch + excluded.failed_fetch\n;\n\n-- UPDATE\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_update() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO gitserver_repos_statistics AS grs (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\n      SELECT\n        newtab.shard_id AS shard_id,\n        COUNT(*) AS total,\n        COUNT(*) FILTER(WHERE clone_status = 'not_cloned')  AS not_cloned,\n        COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n        COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n        COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\n      FROM\n        newtab\n      GROUP BY newtab.shard_id\n      ON CONFLICT(shard_id) DO\n      UPDATE\n      SET\n        total        = grs.total        + (excluded.total        - (SELECT COUNT(*)                                              FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        not_cloned   = grs.not_cloned   + (excluded.not_cloned   - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'not_cloned') FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloning      = grs.cloning      + (excluded.cloning      - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloning')    FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        cloned       = grs.cloned       + (excluded.cloned       - (SELECT COUNT(*) FILTER(WHERE ot.clone_status = 'cloned')     FROM oldtab ot WHERE ot.shard_id = excluded.shard_id)),\n        failed_fetch = grs.failed_fetch + (excluded.failed_fetch - (SELECT COUNT(*) FILTER(WHERE ot.last_error IS NOT NULL)      FROM oldtab ot WHERE ot.shard_id = excluded.shard_id))\n      ;\n\n      WITH moved AS (\n        SELECT\n          oldtab.shard_id AS shard_id,\n          COUNT(*) AS total,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'not_cloned')  AS not_cloned,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloning') AS cloning,\n          COUNT(*) FILTER(WHERE oldtab.clone_status = 'cloned') AS cloned,\n          COUNT(*) FILTER(WHERE oldtab.last_error IS NOT NULL) AS failed_fetch\n        FROM\n          oldtab\n        JOIN newtab ON newtab.repo_id = oldtab.repo_id\n        WHERE\n          oldtab.shard_id != newtab.shard_id\n        GROUP BY oldtab.shard_id\n      )\n      UPDATE gitserver_repos_statistics grs\n      SET\n        total        = grs.total        - moved.total,\n        not_cloned   = grs.not_cloned   - moved.not_cloned,\n        cloning      = grs.cloning      - moved.cloning,\n        cloned       = grs.cloned       - moved.cloned,\n        failed_fetch = grs.failed_fetch - moved.failed_fetch\n      FROM moved\n      WHERE moved.shard_id = grs.shard_id;\n\n      INSERT INTO repo_statistics (not_cloned, cloning, cloned, failed_fetch)\n      VALUES (\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'not_cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'not_cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloning')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloning')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.clone_status = 'cloned')\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.clone_status = 'cloned')\n        ),\n        (\n          (SELECT COUNT(*) FROM newtab JOIN repo r ON newtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND newtab.last_error IS NOT NULL)\n          -\n          (SELECT COUNT(*) FROM oldtab JOIN repo r ON oldtab.repo_id = r.id WHERE r.deleted_at is NULL AND r.blocked IS NULL AND oldtab.last_error IS NOT NULL)\n        )\n      );\n\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_update ON gitserver_repos;\nCREATE TRIGGER trig_recalc_gitserver_repos_statistics_on_update\nAFTER UPDATE ON gitserver_repos\nREFERENCING OLD TABLE AS oldtab NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_gitserver_repos_statistics_on_update();\n\n-- INSERT\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_insert() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      INSERT INTO gitserver_repos_statistics AS grs (shard_id, total, not_cloned, cloning, cloned, failed_fetch)\n      SELECT\n        shard_id,\n        COUNT(*) AS total,\n        COUNT(*) FILTER(WHERE clone_status = 'not_cloned') AS not_cloned,\n        COUNT(*) FILTER(WHERE clone_status = 'cloning') AS cloning,\n        COUNT(*) FILTER(WHERE clone_status = 'cloned') AS cloned,\n        COUNT(*) FILTER(WHERE last_error IS NOT NULL) AS failed_fetch\n      FROM\n        newtab\n      GROUP BY shard_id\n      ON CONFLICT(shard_id)\n      DO UPDATE\n      SET\n        total        = grs.total        + excluded.total,\n        not_cloned   = grs.not_cloned   + excluded.not_cloned,\n        cloning      = grs.cloning      + excluded.cloning,\n        cloned       = grs.cloned       + excluded.cloned,\n        failed_fetch = grs.failed_fetch + excluded.failed_fetch\n      ;\n\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_insert ON gitserver_repos;\nCREATE TRIGGER trig_recalc_gitserver_repos_statistics_on_insert\nAFTER INSERT ON gitserver_repos\nREFERENCING NEW TABLE AS newtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_gitserver_repos_statistics_on_insert();\n\n-- DELETE\nCREATE OR REPLACE FUNCTION recalc_gitserver_repos_statistics_on_delete() RETURNS trigger\n    LANGUAGE plpgsql\n    AS $$ BEGIN\n      UPDATE gitserver_repos_statistics grs\n      SET\n        total        = grs.total      - (SELECT COUNT(*)                                           FROM oldtab WHERE oldtab.shard_id = grs.shard_id),\n        not_cloned   = grs.not_cloned - (SELECT COUNT(*) FILTER(WHERE clone_status = 'not_cloned') FROM oldtab WHERE oldtab.shard_id = grs.shard_id),\n        cloning      = grs.cloning    - (SELECT COUNT(*) FILTER(WHERE clone_status = 'cloning')    FROM oldtab WHERE oldtab.shard_id = grs.shard_id),\n        cloned       = grs.cloned     - (SELECT COUNT(*) FILTER(WHERE clone_status = 'cloned')     FROM oldtab WHERE oldtab.shard_id = grs.shard_id),\n        failed_fetch = grs.cloned     - (SELECT COUNT(*) FILTER(WHERE last_error IS NOT NULL)      FROM oldtab WHERE oldtab.shard_id = grs.shard_id)\n      ;\n\n      RETURN NULL;\n  END\n$$;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_delete ON gitserver_repos;\nCREATE TRIGGER trig_recalc_gitserver_repos_statistics_on_delete\nAFTER DELETE ON gitserver_repos REFERENCING\nOLD TABLE AS oldtab\nFOR EACH STATEMENT EXECUTE FUNCTION recalc_gitserver_repos_statistics_on_delete();",
				"DownQuery": "DROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_update ON repo;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_insert ON repo;\nDROP TRIGGER IF EXISTS trig_recalc_repo_statistics_on_repo_delete ON repo;\n\nDROP FUNCTION IF EXISTS recalc_repo_statistics_on_repo_update();\nDROP FUNCTION IF EXISTS recalc_repo_statistics_on_repo_insert();\nDROP FUNCTION IF EXISTS recalc_repo_statistics_on_repo_delete();\n\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_update ON gitserver_repos;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_insert ON gitserver_repos;\nDROP TRIGGER IF EXISTS trig_recalc_gitserver_repos_statistics_on_delete ON gitserver_repos;\n\nDROP FUNCTION IF EXISTS recalc_gitserver_repos_statistics_on_update();\nDROP FUNCTION IF EXISTS recalc_gitserver_repos_statistics_on_insert();\nDROP FUNCTION IF EXISTS recalc_gitserver_repos_statistics_on_delete();\n\nDROP TABLE IF EXISTS gitserver_repos_statistics;\nDROP TABLE IF EXISTS repo_statistics;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658950366
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659368926,
				"Name": "cleanup_lsif_indexes_errored",
				"UpQuery": "UPDATE lsif_indexes SET state = 'failed' WHERE state = 'errored' AND num_failures \u003e 0;",
				"DownQuery": "-- Nothing to do here, to older instances both versions of this data are valid state.",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658950366
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659380538,
				"Name": "event_log_dot_com_fields",
				"UpQuery": "ALTER TABLE IF EXISTS event_logs\n    ADD COLUMN IF NOT EXISTS first_source_url TEXT,\n    ADD COLUMN IF NOT EXISTS last_source_url  TEXT,\n    ADD COLUMN IF NOT EXISTS referrer         TEXT,\n    ADD COLUMN IF NOT EXISTS device_id        TEXT,\n    ADD COLUMN IF NOT EXISTS insert_id        TEXT;",
				"DownQuery": "ALTER TABLE IF EXISTS event_logs\n    DROP COLUMN IF EXISTS first_source_url,\n    DROP COLUMN IF EXISTS last_source_url,\n    DROP COLUMN IF EXISTS referrer,\n    DROP COLUMN IF EXISTS device_id,\n    DROP COLUMN IF EXISTS insert_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659368926
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659434035,
				"Name": "alter webhook_build_jobs table",
				"UpQuery": "ALTER TABLE IF EXISTS webhook_build_jobs\n    ADD COLUMN IF NOT EXISTS org text,\n    ADD COLUMN IF NOT EXISTS extsvc_id integer;",
				"DownQuery": "ALTER TABLE IF EXISTS webhook_build_jobs\n    DROP COLUMN IF EXISTS org,\n    DROP COLUMN IF EXISTS extsvc_id;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659368926
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659459805,
				"Name": "repo key value pairs",
				"UpQuery": "-- Perform migration here.\n\nCREATE TABLE IF NOT EXISTS repo_kvps (\n    repo_id INTEGER NOT NULL REFERENCES repo(id) ON DELETE CASCADE,\n    key TEXT NOT NULL,\n    value TEXT NULL,\n    PRIMARY KEY (repo_id, key) INCLUDE (value)\n);",
				"DownQuery": "-- Undo the changes made in the up migration\n\nDROP TABLE IF EXISTS repo_kvps;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659434035
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1659721548,
				"Name": "data_usage_seed_allowlist",
				"UpQuery": "INSERT INTO event_logs_export_allowlist (event_name)\nVALUES ('codeintel.searchDocumentHighlight'),\n       ('SearchNotebookBlocksUpdated'),\n       ('search.latencies.symbol'),\n       ('hover'),\n       ('codeintel.lsifDocumentHighlight'),\n       ('search.latencies.literal'),\n       ('codeintel.lsifHover'),\n       ('codeintel.lsifDefinitions'),\n       ('SearchResultsFetched'),\n       ('search.latencies.regexp'),\n       ('codeintel.searchDefinitions'),\n       ('codeintel.searchHover'),\n       ('ViewHome'),\n       ('ViewSearchResults'),\n       ('search.latencies.repo'),\n       ('HomepageInvitationsViewEmpty'),\n       ('RecentSearchesPanelLoaded'),\n       ('SavedSearchesPanelLoaded'),\n       ('SearchResultClicked'),\n       ('INSIGHT_TOTAL_ORGS_WITH_DASHBOARD'),\n       ('INSIGHT_TOTAL_COUNT_CRITICAL'),\n       ('INSIGHT_TIME_INTERVALS'),\n       ('INSIGHT_ORG_VISIBLE_INSIGHTS'),\n       ('INSIGHT_TOTAL_COUNTS'),\n       ('INSIGHT_DASHBOARD_TOTAL_COUNT'),\n       ('INSIGHTS_PER_DASHBORD_STATS'),\n       ('RepositoriesPanelLoaded'),\n       ('RecentFilesPanelLoaded'),\n       ('SearchResultsCacheRetrieved'),\n       ('BrowserExtensionConnectedToServer'),\n       ('ViewTree'),\n       ('FileTreeClick'),\n       ('codeintel.searchDefinitions.xrepo'),\n       ('search.latencies.file'),\n       ('ViewNoResultsPage'),\n       ('ViewRepository'),\n       ('search.latencies.structural'),\n       ('InsightHover'),\n       ('ExternalAuthSignupFailed'),\n       ('CodeIntelRefs'),\n       ('search.latencies.diff'),\n       ('SurveyReminderViewed'),\n       ('ExtensionActivation'),\n       ('InstallBrowserExtensionCTAShown'),\n       ('ViewSiteAdminOverview'),\n       ('ViewSettingsUser'),\n       ('SearchContextDropdownToggled'),\n       ('definitionHoverOverlay.click'),\n       ('InstallIDEExtensionCTAShown'),\n       ('search.latencies.commit'),\n       ('ViewRepositoryCommit'),\n       ('ViewOnboardingTour'),\n       ('ViewCodeIntelIndexes'),\n       ('ViewInsights'),\n       ('codeintel.lsifReferences'),\n       ('NotebookVisibilitySettingsDropdownToggled'),\n       ('referenceHoverOverlay.click'),\n       ('ViewSearchNotebooksListMyNotebooks'),\n       ('ViewBatchChangesListPage'),\n       ('SearchContextsDropdownViewed'),\n       ('ViewExecutorsList'),\n       ('findReferences'),\n       ('ReferencePanelResultsClicked'),\n       ('SearchNotebooksListPageViewed'),\n       ('SearchNotebookPageViewed'),\n       ('ViewCodeIntelUploads'),\n       ('ViewCodeIntelConfiguration'),\n       ('ExternalAuthSignupSucceeded'),\n       ('ViewSiteAdminConfiguration'),\n       ('goToDefinition.preloaded'),\n       ('ViewSiteAdminExternalServices'),\n       ('CodeCopied'),\n       ('SearchNotebookRunBlock'),\n       ('ViewSiteAdminRepos'),\n       ('git.blame.toggle'),\n       ('codeintel.searchReferences'),\n       ('SearchContextSelected'),\n       ('ViewSiteAdminUsageStatistics'),\n       ('ViewUserProfile'),\n       ('SettingsFileSaved'),\n       ('CodeMonitoringGettingStartedPageViewed'),\n       ('SignInAttempted'),\n       ('SearchNotebookAddBlock'),\n       ('ViewUserSettingsTokens'),\n       ('ViewCodeIntelIndex'),\n       ('GoToCodeHostClicked'),\n       ('RecentSearchesPanelSearchClicked'),\n       ('RepositoriesPanelRepoFilterClicked'),\n       ('codeintel.lsifDefinitions.xrepo'),\n       ('ViewSiteAdminAllUsers'),\n       ('SignInSucceeded'),\n       ('CodeMonitoringPageViewed'),\n       ('ViewCodeIntelRepositoryIndexConfiguration'),\n       ('ViewCodeIntelConfigurationPolicy'),\n       ('NotebooksGettingStartedTabViewed'),\n       ('ViewAddExternalService'),\n       ('InsightUICustomization'),\n       ('ViewRepositoryError'),\n       ('ViewCodeInsightsCreationPage'),\n       ('SearchNotebookShareModalOpened'),\n       ('ViewSiteAdminExternalService'),\n       ('ViewExtensionsOverview'),\n       ('ManageCodeMonitorPageViewed'),\n       ('ViewInsightsGetStartedPage'),\n       ('StandaloneInsightPageViewed'),\n       ('ViewBatchChangeDetailsPage'),\n       ('ViewRevisionsPopover'),\n       ('ViewUserSettingsEmails'),\n       ('codeintel.searchReferences.xrepo'),\n       ('SymbolTreeViewClicked'),\n       ('ViewApiConsole'),\n       ('UTMCodeHostIntegration'),\n       ('ViewSettingsSite'),\n       ('ViewRepoSettingsIndex'),\n       ('codeintel.lsifImplementations'),\n       ('IDESearchSubmitted'),\n       ('ViewUserSettingsProductResearch'),\n       ('ViewUserSettingsPassword'),\n       ('ViewSettingsOrg'),\n       ('ViewSearchNotebooksListExploreNotebooks'),\n       ('ViewRepoSettings'),\n       ('SearchDidYouMeanDisplayed'),\n       ('SiteConfigurationSaved'),\n       ('ShowHistoryPanel'),\n       ('ViewSavedSearchListPage'),\n       ('ViewCodeInsightsSearchBasedCreationPage'),\n       ('findImplementations'),\n       ('ViewRepoSettingsMirror'),\n       ('AdminAnalyticsCodeIntelViewed'),\n       ('AdminAnalyticsSearchViewed'),\n       ('InsightAddMoreClick'),\n       ('ViewSignIn'),\n       ('ViewOrgSettingsProfile'),\n       ('InsightDataPointClick'),\n       ('SignInFailed'),\n       ('ViewSearchNotebooksListStarredNotebooks'),\n       ('ViewSiteAdminOrgs'),\n       ('ViewRepoSettingsPermissions'),\n       ('BrowserExtensionPopupOpened'),\n       ('CreateCodeMonitorPageViewed'),\n       ('FuzzyFinderViewed'),\n       ('ViewNewAccessToken'),\n       ('AccessTokenCreated'),\n       ('RepositoriesPopover'),\n       ('ViewRepositoriesPopover'),\n       ('SearchNotebookDeleteBlock'),\n       ('RootBreadcrumbClicked'),\n       ('ViewUserEventLogPage'),\n       ('CodeInsightsCreateSearchBasedInsightClick'),\n       ('ViewRepositoryCompareOverview'),\n       ('InsightAddition'),\n       ('AdminAnalyticsCodeIntelAggUniquesClicked'),\n       ('StandaloneInsightPageEditClick'),\n       ('SearchNotebookTitleUpdated'),\n       ('SearchNotebooksNotebooksTabClick'),\n       ('CopyFilePath'),\n       ('ViewOrgMembers'),\n       ('InsightEdit'),\n       ('RepositoryComparisonFetched'),\n       ('SearchNotebookCreated'),\n       ('AdminAnalyticsNotebooksViewed'),\n       ('NoResultsPanel'),\n       ('ViewSiteAdminProductSubscription'),\n       ('AdminAnalyticsUsersViewed'),\n       ('ReferencePanelClickedReferences'),\n       ('CreateCodeMonitorFormSubmitted'),\n       ('ViewBatchChangeApplyPage'),\n       ('CloseOnboardingTourClicked'),\n       ('IDEInstalled'),\n       ('FileTreeViewClicked'),\n       ('AdminAnalyticsBatchChangesViewed'),\n       ('ViewRepositoryBranchesOverview'),\n       ('WAUsChartSelected'),\n       ('ViewCodeIntelUpload'),\n       ('codeintel.lsifReferences.xrepo'),\n       ('mixPreciseAndSearchBasedReferences.toggle'),\n       ('ViewSiteAdminSurveyResponses'),\n       ('ViewRepositoryCommits'),\n       ('ViewNewOrg'),\n       ('SearchResultsFetchFailed'),\n       ('SiteConfigurationActionExecuted'),\n       ('CodeInsightsSearchBasedCreationPageSubmitClick'),\n       ('ReferencePanelClickedImplementations'),\n       ('SearchNotebookMoveBlock'),\n       ('UserNotificationsLinkClicked'),\n       ('AdminAnalyticsCodeIntelAggTotalsClicked'),\n       ('ReferencePanelClickedDefinition'),\n       ('ViewCodeInsightsCaptureGroupCreationPage'),\n       ('SearchNotebooksGettingStartedTabClick'),\n       ('ViewUserSettingsPermissions'),\n       ('CodeInsightsCreateCaptureGroupInsightClick'),\n       ('BrowserExtensionPopupRejected'),\n       ('AdminAnalyticsSearchAggUniquesClicked'),\n       ('CommitSHACopiedToClipboard'),\n       ('ExtensionToggled'),\n       ('vscode.open.file'),\n       ('SearchNotebookRunAllBlocks'),\n       ('CodeInsightsDashboardCreationPageSubmitClick'),\n       ('BatchSpecCreated'),\n       ('AddExternalServiceSucceeded'),\n       ('ManageCodeMonitorFormSubmitted'),\n       ('BatchChangeCreatedOrUpdated'),\n       ('SearchNotepadEnabled'),\n       ('ReferencePanelClickedHistory'),\n       ('SearchSnippetClicked'),\n       ('ViewSiteAdminUpdates'),\n       ('CodeInsightsCaptureGroupCreationPageSubmitClick'),\n       ('SearchSkippedResultsAgainClicked'),\n       ('ViewRepositoryReleasesTags'),\n       ('OrgMemberAdded'),\n       ('RepositoryComparisonSubmitted'),\n       ('AdminAnalyticsSearchDateRangeLAST_WEEKSelected'),\n       ('ViewCodeInsightsCodeStatsCreationPage'),\n       ('DAUsChartSelected'),\n       ('goToDefinition'),\n       ('MAUsChartSelected'),\n       ('SettingsFileDiscard'),\n       ('ViewRepositoryStatsContributors'),\n       ('InstallBrowserExtensionCTAClicked'),\n       ('NewUserEmailAddressAdded'),\n       ('HomepageFooterCTASelected'),\n       ('ViewedOnboardingTourFilterRepoStep'),\n       ('SurveyButtonClicked'),\n       ('ViewNewSavedSearchPage'),\n       ('allResultsCollapsed'),\n       ('SearchHelpDropdownQueryDocsLinkClicked'),\n       ('CodeMonitoringLogsPageViewed'),\n       ('AdminAnalyticsSearchAggTotalsClicked'),\n       ('ViewBatchChangeDetailsPageAfterCreate'),\n       ('OnboardingTourRepositoryOptionClicked'),\n       ('CodeInsightsCreateCodeStatsInsightClick'),\n       ('referenceCodeHost.click'),\n       ('InsightsGetStartedTabClick'),\n       ('NewOrgCreated'),\n       ('BatchChangeClosed'),\n       ('CreateNewOrgClicked'),\n       ('AddExternalServiceFailed'),\n       ('CommitBodyToggled'),\n       ('ViewSurvey'),\n       ('HideHistoryPanel'),\n       ('IDEUninstalled'),\n       ('ViewSiteAdminPings'),\n       ('InsightRemoval'),\n       ('ViewRepositoryBranchesAll'),\n       ('SavedSearchCreated'),\n       ('UserEmailAddressSetAsPrimary'),\n       ('WrappedCode'),\n       ('batch_change_list_page:create_batch_change_details:clicked'),\n       ('ViewRegistryExtensionManifest'),\n       ('SearchReferenceClosed'),\n       ('AdminAnalyticsUsersAggTotalsClicked'),\n       ('SearchNotebookCopyNotebookButtonClick'),\n       ('codecov.decorations.toggleCoverage'),\n       ('AdminAnalyticsUsersAggUniquesClicked'),\n       ('AlertNeedsRepoConfigCTAClicked'),\n       ('BatchChangeDeleted'),\n       ('ManageCodeMonitorDeleteSubmitted'),\n       ('AdminAnalyticsNotebooksAggTotalsClicked'),\n       ('CodeInsightsCodeStatsCreationPageSubmitClick'),\n       ('SearchNotebookImportMarkdownNotebookButtonClick'),\n       ('NoResultsVideoPlayed'),\n       ('AdminAnalyticsNotebooksAggUniquesClicked'),\n       ('NoResultsMore'),\n       ('SearchNotebookDeleteButtonClicked'),\n       ('SurveySubmitted'),\n       ('UpdateUserClicked'),\n       ('SavedSearchesPanelCreateButtonClicked'),\n       ('UserEmailAddressMarkedVerified'),\n       ('SearchNotebookImportedFromMarkdown'),\n       ('AddOrgMemberFailed'),\n       ('SearchResultsAutoPureOther'),\n       ('allResultsExpanded'),\n       ('SettingsFileDiscardCanceled'),\n       ('SearchResultsAutoPureAnd'),\n       ('SignUpSucceeded'),\n       ('SearchNotebookDeleteModalOpened'),\n       ('AdminAnalyticsNotebooksDateRangeLAST_MONTHSelected'),\n       ('AdminAnalyticsNotebooksDateRangeLAST_WEEKSelected'),\n       ('ViewSiteAdminRegistryExtensions'),\n       ('InsightsGetStartedBigTemplateClick'),\n       ('ViewSiteAdminCreateUser'),\n       ('SearchResultContextsCTAShown'),\n       ('AdminAnalyticsNotebooksDateRangeLAST_THREE_MONTHSSelected'),\n       ('SearchDidYouMeanClicked'),\n       ('SearchNotebookExportNotebook'),\n       ('InsightGetStartedTemplateClick'),\n       ('UserProfileUpdated'),\n       ('AdminAnalyticsSearchMinutesInputEdited'),\n       ('UserEmailAddressMarkedUnverified'),\n       ('searchExport.export'),\n       ('CodeMonitoringExampleMonitorClicked'),\n       ('BrowserExtensionPopupClosed'),\n       ('ViewSearchNotebooksListOrgNotebooks')\nON CONFLICT DO NOTHING;",
				"DownQuery": "DELETE\nFROM event_logs_export_allowlist\nWHERE event_name IN ('codeintel.searchDocumentHighlight',\n                     'SearchNotebookBlocksUpdated',\n                     'search.latencies.symbol',\n                     'hover',\n                     'codeintel.lsifDocumentHighlight',\n                     'search.latencies.literal',\n                     'codeintel.lsifHover',\n                     'codeintel.lsifDefinitions',\n                     'SearchResultsFetched',\n                     'search.latencies.regexp',\n                     'codeintel.searchDefinitions',\n                     'codeintel.searchHover',\n                     'ViewHome',\n                     'ViewSearchResults',\n                     'search.latencies.repo',\n                     'HomepageInvitationsViewEmpty',\n                     'RecentSearchesPanelLoaded',\n                     'SavedSearchesPanelLoaded',\n                     'SearchResultClicked',\n                     'INSIGHT_TOTAL_ORGS_WITH_DASHBOARD',\n                     'INSIGHT_TOTAL_COUNT_CRITICAL',\n                     'INSIGHT_TIME_INTERVALS',\n                     'INSIGHT_ORG_VISIBLE_INSIGHTS',\n                     'INSIGHT_TOTAL_COUNTS',\n                     'INSIGHT_DASHBOARD_TOTAL_COUNT',\n                     'INSIGHTS_PER_DASHBORD_STATS',\n                     'RepositoriesPanelLoaded',\n                     'RecentFilesPanelLoaded',\n                     'SearchResultsCacheRetrieved',\n                     'BrowserExtensionConnectedToServer',\n                     'ViewTree',\n                     'FileTreeClick',\n                     'codeintel.searchDefinitions.xrepo',\n                     'search.latencies.file',\n                     'ViewNoResultsPage',\n                     'ViewRepository',\n                     'search.latencies.structural',\n                     'InsightHover',\n                     'ExternalAuthSignupFailed',\n                     'CodeIntelRefs',\n                     'search.latencies.diff',\n                     'SurveyReminderViewed',\n                     'ExtensionActivation',\n                     'InstallBrowserExtensionCTAShown',\n                     'ViewSiteAdminOverview',\n                     'ViewSettingsUser',\n                     'SearchContextDropdownToggled',\n                     'definitionHoverOverlay.click',\n                     'InstallIDEExtensionCTAShown',\n                     'search.latencies.commit',\n                     'ViewRepositoryCommit',\n                     'ViewOnboardingTour',\n                     'ViewCodeIntelIndexes',\n                     'ViewInsights',\n                     'codeintel.lsifReferences',\n                     'NotebookVisibilitySettingsDropdownToggled',\n                     'referenceHoverOverlay.click',\n                     'ViewSearchNotebooksListMyNotebooks',\n                     'ViewBatchChangesListPage',\n                     'SearchContextsDropdownViewed',\n                     'ViewExecutorsList',\n                     'findReferences',\n                     'ReferencePanelResultsClicked',\n                     'SearchNotebooksListPageViewed',\n                     'SearchNotebookPageViewed',\n                     'ViewCodeIntelUploads',\n                     'ViewCodeIntelConfiguration',\n                     'ExternalAuthSignupSucceeded',\n                     'ViewSiteAdminConfiguration',\n                     'goToDefinition.preloaded',\n                     'ViewSiteAdminExternalServices',\n                     'CodeCopied',\n                     'SearchNotebookRunBlock',\n                     'ViewSiteAdminRepos',\n                     'git.blame.toggle',\n                     'codeintel.searchReferences',\n                     'SearchContextSelected',\n                     'ViewSiteAdminUsageStatistics',\n                     'ViewUserProfile',\n                     'SettingsFileSaved',\n                     'CodeMonitoringGettingStartedPageViewed',\n                     'SignInAttempted',\n                     'SearchNotebookAddBlock',\n                     'ViewUserSettingsTokens',\n                     'ViewCodeIntelIndex',\n                     'GoToCodeHostClicked',\n                     'RecentSearchesPanelSearchClicked',\n                     'RepositoriesPanelRepoFilterClicked',\n                     'codeintel.lsifDefinitions.xrepo',\n                     'ViewSiteAdminAllUsers',\n                     'SignInSucceeded',\n                     'CodeMonitoringPageViewed',\n                     'ViewCodeIntelRepositoryIndexConfiguration',\n                     'ViewCodeIntelConfigurationPolicy',\n                     'NotebooksGettingStartedTabViewed',\n                     'ViewAddExternalService',\n                     'InsightUICustomization',\n                     'ViewRepositoryError',\n                     'ViewCodeInsightsCreationPage',\n                     'SearchNotebookShareModalOpened',\n                     'ViewSiteAdminExternalService',\n                     'ViewExtensionsOverview',\n                     'ManageCodeMonitorPageViewed',\n                     'ViewInsightsGetStartedPage',\n                     'StandaloneInsightPageViewed',\n                     'ViewBatchChangeDetailsPage',\n                     'ViewRevisionsPopover',\n                     'ViewUserSettingsEmails',\n                     'codeintel.searchReferences.xrepo',\n                     'SymbolTreeViewClicked',\n                     'ViewApiConsole',\n                     'UTMCodeHostIntegration',\n                     'ViewSettingsSite',\n                     'ViewRepoSettingsIndex',\n                     'codeintel.lsifImplementations',\n                     'IDESearchSubmitted',\n                     'ViewUserSettingsProductResearch',\n                     'ViewUserSettingsPassword',\n                     'ViewSettingsOrg',\n                     'ViewSearchNotebooksListExploreNotebooks',\n                     'ViewRepoSettings',\n                     'SearchDidYouMeanDisplayed',\n                     'SiteConfigurationSaved',\n                     'ShowHistoryPanel',\n                     'ViewSavedSearchListPage',\n                     'ViewCodeInsightsSearchBasedCreationPage',\n                     'findImplementations',\n                     'ViewRepoSettingsMirror',\n                     'AdminAnalyticsCodeIntelViewed',\n                     'AdminAnalyticsSearchViewed',\n                     'InsightAddMoreClick',\n                     'ViewSignIn',\n                     'ViewOrgSettingsProfile',\n                     'InsightDataPointClick',\n                     'SignInFailed',\n                     'ViewSearchNotebooksListStarredNotebooks',\n                     'ViewSiteAdminOrgs',\n                     'ViewRepoSettingsPermissions',\n                     'BrowserExtensionPopupOpened',\n                     'CreateCodeMonitorPageViewed',\n                     'FuzzyFinderViewed',\n                     'ViewNewAccessToken',\n                     'AccessTokenCreated',\n                     'RepositoriesPopover',\n                     'ViewRepositoriesPopover',\n                     'SearchNotebookDeleteBlock',\n                     'RootBreadcrumbClicked',\n                     'ViewUserEventLogPage',\n                     'CodeInsightsCreateSearchBasedInsightClick',\n                     'ViewRepositoryCompareOverview',\n                     'InsightAddition',\n                     'AdminAnalyticsCodeIntelAggUniquesClicked',\n                     'StandaloneInsightPageEditClick',\n                     'SearchNotebookTitleUpdated',\n                     'SearchNotebooksNotebooksTabClick',\n                     'CopyFilePath',\n                     'ViewOrgMembers',\n                     'InsightEdit',\n                     'RepositoryComparisonFetched',\n                     'SearchNotebookCreated',\n                     'AdminAnalyticsNotebooksViewed',\n                     'NoResultsPanel',\n                     'ViewSiteAdminProductSubscription',\n                     'AdminAnalyticsUsersViewed',\n                     'ReferencePanelClickedReferences',\n                     'CreateCodeMonitorFormSubmitted',\n                     'ViewBatchChangeApplyPage',\n                     'CloseOnboardingTourClicked',\n                     'IDEInstalled',\n                     'FileTreeViewClicked',\n                     'AdminAnalyticsBatchChangesViewed',\n                     'ViewRepositoryBranchesOverview',\n                     'WAUsChartSelected',\n                     'ViewCodeIntelUpload',\n                     'codeintel.lsifReferences.xrepo',\n                     'mixPreciseAndSearchBasedReferences.toggle',\n                     'ViewSiteAdminSurveyResponses',\n                     'ViewRepositoryCommits',\n                     'ViewNewOrg',\n                     'SearchResultsFetchFailed',\n                     'SiteConfigurationActionExecuted',\n                     'CodeInsightsSearchBasedCreationPageSubmitClick',\n                     'ReferencePanelClickedImplementations',\n                     'SearchNotebookMoveBlock',\n                     'UserNotificationsLinkClicked',\n                     'AdminAnalyticsCodeIntelAggTotalsClicked',\n                     'ReferencePanelClickedDefinition',\n                     'ViewCodeInsightsCaptureGroupCreationPage',\n                     'SearchNotebooksGettingStartedTabClick',\n                     'ViewUserSettingsPermissions',\n                     'CodeInsightsCreateCaptureGroupInsightClick',\n                     'BrowserExtensionPopupRejected',\n                     'AdminAnalyticsSearchAggUniquesClicked',\n                     'CommitSHACopiedToClipboard',\n                     'ExtensionToggled',\n                     'vscode.open.file',\n                     'SearchNotebookRunAllBlocks',\n                     'CodeInsightsDashboardCreationPageSubmitClick',\n                     'BatchSpecCreated',\n                     'AddExternalServiceSucceeded',\n                     'ManageCodeMonitorFormSubmitted',\n                     'BatchChangeCreatedOrUpdated',\n                     'SearchNotepadEnabled',\n                     'ReferencePanelClickedHistory',\n                     'SearchSnippetClicked',\n                     'ViewSiteAdminUpdates',\n                     'CodeInsightsCaptureGroupCreationPageSubmitClick',\n                     'SearchSkippedResultsAgainClicked',\n                     'ViewRepositoryReleasesTags',\n                     'OrgMemberAdded',\n                     'RepositoryComparisonSubmitted',\n                     'AdminAnalyticsSearchDateRangeLAST_WEEKSelected',\n                     'ViewCodeInsightsCodeStatsCreationPage',\n                     'DAUsChartSelected',\n                     'goToDefinition',\n                     'MAUsChartSelected',\n                     'SettingsFileDiscard',\n                     'ViewRepositoryStatsContributors',\n                     'InstallBrowserExtensionCTAClicked',\n                     'NewUserEmailAddressAdded',\n                     'HomepageFooterCTASelected',\n                     'ViewedOnboardingTourFilterRepoStep',\n                     'SurveyButtonClicked',\n                     'ViewNewSavedSearchPage',\n                     'allResultsCollapsed',\n                     'SearchHelpDropdownQueryDocsLinkClicked',\n                     'CodeMonitoringLogsPageViewed',\n                     'AdminAnalyticsSearchAggTotalsClicked',\n                     'ViewBatchChangeDetailsPageAfterCreate',\n                     'OnboardingTourRepositoryOptionClicked',\n                     'CodeInsightsCreateCodeStatsInsightClick',\n                     'referenceCodeHost.click',\n                     'InsightsGetStartedTabClick',\n                     'NewOrgCreated',\n                     'BatchChangeClosed',\n                     'CreateNewOrgClicked',\n                     'AddExternalServiceFailed',\n                     'CommitBodyToggled',\n                     'ViewSurvey',\n                     'HideHistoryPanel',\n                     'IDEUninstalled',\n                     'ViewSiteAdminPings',\n                     'InsightRemoval',\n                     'ViewRepositoryBranchesAll',\n                     'SavedSearchCreated',\n                     'UserEmailAddressSetAsPrimary',\n                     'WrappedCode',\n                     'batch_change_list_page:create_batch_change_details:clicked',\n                     'ViewRegistryExtensionManifest',\n                     'SearchReferenceClosed',\n                     'AdminAnalyticsUsersAggTotalsClicked',\n                     'SearchNotebookCopyNotebookButtonClick',\n                     'codecov.decorations.toggleCoverage',\n                     'AdminAnalyticsUsersAggUniquesClicked',\n                     'AlertNeedsRepoConfigCTAClicked',\n                     'BatchChangeDeleted',\n                     'ManageCodeMonitorDeleteSubmitted',\n                     'AdminAnalyticsNotebooksAggTotalsClicked',\n                     'CodeInsightsCodeStatsCreationPageSubmitClick',\n                     'SearchNotebookImportMarkdownNotebookButtonClick',\n                     'NoResultsVideoPlayed',\n                     'AdminAnalyticsNotebooksAggUniquesClicked',\n                     'NoResultsMore',\n                     'SearchNotebookDeleteButtonClicked',\n                     'SurveySubmitted',\n                     'UpdateUserClicked',\n                     'SavedSearchesPanelCreateButtonClicked',\n                     'UserEmailAddressMarkedVerified',\n                     'SearchNotebookImportedFromMarkdown',\n                     'AddOrgMemberFailed',\n                     'SearchResultsAutoPureOther',\n                     'allResultsExpanded',\n                     'SettingsFileDiscardCanceled',\n                     'SearchResultsAutoPureAnd',\n                     'SignUpSucceeded',\n                     'SearchNotebookDeleteModalOpened',\n                     'AdminAnalyticsNotebooksDateRangeLAST_MONTHSelected',\n                     'AdminAnalyticsNotebooksDateRangeLAST_WEEKSelected',\n                     'ViewSiteAdminRegistryExtensions',\n                     'InsightsGetStartedBigTemplateClick',\n                     'ViewSiteAdminCreateUser',\n                     'SearchResultContextsCTAShown',\n                     'AdminAnalyticsNotebooksDateRangeLAST_THREE_MONTHSSelected',\n                     'SearchDidYouMeanClicked',\n                     'SearchNotebookExportNotebook',\n                     'InsightGetStartedTemplateClick',\n                     'UserProfileUpdated',\n                     'AdminAnalyticsSearchMinutesInputEdited',\n                     'UserEmailAddressMarkedUnverified',\n                     'searchExport.export',\n                     'CodeMonitoringExampleMonitorClicked',\n                     'BrowserExtensionPopupClosed',\n                     'ViewSearchNotebooksListOrgNotebooks');",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658837440,
					1659380538,
					1659434035
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1660132915,
				"Name": "lsif_uploads_uncompressed_size",
				"UpQuery": "ALTER TABLE lsif_uploads\nADD COLUMN IF NOT EXISTS uncompressed_size bigint;\n\nDROP VIEW IF EXISTS lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name,\n    u.uncompressed_size\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;",
				"DownQuery": "DROP VIEW IF EXISTS lsif_uploads_with_repository_name;\n\nCREATE VIEW lsif_uploads_with_repository_name AS\nSELECT u.id,\n    u.commit,\n    u.root,\n    u.queued_at,\n    u.uploaded_at,\n    u.state,\n    u.failure_message,\n    u.started_at,\n    u.finished_at,\n    u.repository_id,\n    u.indexer,\n    u.indexer_version,\n    u.num_parts,\n    u.uploaded_parts,\n    u.process_after,\n    u.num_resets,\n    u.upload_size,\n    u.num_failures,\n    u.associated_index_id,\n    u.expired,\n    u.last_retention_scan_at,\n    r.name AS repository_name\nFROM lsif_uploads u\nJOIN repo r ON r.id = u.repository_id\nWHERE r.deleted_at IS NULL;\n\nALTER TABLE lsif_uploads\nDROP COLUMN IF EXISTS uncompressed_size;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659721548
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1660312877,
				"Name": "add aggregated user statistics table",
				"UpQuery": "-- Perform migration here.\n\nCREATE TABLE IF NOT EXISTS aggregated_user_statistics (\n    user_id BIGINT NOT NULL PRIMARY KEY,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL,\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL,\n    user_last_active_at TIMESTAMP WITH TIME ZONE DEFAULT NULL,\n    user_events_count BIGINT DEFAULT NULL,\n    CONSTRAINT aggregated_user_statistics_user_id_fkey FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n);",
				"DownQuery": "-- Undo the changes made in the up migration\n\nDROP TABLE IF EXISTS aggregated_user_statistics;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1659459805,
					1660132915
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1658874734,
				"Name": "normalized_changeset_specs",
				"UpQuery": "ALTER TABLE changeset_specs\n    ADD COLUMN IF NOT EXISTS diff bytea,\n    ADD COLUMN IF NOT EXISTS base_rev TEXT,\n    ADD COLUMN IF NOT EXISTS base_ref TEXT,\n    ADD COLUMN IF NOT EXISTS body TEXT,\n    ADD COLUMN IF NOT EXISTS published TEXT,\n    ADD COLUMN IF NOT EXISTS commit_message TEXT,\n    ADD COLUMN IF NOT EXISTS commit_author_name TEXT,\n    ADD COLUMN IF NOT EXISTS commit_author_email TEXT,\n    ADD COLUMN IF NOT EXISTS type TEXT;\n\nUPDATE\n    changeset_specs\nSET\n    diff = convert_to(spec-\u003e'commits'-\u003e0-\u003e\u003e'diff', 'UTF8'),\n    base_rev = spec-\u003e\u003e'baseRev',\n    base_ref = spec-\u003e\u003e'baseRef',\n    body = spec-\u003e\u003e'body',\n    published = spec-\u003e\u003e'published',\n    commit_message = spec-\u003e'commits'-\u003e0-\u003e\u003e'message',\n    commit_author_name = spec-\u003e'commits'-\u003e0-\u003e\u003e'authorName',\n    commit_author_email = spec-\u003e'commits'-\u003e0-\u003e\u003e'authorEmail',\n    type = CASE WHEN spec-\u003e\u003e'externalID' IS NOT NULL THEN 'existing' ELSE 'branch' END;",
				"DownQuery": "ALTER TABLE changeset_specs\n    DROP COLUMN IF EXISTS diff,\n    DROP COLUMN IF EXISTS base_rev,\n    DROP COLUMN IF EXISTS base_ref,\n    DROP COLUMN IF EXISTS body,\n    DROP COLUMN IF EXISTS published,\n    DROP COLUMN IF EXISTS commit_message,\n    DROP COLUMN IF EXISTS commit_author_name,\n    DROP COLUMN IF EXISTS commit_author_email,\n    DROP COLUMN IF EXISTS type;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658748822
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			},
			{
				"ID": 1660742069,
				"Name": "non_null_changeset_spec_type",
				"UpQuery": "-- Ensure no unmigrated records exist.\nUPDATE\n    changeset_specs\nSET\n    diff = convert_to(spec-\u003e'commits'-\u003e0-\u003e\u003e'diff', 'UTF8'),\n    base_rev = spec-\u003e\u003e'baseRev',\n    base_ref = spec-\u003e\u003e'baseRef',\n    body = spec-\u003e\u003e'body',\n    published = spec-\u003e\u003e'published',\n    commit_message = spec-\u003e'commits'-\u003e0-\u003e\u003e'message',\n    commit_author_name = spec-\u003e'commits'-\u003e0-\u003e\u003e'authorName',\n    commit_author_email = spec-\u003e'commits'-\u003e0-\u003e\u003e'authorEmail',\n    type = CASE WHEN spec-\u003e\u003e'externalID' IS NOT NULL THEN 'existing' ELSE 'branch' END;\n\nALTER TABLE changeset_specs ALTER COLUMN type SET NOT NULL;\nALTER TABLE changeset_specs ALTER COLUMN spec DROP NOT NULL;\nUPDATE changeset_specs SET spec = NULL;",
				"DownQuery": "ALTER TABLE changeset_specs ALTER COLUMN type DROP NOT NULL;\nALTER TABLE changeset_specs ADD COLUMN IF NOT EXISTS spec jsonb;\n\nUPDATE\n    changeset_specs\nSET\n    spec = jsonb_build_object(\n        'baseRev', base_rev,\n        'baseRef', base_ref,\n        'externalID', external_id,\n        'headRef', head_ref,\n        'title', title,\n        'body', body,\n        'published', published,\n        'commits', json_build_array(\n            jsonb_build_object(\n                'diff', encode(diff, 'escape'),\n                'message', commit_message,\n                'authorName', commit_author_name,\n                'authorEmail', commit_author_email\n            )\n        )\n    );\n\nALTER TABLE changeset_specs ALTER COLUMN spec SET NOT NULL;",
				"Privileged": false,
				"NonIdempotent": false,
				"Parents": [
					1658874734,
					1660312877
				],
				"IsCreateIndexConcurrently": false,
				"IndexMetadata": null
			}
		],
		"BoundsByRev": {
			"v3.29.0": {
				"RootID": -1528395787,
				"LeafIDs": [
					1528395834
				]
			},
			"v3.30.0": {
				"RootID": -1528395787,
				"LeafIDs": [
					1528395853
				]
			},
			"v3.31.0": {
				"RootID": -1528395787,
				"LeafIDs": [
					1528395871
				]
			},
			"v3.32.0": {
				"RootID": -1528395787,
				"LeafIDs": [
					1528395891
				]
			},
			"v3.33.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1528395918
				]
			},
			"v3.34.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1528395944
				]
			},
			"v3.35.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1528395964
				]
			},
			"v3.36.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1528395968
				]
			},
			"v3.37.0": {
				"RootID": -1528395834,
				"LeafIDs": [
					1645106226
				]
			},
			"v3.38.0": {
				"RootID": 1528395943,
				"LeafIDs": [
					1646652951,
					1647282553
				]
			},
			"v3.39.0": {
				"RootID": 1528395943,
				"LeafIDs": [
					1649441222,
					1649759318,
					1649432863
				]
			},
			"v3.40.0": {
				"RootID": 1528395943,
				"LeafIDs": [
					1652228814,
					1652707934
				]
			},
			"v3.41.0": {
				"RootID": 1644868458,
				"LeafIDs": [
					1655481894
				]
			},
			"v3.42.0": {
				"RootID": 1646027072,
				"LeafIDs": [
					1654770608,
					1658174103,
					1658225452,
					1657663493
				]
			},
			"v3.43.0": {
				"RootID": 1646027072,
				"LeafIDs": [
					1660312877,
					1658874734
				]
			},
			"v4.0.0": {
				"RootID": 1646027072,
				"LeafIDs": [
					1659085788,
					1660742069
				]
			}
		}
	}
}
